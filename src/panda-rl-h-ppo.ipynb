{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!apt install -y python-opengl ffmpeg > /dev/null 2>&1\n%pip install pyvirtualdisplay ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:09:45.071277Z","iopub.execute_input":"2024-12-09T00:09:45.071668Z","iopub.status.idle":"2024-12-09T00:09:57.851788Z","shell.execute_reply.started":"2024-12-09T00:09:45.071636Z","shell.execute_reply":"2024-12-09T00:09:57.850715Z"}},"outputs":[{"name":"stdout","text":"Collecting pyvirtualdisplay\n  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\nDownloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\nInstalling collected packages: pyvirtualdisplay\nSuccessfully installed pyvirtualdisplay-3.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install \\\ngym==0.25.2 \\\ngymnasium==1.0.0 \\\nimutils==0.5.4 \\\nJinja2==3.1.4 \\\njoblib \\\nlibclang==18.1.1 \\\nMarkdown==3.7 \\\nMarkupSafe==3.0.2 \\\nmatplotlib==3.9.3 \\\npanda-gym==3.0.7 \\\npillow==11.0.0 \\\npybullet==3.2.6 \\\nsix==1.16.0 \\\nsympy==1.13.1 \\\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:09:57.854321Z","iopub.execute_input":"2024-12-09T00:09:57.854999Z","iopub.status.idle":"2024-12-09T00:10:54.428032Z","shell.execute_reply.started":"2024-12-09T00:09:57.854965Z","shell.execute_reply":"2024-12-09T00:10:54.426956Z"}},"outputs":[{"name":"stdout","text":"Collecting gym==0.25.2\n  Downloading gym-0.25.2.tar.gz (734 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m734.5/734.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting gymnasium==1.0.0\n  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\nCollecting imutils==0.5.4\n  Downloading imutils-0.5.4.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: Jinja2==3.1.4 in /opt/conda/lib/python3.10/site-packages (3.1.4)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (1.4.2)\nRequirement already satisfied: libclang==18.1.1 in /opt/conda/lib/python3.10/site-packages (18.1.1)\nCollecting Markdown==3.7\n  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\nCollecting MarkupSafe==3.0.2\n  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting matplotlib==3.9.3\n  Downloading matplotlib-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting panda-gym==3.0.7\n  Downloading panda_gym-3.0.7-py3-none-any.whl.metadata (4.3 kB)\nCollecting pillow==11.0.0\n  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\nCollecting pybullet==3.2.6\n  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: six==1.16.0 in /opt/conda/lib/python3.10/site-packages (1.16.0)\nCollecting sympy==1.13.1\n  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym==0.25.2) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym==0.25.2) (3.1.0)\nRequirement already satisfied: gym_notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym==0.25.2) (0.0.8)\nRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium==1.0.0) (4.12.2)\nRequirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium==1.0.0) (0.0.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.3) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.3) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.3) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.3) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.3) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.3) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.3) (2.9.0.post0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from panda-gym==3.0.7) (1.14.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1) (1.3.0)\nDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\nDownloading matplotlib-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading panda_gym-3.0.7-py3-none-any.whl (23 kB)\nDownloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: gym, imutils\n  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gym: filename=gym-0.25.2-py3-none-any.whl size=852297 sha256=9d7eb1b354607b6b62db474d224db226b0354b13d6c04822315519ed81fe3e5a\n  Stored in directory: /root/.cache/pip/wheels/78/95/2c/ee47a8d43fda6a851e340e77e27cf75b49ff4ce2d1540c0e80\n  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25837 sha256=1ca82c6233c8709b3fe3e97f446b714e58bdd5009e6650d41efaff995570a255\n  Stored in directory: /root/.cache/pip/wheels/85/cf/3a/e265e975a1e7c7e54eb3692d6aa4e2e7d6a3945d29da46f2d7\nSuccessfully built gym imutils\nInstalling collected packages: pybullet, imutils, sympy, pillow, MarkupSafe, Markdown, gymnasium, gym, panda-gym, matplotlib\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.3\n    Uninstalling sympy-1.13.3:\n      Successfully uninstalled sympy-1.13.3\n  Attempting uninstall: pillow\n    Found existing installation: pillow 10.3.0\n    Uninstalling pillow-10.3.0:\n      Successfully uninstalled pillow-10.3.0\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 2.1.5\n    Uninstalling MarkupSafe-2.1.5:\n      Successfully uninstalled MarkupSafe-2.1.5\n  Attempting uninstall: Markdown\n    Found existing installation: Markdown 3.6\n    Uninstalling Markdown-3.6:\n      Successfully uninstalled Markdown-3.6\n  Attempting uninstall: gymnasium\n    Found existing installation: gymnasium 0.29.0\n    Uninstalling gymnasium-0.29.0:\n      Successfully uninstalled gymnasium-0.29.0\n  Attempting uninstall: gym\n    Found existing installation: gym 0.26.2\n    Uninstalling gym-0.26.2:\n      Successfully uninstalled gym-0.26.2\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.5\n    Uninstalling matplotlib-3.7.5:\n      Successfully uninstalled matplotlib-3.7.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.3.1 which is incompatible.\njupyterlab 4.3.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkaggle-environments 1.16.9 requires gymnasium==0.29.0, but you have gymnasium 1.0.0 which is incompatible.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nstable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.0.0 which is incompatible.\nydata-profiling 4.12.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Markdown-3.7 MarkupSafe-3.0.2 gym-0.25.2 gymnasium-1.0.0 imutils-0.5.4 matplotlib-3.9.3 panda-gym-3.0.7 pillow-11.0.0 pybullet-3.2.6 sympy-1.13.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from pyvirtualdisplay import Display\ndisplay = Display(visible=0, size=(1024, 768))\ndisplay.start()\n\n\nfrom matplotlib import pyplot as plt, animation\n%matplotlib inline\nfrom IPython import display\n\ndef create_anim(frames, dpi, fps):\n    plt.figure(figsize=(frames[0].shape[1] / dpi, frames[0].shape[0] / dpi), dpi=dpi)\n    patch = plt.imshow(frames[0])\n    def setup():\n        plt.axis('off')\n    def animate(i):\n        patch.set_data(frames[i])\n    anim = animation.FuncAnimation(plt.gcf(), animate, init_func=setup, frames=len(frames), interval=fps)\n    return anim\n\ndef display_anim(frames, dpi=72, fps=50):\n    anim = create_anim(frames, dpi, fps)\n    return anim.to_jshtml()\n\ndef save_anim(frames, filename, dpi=72, fps=50):\n    anim = create_anim(frames, dpi, fps)\n    anim.save(filename)\n\n\nclass trigger:\n    def __init__(self):\n        self._trigger = True\n\n    def __call__(self, e):\n        return self._trigger\n\n    def set(self, t):\n        self._trigger = t","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:10:54.429942Z","iopub.execute_input":"2024-12-09T00:10:54.430307Z","iopub.status.idle":"2024-12-09T00:10:55.123196Z","shell.execute_reply.started":"2024-12-09T00:10:54.430267Z","shell.execute_reply":"2024-12-09T00:10:55.122301Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import pybullet as p\n# Add a marker for the world frame\ndef add_world_frame():\n    length = 0.1  # Length of the axis\n    radius = 0.01  # Radius of the lines\n\n    print(\"Frame\")\n    print(\"X-axis: red\")\n    print(\"Y-axis: green\")\n    print(\"Z-axis: blue\")\n\n    # X-axis (red)\n    p.addUserDebugLine([0, 0, 0], [length, 0, 0], [1, 0, 0], lineWidth=2)\n\n    # Y-axis (green)\n    p.addUserDebugLine([0, 0, 0], [0, length, 0], [0, 1, 0], lineWidth=2)\n\n    # Z-axis (blue)\n    p.addUserDebugLine([0, 0, 0], [0, 0, length], [0, 0, 1], lineWidth=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:10:55.125202Z","iopub.execute_input":"2024-12-09T00:10:55.125496Z","iopub.status.idle":"2024-12-09T00:10:55.135816Z","shell.execute_reply.started":"2024-12-09T00:10:55.125469Z","shell.execute_reply":"2024-12-09T00:10:55.134970Z"}},"outputs":[{"name":"stderr","text":"pybullet build time: Nov 28 2023 23:45:17\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import math\nfrom math import pi\nfrom random import choice, uniform\nfrom typing import Any, Dict, Tuple, Optional\n\nimport numpy as np\nfrom panda_gym.envs.core import RobotTaskEnv, Task\nfrom panda_gym.envs.robots.panda import Panda\nfrom panda_gym.pybullet import PyBullet\n\n\nclass TargetObject:\n    \"\"\"\n    TargetObject tracks the lifecycle of a target object (not a goal)\n    \"\"\"\n\n    def __init__(\n        self,\n        id: str,\n        name: str,\n        shape: int,\n        size: np.array,\n        position: np.array,\n        color: np.array,\n        removed: bool = False,\n    ):\n        self.id = id\n        self.name = name\n        self.shape = shape\n        self.size = size\n        self.position = position\n        self.color = color\n        self.removed = removed\n\n\nclass Pick_And_Place(Task):\n    def __init__(\n        self,\n        sim: PyBullet,\n        observation_type: int,\n        robot: Panda,\n        objects_count: int = 3,\n        img_size: Tuple[int, int] = (256, 256),\n        blocker_bar: bool = True,\n        sorting_count: int  = 1\n    ):\n        if observation_type not in [OBSERVATION_POSES, OBSERVATION_IMAGE]:\n            raise Exception(\n                f\"Invalid output type {observation_type}. Must be one of \"\n                + f\"{OBSERVATION_POSES} for values and {OBSERVATION_IMAGE} \"\n                + \"four images.\"\n            )\n\n        super().__init__(sim)\n\n        self.robot = robot\n        self.observation_type = observation_type\n        self.sorting_count = sorting_count\n        self.score: float = 0.0\n\n        self.objects_count: int = objects_count\n        if observation_type == OBSERVATION_IMAGE:\n            self.img_size = img_size\n        self.object_opacity = 0.8\n\n        self.sim.create_plane(z_offset=-0.4)\n\n        # goal_positions will contain one of the three\n        # preset strings (set below) w/ the resulting\n        # starting position each goal is expected to be\n        self.sorter_positions: Dict[str, np.array] = {}\n        self.blocker_bar = blocker_bar\n        self._init_sorting_areas()\n\n        # Track each target object as part of our goal\n        self.goal: Dict[int, TargetObject] = {}\n\n        # Size multiplier is the range of sizes allowed for\n        # target objects\n        self.size_multiplier: Tuple[float, float] = (0.5, 1)\n\n        self.task_init()\n\n    def task_init(self):\n        # Create our plane and table for the scenario\n        self.sim.create_table(length=0.8, width=0.8, height=0.4, x_offset=-0.3)\n\n        # These position_limits are where the objects are allowed\n        # to spawn. This reads as (x, y), where each axis\n        # in turn is a tuple of min/max placement.\n        self.object_position_limits: Tuple[Tuple[float, float]] = (\n            (-0.06, 0.06),\n            (-0.2, 0.2),\n        )\n        # self.sim.create_sphere(\n        #     body_name=\"marker\",\n        #     radius=0.025,\n        #     mass=0.0,\n        #     ghost=True,\n        #     position=(0.06, 0.2, 0.01),\n        #     rgba_color=(255, 255, 0, 1.0),\n        # )\n\n    def _init_sorting_areas(self):\n        if self.sorting_count == 3:\n            self.sorter_positions = {\n                SORTING_ONE: np.array([-0.25, -0.2, 0.01]),\n                SORTING_TWO: np.array([-0.25, 0.00, 0.01]),\n                SORTING_THREE: np.array([-0.25, 0.2, 0.01]),\n            }\n        if self.sorting_count == 2:\n            self.sorter_positions = {\n                SORTING_ONE: np.array([-0.25, -0.2, 0.01]),\n                SORTING_TWO: np.array([-0.25, 0.00, 0.01]),\n            }\n        if self.sorting_count == 1:\n            self.sorter_positions = {\n                SORTING_ONE: np.array([-0.25, -0.2, 0.01]),\n            }\n        if self.blocker_bar:\n            self.sorter_positions[\"blocker\"] = np.array([-0.2, 0.0, 0.01])\n        count = self.sorting_count\n        if (count == 3):\n            self.sim.create_box(\n                body_name=SORTING_THREE,\n                half_extents=np.array([0.05, 0.1, 0.01]),\n                mass=0.0,\n                ghost=False,\n                position=self.sorter_positions[SORTING_THREE],\n                rgba_color=np.array([1.0, 0, 0, 0.4]),\n            )\n            count -=1\n        if count == 2:\n            self.sim.create_box(\n                body_name=SORTING_TWO,\n                half_extents=np.array([0.05, 0.1, 0.01]),\n                mass=0.0,\n                ghost=False,\n                position=self.sorter_positions[SORTING_TWO],\n                rgba_color=np.array([0.0, 1.0, 0, 0.4]),\n            )\n            count-=1\n        if count == 1:\n            self.sim.create_box(\n                body_name=SORTING_ONE,\n                half_extents=np.array([0.05, 0.1, 0.01]),\n                mass=0.0,\n                ghost=False,\n                position=self.sorter_positions[SORTING_ONE],\n                rgba_color=np.array([0, 0, 1.0, 0.5]),\n            )\n\n        if self.blocker_bar:\n            # Create the blocking bar\n            self.sim.create_box(\n                body_name=\"blocker\",\n                half_extents=np.array([0.01, 0.3, 0.005]),\n                mass=0.0,\n                ghost=False,\n                position=self.sorter_positions[\"blocker\"],\n                rgba_color=np.array([0.0, 0.0, 0.0, 0.8]),\n            )\n\n    def set_sorter_positions(self):\n        \"\"\"\n        set_goal_positions will ensure that goals are placed\n        in the appropriate place in the environment\n        \"\"\"\n        # for count in range(self.sorting_count):\n        #     self.sim.set_base_pose(\n        #         GOALS[count],\n        #         position=self.sorter_positions[GOALS[count]],\n        #         orientation=np.array([0.0, 0.0, 0.0, 1.0]),\n        #     )\n        for sorter in self.sorter_positions:\n            self.sim.set_base_pose(\n                sorter,\n                position=self.sorter_positions[sorter],\n                orientation=np.array([0.0, 0.0, 0.0, 1.0]),\n            )\n\n    def setup_target_objects(self):\n        \"\"\"\n        Generate self.objects_count objects randomly on the table of\n        varying sizes, colors, and shapes. The shapes check to ensure\n        that they do NOT collide with one another to start.\n        \"\"\"\n        base_size = 0.025\n        base_mass = 0.5\n        base_box_volume = base_size**3\n        base_cylinder_volume = pi * base_size**3  # h == r in base cylinder\n        # First, delete each object to cleanup\n        self.delete_all_objects()\n\n        for object in range(0, self.objects_count):\n            # Attempt to create the object. If it collides with\n            # another, delete it and try again\n            while True:\n                name = f\"object_{object}\"\n                color = self.get_random_color()\n                if (self.sorting_count == 1):\n                    shape = choice(SHAPES[0:1])\n                if (self.sorting_count == 2):\n                    shape = choice(SHAPES[0:2])\n                if (self.sorting_count == 3):\n                    shape = choice(SHAPES)\n                position = self.get_random_object_position()\n\n                if shape == CUBE:\n                    x = base_size * uniform(\n                        self.size_multiplier[0], self.size_multiplier[1]\n                    )\n                    y = base_size * uniform(\n                        self.size_multiplier[0], self.size_multiplier[1]\n                    )\n                    z = base_size * uniform(\n                        self.size_multiplier[0], self.size_multiplier[1]\n                    )\n                    size = np.array([x, y, z]).astype(np.float32)\n\n                    volume = x * y * z\n                    mass_multiplier = volume / base_box_volume\n\n                    self.sim.create_box(\n                        body_name=name,\n                        half_extents=np.array([x, y, z]),\n                        mass=base_mass * mass_multiplier,\n                        ghost=False,\n                        position=position,\n                        rgba_color=color,\n                    )\n                elif shape == CYLINDER:\n                    height = base_size * uniform(\n                        self.size_multiplier[0], self.size_multiplier[1]\n                    )\n                    radius = base_size * uniform(\n                        self.size_multiplier[0], self.size_multiplier[1]\n                    )\n                    size = np.array([height, radius, 0.0]).astype(np.float32)\n\n                    volume = pi * radius**2 * height\n                    mass_multiplier = volume / base_cylinder_volume\n\n                    self.sim.create_cylinder(\n                        body_name=name,\n                        radius=radius,\n                        height=height,\n                        mass=base_mass * mass_multiplier,\n                        ghost=False,\n                        position=position,\n                        rgba_color=color,\n                    )\n                elif shape == SPHERE:\n                    multiplier = uniform(\n                        self.size_multiplier[0], self.size_multiplier[1]\n                    )\n                    size = np.array([multiplier, 0.0, 0.0]).astype(np.float32)\n\n                    self.sim.create_sphere(\n                        body_name=name,\n                        radius=base_size * multiplier,\n                        mass=base_mass * multiplier,\n                        ghost=False,\n                        position=position,\n                        rgba_color=color,\n                    )\n                else:\n                    raise Exception(\"Improper shape chosen\")\n\n                id = self.sim._bodies_idx[name]\n\n                # Now ensure that the shape created does not\n                # intersect any of the existing shapes\n                collisions = False\n                # If this is the first, we're good; move on\n                if len(self.goal) <= 0:\n                    break\n                # ...otherwise we're going to compare it\n                # against all known objects. If there's\n                # overlap we delete this and move on\n                for other in self.goal:\n                    other_id = self.goal[other].id\n                    if self.check_collision(id, other_id):\n                        collisions = True\n                        break\n\n                if collisions:\n                    self.sim.physics_client.removeBody(id)\n                    continue\n                else:\n                    break\n\n            self.goal[object] = TargetObject(id, name, shape, size, position, color)\n\n    def check_collision(self, object1: str, object2: str) -> bool:\n        \"\"\"\n        check_collision will check if the two objects overlap at all\n        and returns a boolean to that effect\n        \"\"\"\n        contacts = self.sim.physics_client.getContactPoints(object1, object2)\n        return contacts is not None and len(contacts) > 0\n\n    def delete_all_objects(self):\n        for object in self.goal:\n            self.sim.physics_client.removeBody(self.goal[object].id)\n        self.goal = {}\n\n    def get_random_color(self) -> np.array:\n        \"\"\"\n        Returns an appropriate color from a list of decent color choices\n        in the form of a 4 dimensional RGBA array (colors are (0,255) ->\n        (0, 1) scaled)\n        \"\"\"\n        colors = [\n            (255, 0, 0),\n            (0, 255, 0),\n            (0, 0, 255),\n            (255, 0, 255),\n            (178, 102, 255),\n            (102, 255, 255),\n            (102, 0, 204),\n            (255, 128, 0),\n            (204, 0, 102),\n        ]\n        color = choice(colors)\n\n        return np.array([color[0], color[1], color[2], self.object_opacity])\n\n    def get_random_object_position(self) -> np.array:\n        \"\"\"\n        get_random_object_position returns a random np.array of an object's\n        permissions within the permissive bounds set at instantiation.\n        \"\"\"\n        x = uniform(\n            self.object_position_limits[0][0], self.object_position_limits[0][1]\n        )\n        y = uniform(\n            self.object_position_limits[1][0], self.object_position_limits[1][1]\n        )\n        z = 0.01\n        return np.array([x, y, z])\n\n    def reset(self):\n        # Ensure each goal hasn't moved\n        self.set_sorter_positions()\n\n        # Generate new objects\n        self.setup_target_objects()\n\n        # Clear our score\n        self.score = 0.0\n\n    def get_obs(self) -> Tuple[np.array, float]:\n        \"\"\"\n        Determines if any objects collided, adjusts score and reward accordingly,\n        and returns an observation along with the reward for this step.\n\n        Returns:\n            np.array: The observation at this step.\n            float: The reward for this step.\n        \"\"\"\n        reward = 0.0  # Initialize the reward\n\n        # Handle floor collisions\n        reward += self._handle_floor_collisions()\n\n        # Handle goal collisions\n        reward += self._handle_goal_collisions()\n\n        # Reward for moving towards the closest object\n        reward += self._reward_closer_to_object()\n\n        # Reward for successful grasping\n        #reward += self._reward_grasping_success()\n\n        # Reward for moving an object towards its goal\n        reward += self._reward_object_towards_goal()\n\n        # Penalize time-step to encourage efficiency\n        reward += STEP_PENALTY\n\n        # Ensure that each goal stays in position\n        self.set_sorter_positions()\n\n        # Return the observation and the reward\n        if self.observation_type == OBSERVATION_IMAGE:\n            observation = self._get_img()\n        else:\n            observation = self._get_poses_output()\n        self.score += reward\n        return observation, reward\n\n    def _handle_floor_collisions(self) -> float:\n        \"\"\"Checks for floor collisions and penalizes accordingly.\"\"\"\n        reward = 0.0\n        floor_id = self.sim._bodies_idx[\"plane\"]\n        for object_key in self.goal:\n            if self.goal[object_key].removed:\n                continue\n\n            object_id = self.goal[object_key].id\n            if self.check_collision(object_id, floor_id):\n                reward += FLOOR_COLLISION_PENALTY\n                self.sim.physics_client.removeBody(object_id)\n                self.goal[object_key].removed = True\n                print(f\"Object {object_key} dropped to the floor\")\n        return reward\n\n    def _handle_goal_collisions(self) -> float:\n        \"\"\"Checks for collisions between objects and goals, rewarding or penalizing as necessary.\"\"\"\n        reward = 0.0\n        for object_key in self.goal:\n            if self.goal[object_key].removed:\n                continue\n\n            for i in range(self.sorting_count):\n                goal = GOALS[i]\n                object = self.goal[object_key]\n                object_id = object.id\n                goal_id = self.sim._bodies_idx[goal]\n\n                if self.check_collision(object_id, goal_id):\n                    self.sim.physics_client.removeBody(object_id)\n                    self.goal[object_key].removed = True\n\n                    # Reward or penalize based on correct/incorrect sorting\n                    if CORRECT_SORTS[goal] == object.shape:\n                        reward += DROP_SUCCESS_REWARD\n                        print(f\"Object {object_key} correctly sorted into {goal}\")\n                    else:\n                        reward += WRONG_DROP_PENALTY\n                        print(f\"Object {object_key} incorrectly sorted into {goal}\")\n        return reward\n\n    def _reward_closer_to_object(self) -> float:\n        \"\"\"Rewards the agent for moving closer to the nearest object.\"\"\"\n        ee_position = self.robot.get_ee_position()\n        closest_object, closest_distance = self._get_closest_object(ee_position)\n        if closest_object:\n            distance_to_object = np.linalg.norm(ee_position - self.get_object_pose(closest_object)[:3])\n            distance_delta = abs(closest_distance - distance_to_object)\n            return MOVE_TOWARD_OBJECT_REWARD * distance_delta\n        return 0.0\n\n    def _reward_grasping_success(self) -> float:\n        \"\"\"Rewards the agent for successfully grasping an object.\"\"\"\n        return 0.0\n        closest_object, _ = self._get_closest_object(self.robot.get_ee_position())\n        if closest_object and self._is_object_grasped(closest_object):\n            print(f\"Object {closest_object} successfully grasped\")\n            return GRASP_SUCCESS_REWARD\n\n    def _reward_object_towards_goal(self) -> float:\n        \"\"\"Rewards the agent for moving objects closer to their goals.\"\"\"\n        closest_object, closest_distance = self._get_closest_object(self.robot.get_ee_position())\n        if closest_object and not closest_object.removed:\n            object_pos = self.get_object_pose(closest_object)[:3]\n            goal_pos = self.sorter_positions[GOALS[closest_object.shape]]\n            distance_to_goal = np.linalg.norm(object_pos - goal_pos)\n            distance_delta = abs(closest_distance - distance_to_goal)\n            return MOVE_OBJECT_TO_GOAL_REWARD * distance_delta\n\n        return 0.0\n\n    def _get_closest_object(self, ee_position: np.array) -> Tuple[Optional[TargetObject], float]:\n        \"\"\" Return the closest object to the end-effector (EE). \"\"\"\n        closest_object = None\n        closest_distance = float('inf')\n        for object in self.goal.values():\n            if object.removed:\n                continue\n            object_pos = self.get_object_pose(object)[:3]  # x, y, z position\n            distance = np.linalg.norm(ee_position - object_pos)\n            if distance < closest_distance:\n                closest_object = object\n                closest_distance = distance\n        return closest_object, closest_distance\n\n    def _is_object_grasped(self, object) -> bool:\n        \"\"\" Check if the gripper has grasped an object. \"\"\"\n        return self.robot.get_fingers_width() < GRASP_THRESHOLD\n\n    def get_object_pose(self, object: TargetObject) -> np.array:\n        object_position = self.sim.get_base_position(object.name)\n        object_rotation = self.sim.get_base_rotation(object.name)\n        object_velocity = self.sim.get_base_velocity(object.name)\n        object_angular_velocity = self.sim.get_base_angular_velocity(object.name)\n        observation = np.concatenate(\n            [object_position, object_rotation, object_velocity, object_angular_velocity]\n        )\n        return observation.astype(np.float32)\n\n\n\n    def _get_poses_output(self) -> np.array:\n        \"\"\"\n        _get_poses_output will return the poses of all objects in the scene,\n        as well as their identity and size. It will be a series of values for\n        the raw (x, y, z, theta, phi, psi) pose of the object, as well as an\n        identity (type of shape), and size (0-1) for min/max size, and the pose\n        of the robot's end effector, and a 0-1 value for its gripper open/close\n        state. An example of the return would be:\n\n        [[x, y, z, theta, phi, psi,\n          xd, yd, zd, thetad, phid, psid, <~ velocities\n        [identity], [size]] (times # of set objects), ...,\n        (ee_x, ee_y, ee_z, ee_theta, ee_phi, ee_psi,\n        ee_xd, ee_yd, ee_zd, ee_thetad, ee_phid, ee_psid), # <~ velocities\n        gripper_status]\n\n        Note that the identity is a one-hot encoded list of shape [CUBE, CYLINDER,\n        SPHERE] and that size is a three value array of varying meaning based\n        on size: [x, y, z] for CUBE, [radius, height] for CYLINDER, [radius]\n        for SPHERE. Unused values are 0.0.\n        \"\"\"\n        # The size of this vector is determined by the number of objects expected\n        pose_values = 12\n        shape_values = 3\n        size_values = 3\n        # End effector values\n        ee_values = 12\n        finger_values = 1\n        # The length of our vector is (pose_values + (identity, size)) for each\n        # object, pose_values for the end effector, and one additional value for\n        # the gripper finger state (distance between fingers)\n        size = (\n            (len(self.goal) * (pose_values + shape_values + size_values))\n            + ee_values\n            + finger_values\n        )\n        observation: np.array = np.zeros((size,), dtype=\"float32\")\n\n        index = 0\n        for object in self.goal.values():\n            # If the object has been removed, just report 0's for its existence\n            if object.removed:\n                index += 1\n                continue\n\n            pose = self.get_object_pose(object)\n            object_index = index * (pose_values + shape_values + size_values)\n            observation[object_index : object_index + pose_values] = pose\n\n            # The shape is a one hot encoded vector of [CUBE, CYLINDER, SPHERE]\n            if object.shape == CUBE:\n                shape_type = [1, 0, 0]\n            elif object.shape == CYLINDER:\n                shape_type = [0, 1, 0]\n            elif object.shape == SPHERE:\n                shape_type = [0, 0, 1]\n            shapes_index = object_index + pose_values\n            observation[shapes_index : shapes_index + shape_values] = shape_type\n            size_index = shapes_index + shape_values\n            observation[size_index : size_index + size_values] = object.size\n            index += 1\n\n        # Get the end effector position\n        ee_position = self.robot.get_ee_position()\n        ee_rotation_quaternion = self.sim.get_link_orientation(\n            self.robot.body_name, self.robot.ee_link\n        )\n        ee_rotation = self._quaternion_to_euler(ee_rotation_quaternion)\n        # print(\"rot\", ee_rotation)\n        # print(\"rot other\", self.sim.get_base_rotation(self.robot.ee_link))\n        ee_velocity = self.robot.get_ee_velocity()\n        ee_rotational_velocity = self.sim.get_link_angular_velocity(\n            self.robot.body_name, self.robot.ee_link\n        )\n\n        # ee_angulary_velocity = 0.0\n        fingers_width = self.robot.get_fingers_width()\n        ee_index = (pose_values + shape_values + size_values) * len(self.goal)\n        observation[ee_index : ee_index + 3] = ee_position\n        observation[ee_index + 3 : ee_index + 6] = ee_rotation\n        observation[ee_index + 6 : ee_index + 9] = ee_velocity\n        observation[ee_index + 9 : ee_index + 12] = ee_rotational_velocity\n        observation[ee_index + 12] = fingers_width\n\n        return observation\n\n    def _quaternion_to_euler(self, quaternion: np.array):\n        \"\"\"\n        _quaternion_to_euler will convert a quaternion to euler angless\n        \"\"\"\n        x, y, z, w = quaternion\n        t0 = 2.0 * (w * x + y * z)\n        t1 = 1.0 - 2.0 * (x * x + y * y)\n        X = math.atan2(t0, t1)\n\n        t2 = 2.0 * (w * y - z * x)\n        t2 = 1.0 if t2 > +1.0 else t2\n        t2 = -1.0 if t2 < -1.0 else t2\n        Y = math.asin(t2)\n\n        t3 = 2.0 * (w * z + x * y)\n        t4 = 1.0 - 2.0 * (y * y + z * z)\n        Z = math.atan2(t3, t4)\n\n        return np.array([X, Y, Z]).astype(np.float32)\n\n    def _get_img(self) -> np.array:\n        \"\"\"\n        _get_img will return the image from the camera in human rendering\n        mode\n        \"\"\"\n        # We have to swap render mode if it's set to human mode\n        # to get it to draw for us.\n        original_render_mode = self.sim.render_mode\n        self.sim.render_mode = \"rgb_array\"\n        img = self.sim.render(\n            self.img_size[0],\n            self.img_size[1],\n            # target_position=self.camera_position,\n            target_position=None,\n            distance=0.0,\n            yaw=45,\n            pitch=-30,\n            roll=0.0,\n        )\n        self.sim.render_mode = original_render_mode\n        return img\n\n    def get_achieved_goal(self) -> np.ndarray:\n        return np.array(\n            all(target.removed for target in self.goal.values()), dtype=\"bool\"\n        )\n\n    def is_terminated(self) -> bool:\n        \"\"\"\n        is_terminated returns whether or not the episode is\n        in a terminal state; this can be due to:\n        1. All objects have been removed somehow from the env\n        2. The timer has hit 0\n\n        It is not an indication of success\n        \"\"\"\n\n        return all(obj.removed for obj in self.goal.values())\n\n    def is_success(\n        self,\n        achieved_goal: np.ndarray,\n        desired_goal: np.ndarray,\n        info: Dict[str, Any] = ...,\n    ) -> np.ndarray:\n        \"\"\"\n        is_success is a misnamed function, required as a layover\n        from using the panda_gym library. Instead it is best\n        to read it as an interface w/ is_terminated, and in no\n        way reads whether it was a success, since the episode can\n        end via timeout without doing the goals.\n        \"\"\"\n        return np.array([self.is_terminated()], dtype=\"bool\")\n\n    def compute_reward(\n        self,\n        achieved_goal: np.ndarray,\n        desired_goal: np.ndarray,\n        info: Dict[str, Any] = ...,\n    ) -> np.ndarray:\n        return np.array([self.score], dtype=\"float32\")\n\n\nclass My_Arm_RobotEnv(RobotTaskEnv):\n    \"\"\"Sorter task wih Panda robot.\n\n    Args:\n        render_mode (str, optional): Render mode. Defaults to \"human\".\n        control_type (str, optional): \"ee\" to control end-effector position or \"joints\" to control joint values.\n            Defaults to \"ee\".\n        render_width (int, optional): Image width. Defaults to 720.\n        render_height (int, optional): Image height. Defaults to 480.\n    \"\"\"\n\n    def __init__(\n        self,\n        observation_type: int,\n        objects_count: int = 5,\n        blocker_bar: bool = True,\n        render_mode: str = \"human\",\n        control_type: str = \"ee\",\n        renderer: str = \"OpenGL\",\n        render_width: int = 720,\n        render_height: int = 480,\n        sorting_count: int = 1\n    ) -> None:\n        if observation_type not in [OBSERVATION_IMAGE, OBSERVATION_POSES]:\n            raise ValueError(\"observation_type must be one of either images or poses\")\n\n        sim = PyBullet(\n            render_mode=render_mode,\n            background_color=np.array((200, 200, 200)),\n            renderer=renderer,\n        )\n        robot = Panda(\n            sim,\n            block_gripper=False,\n            base_position=np.array([-0.6, 0.0, 0.0]),\n            control_type=control_type,\n        )\n        task = Pick_And_Place(sim,\n                              observation_type,\n                              robot,\n                              objects_count=objects_count,\n                              blocker_bar=blocker_bar,\n                              sorting_count=sorting_count)\n        super().__init__(\n            robot,\n            task,\n            render_width=render_width,\n            render_height=render_height,\n            render_target_position=None,\n            render_distance=0.9,\n            render_yaw=45,\n            render_pitch=-30,\n            render_roll=0.0,\n        )\n        self.total_score = 0\n        self.sim.place_visualizer(\n            target_position=np.zeros(3), distance=0.9, yaw=45, pitch=-30\n        )\n\n    def reset(self) -> Tuple[Dict[str, np.ndarray], Dict[str, np.ndarray]]:\n        with self.sim.no_rendering():\n            self.robot.reset()\n            self.task.reset()\n        observation = self._get_obs()\n        self.total_score = 0\n        return observation, None\n\n    def _get_obs(self) -> Dict[str, np.ndarray]:\n        observation, _ = self.task.get_obs()\n        observation = observation.astype(np.float32)\n        achieved_goal = self.task.get_achieved_goal().astype(np.float32)\n        return {\n            \"observation\": observation,\n            \"achieved_goal\": achieved_goal,\n        }\n\n    def get_obs(self) -> np.ndarray:\n        observation, _ = self.task.get_obs()\n        return observation.astype(np.float32)\n\n    def step(\n        self, action: np.ndarray\n    ) -> Tuple[Dict[str, np.ndarray], float, bool, bool, Dict[str, Any]]:\n        score_prior = self.task.score\n\n        if isinstance(action, dict):\n            discrete_action = action[\"discrete\"]\n            continuous_action = action[\"continuous\"]\n            self.robot.set_action(continuous_action)\n\n        self.sim.step()\n        observation = self._get_obs()\n        score_after = self.task.score\n\n        # An episode is terminated iff the agent has reached the target\n        terminated = bool(\n            self.task.is_success(observation[\"achieved_goal\"], self.task.get_goal())\n        )\n        truncated = False\n        info = {\"is_success\": terminated}\n        step_penalty = STEP_PENALTY\n        reward = (score_after - score_prior) + step_penalty\n        self.total_score += reward\n        # print(\"Score: \",self.total_score)\n        # print(\"reward: \", reward)\n        return observation, reward, terminated, truncated, info\n\n\nSORTING_ONE = \"sorting_one\"\nSORTING_TWO = \"sorting_two\"\nSORTING_THREE = \"sorting_three\"\nGOALS = [SORTING_ONE, SORTING_TWO, SORTING_THREE]\n\nCUBE = 0\nCYLINDER = 1\nSPHERE = 2\nSHAPES = [CUBE, CYLINDER, SPHERE]\n\n# This is the expected correct sorting results\nCORRECT_SORTS = {\n    SORTING_ONE: CYLINDER,\n    SORTING_TWO: SPHERE,\n    SORTING_THREE: CUBE,\n}\n\n\n# FLOOR_PENALTY = -50\n# # WRONG_SORT_REWARD = 25\n# # SORT_REWARD = 100\n# WRONG_SORT_REWARD = 200\n# SORT_REWARD = 500\n\nMOVE_TOWARD_OBJECT_REWARD = -1.0     # Reward for moving EE toward the object\nGRASP_SUCCESS_REWARD = 50.0        # Reward for successful grasp\nMOVE_OBJECT_TO_GOAL_REWARD = -1.0   # Reward for moving object toward goal\nDROP_SUCCESS_REWARD = 50.0       # Reward for successfully placing in correct goal\nWRONG_DROP_PENALTY = -20.0        # Penalty for placing object in wrong goal\nFLOOR_COLLISION_PENALTY = -50.0   # Penalty for dropping the object on the floor\nSTEP_PENALTY = -0.1               # Small penalty to encourage efficiency\nGRASP_THRESHOLD = 0.02\n\nOBSERVATION_POSES: int = 0\nOBSERVATION_IMAGE: int = 1\n\n\nimport time\ndef test_env():\n\n    env = My_Arm_RobotEnv(observation_type=0,\n                          render_mode=\"human\",\n                          blocker_bar=False,\n                          objects_count=1,\n                          sorting_count=2\n                          )\n    add_world_frame()\n    observation, info = env.reset()\n\n    for _ in range(10000):\n        time.sleep(1/24)\n        action = env.action_space.sample()\n        print(action)\n        observation, reward, terminated, truncated, info = env.step(action)\n\n        if terminated or truncated:\n            print(\"Run 1 episode\")\n            observation, info = env.reset()\n\n\nimport time\n\n\ndef test_fixed_actions():\n    env = My_Arm_RobotEnv(\n        observation_type=0,\n        render_mode=\"human\",\n        blocker_bar=False,\n        objects_count=1,\n        sorting_count=2\n    )\n\n    observation, info = env.reset()\n\n    # List of fixed actions to cycle through\n    fixed_actions = [\n        [0, 0, 0.1, 0],  # Move up\n        [0, 0, -0.1, 0],  # Move down\n        [-0.1, 0, 0, 0],  # Move left\n        [0.1, 0, 0, 0],  # Move right\n        [0, 0.1, 0, 0],  # Move forward\n        [0, -0.1, 0, 0],  # Move backward\n        [0, 0, 0, 0.3],  # Open gripper\n        [0, 0, 0, -0.2],  # Close gripper\n        [0, 0, 0.1, 0.7],  # Move up + open gripper\n        [0, 0, -0.1, -0.5]  # Move down + close gripper\n    ]\n    frame = []\n    for action in fixed_actions:\n        for _ in range(50):  # Each action lasts for 50 time steps\n            # frame.append(env.render('human'))\n            observation, reward, terminated, truncated, info = env.step(action)\n            print(f\"Action: {action}, Reward: {reward}, Terminated: {terminated}\")\n            time.sleep(1 / 24)  # Delay for rendering\n\n        if terminated or truncated:\n            print(\"Episode ended, resetting environment.\")\n            observation, info = env.reset()\n\n    # display.HTML(display_anim(frame))\n\n# if __name__ == '__main__':\n#     test_fixed_actions()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:10:55.137120Z","iopub.execute_input":"2024-12-09T00:10:55.137386Z","iopub.status.idle":"2024-12-09T00:10:55.461195Z","shell.execute_reply.started":"2024-12-09T00:10:55.137362Z","shell.execute_reply":"2024-12-09T00:10:55.460402Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch import Tensor\nfrom torch.nn import (Sequential, Module, Linear, ModuleList, Softplus,ModuleDict, ModuleList)\nfrom torch.nn import LeakyReLU\nimport numpy as np\nfrom typing import Union, List\n\nclass DiscreteActor(Module):\n    def __init__(\n            self,\n            obs_dim: int = 20,\n            output_dim: int = 3,\n            control_type=None\n    ):\n        \"\"\"Init the discrete actor. This network estimate a distribution of\n        discrete actions.\n        Args:\n            obs_dim (int, optional): Dimension of observation space. Defaults to 20.\n            output_size (int, optional): Output size or number of discrete\n            actions. Defaults to 3 (Move, Pick, Place)\n        \"\"\"\n        super(DiscreteActor, self).__init__()\n\n        if control_type is not None and control_type == 'pendulum':\n            obs_dim = 3\n            output_dim = 1\n\n        self.model = Sequential(\n            Linear(obs_dim, 256),\n            LeakyReLU(),\n            Linear(256, 128),\n            LeakyReLU(),\n            Linear(128, 64),\n            LeakyReLU(),\n            Linear(64, output_dim),\n        )\n\n    def forward(self, input: Union[np.ndarray, Tensor, List]) -> Union[\n        np.ndarray, Tensor, List]:\n        if isinstance(input, np.ndarray):\n            input_tensor: Tensor = torch.from_numpy(input.astype(\"float32\"))\n        elif type(input) is list:\n            input_tensor: Tensor = torch.from_numpy(\n                np.array(input).astype(\"float32\"))\n        else:\n            input_tensor = input\n\n        # return distribution\n        output = self.model(input_tensor)\n        output_dist = torch.distributions.Categorical(logits=output)\n        return output_dist\n\n    def save(self, filepath: str):\n        torch.save({\n            \"model\": self.model.state_dict(),\n        }, filepath)\n\n    def load(self, filepath: str):\n        data = torch.load(filepath)\n        self.model.load_state_dict(data[\"model\"])\n\n\nclass ContinuousActor(Module):\n    def __init__(\n            self,\n            obs_dim: int = 20,\n            continuous_param_dim: List = [4, 4, 4],\n            control_type=None\n    ):\n        \"\"\"Init the continuous actor. This network predicts mean and std for\n        the continuous parameters.\n        Args:\n            obs_dim (int, optional): Dimension of observation space. Defaults to 20.\n            continuous_param_dim (int, optional): Dimension of continuous\n            parameter. Defaults to [1, 1, 1, 1], meaning each discrete action only has 1 parameter\n        \"\"\"\n        super(ContinuousActor, self).__init__()\n\n        if control_type is not None and control_type == 'pendulum':\n            obs_dim = 3\n            continuous_param_dim = [1]\n\n        self.model = ModuleList(\n            ModuleDict({\n                \"mean\": Sequential(\n                    Linear(obs_dim, 64),\n                    LeakyReLU(),\n                    Linear(64, param_dim)\n                ),\n                \"std\": Sequential(\n                    Linear(obs_dim, 64),\n                    LeakyReLU(),\n                    Linear(64, param_dim),\n                    Softplus()  # Ensures positive standard deviations\n                )\n            })\n            for param_dim in continuous_param_dim\n        )\n\n    def forward(self, input: Union[np.ndarray, Tensor, List]):\n        if isinstance(input, np.ndarray):\n            input_tensor: Tensor = torch.from_numpy(input.astype(\"float32\"))\n        elif type(input) is list:\n            input_tensor: Tensor = torch.from_numpy(\n                np.array(input).astype(\"float32\"))\n        else:\n            input_tensor = input\n\n        continuous_params = [\n            {\n                \"mean\": head[\"mean\"](input_tensor),\n                \"std\": head[\"std\"](input_tensor)\n            }\n            for head in self.model\n        ]\n\n        return continuous_params\n\n\n    def save(self, filepath: str):\n        torch.save({\n            \"model\": self.model.state_dict(),\n        }, filepath)\n\n    def load(self, filepath: str):\n        data = torch.load(filepath)\n        self.model.load_state_dict(data[\"model\"])\n\n\nclass Critic(Module):\n    def __init__(\n            self,\n            obs_dim: int,\n            control_type=None\n    ):\n        \"\"\"Init the critic network. This network estimate V(s)\"\"\"\n        super(Critic, self).__init__()\n\n        if control_type is not None and control_type == 'pendulum':\n            obs_dim = 3\n\n        self.model = Sequential(\n            Linear(obs_dim, 128),\n            LeakyReLU(),\n            Linear(128, 64),\n            LeakyReLU(),\n            Linear(64, 32),\n            LeakyReLU(),\n            Linear(32, 1),\n        )\n\n    def forward(self, input: np.ndarray) -> Tensor:\n        if isinstance(input, np.ndarray):\n            input_tensor: Tensor = torch.from_numpy(input.astype(\"float32\"))\n        elif type(input) is list:\n            input_tensor: Tensor = torch.from_numpy(\n                np.array(input).astype(\"float32\"))\n        else:\n            input_tensor = input\n\n        return self.model(input_tensor)\n\n    def save(self, filepath: str):\n        torch.save({\n            \"model\": self.model.state_dict(),\n        }, filepath)\n\n    def load(self, filepath: str):\n        data = torch.load(filepath)\n        self.model.load_state_dict(data[\"model\"])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:10:55.462234Z","iopub.execute_input":"2024-12-09T00:10:55.462676Z","iopub.status.idle":"2024-12-09T00:10:55.489685Z","shell.execute_reply.started":"2024-12-09T00:10:55.462642Z","shell.execute_reply":"2024-12-09T00:10:55.488961Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch import Tensor\nfrom torch.nn import MSELoss\nfrom torch.distributions import Normal\nfrom panda_gym.envs.core import RobotTaskEnv\nfrom typing import List, Tuple\nimport sys\nimport matplotlib.pyplot as plt\nimport pickle\n\n\nclass Trainer:\n    def __init__(\n            self,\n            env: RobotTaskEnv,\n            discrete_actor: DiscreteActor,\n            continuous_actor: ContinuousActor,\n            critic: Critic,\n            timesteps: int,\n            timesteps_per_batch: int,\n            max_timesteps_per_episode: int,\n            training_cycles_per_batch: int = 5,\n            gamma: float = 0.99,\n            epsilon: float = 0.2,\n            alpha: float = 3e-4,\n            save_every_x_timesteps: int = 50000\n    ):\n        # Environment\n        self.env = env\n\n        # Neural networks\n        self.discrete_actor = discrete_actor\n        self.continuous_actor = continuous_actor\n        self.critic = critic\n\n        # Hypeparameters\n        self.gamma = gamma\n        self.epsilon = epsilon\n        self.alpha = alpha\n\n        # Iteration parameters\n        self.timesteps = timesteps\n        self.current_timestep = 0\n        self.max_timesteps_per_episode = max_timesteps_per_episode\n        self.timesteps_per_batch = timesteps_per_batch\n        self.training_cycles_per_batch = training_cycles_per_batch\n        self.save_every_x_timesteps = save_every_x_timesteps\n\n        # Optimizers\n        self.discrete_optimizer = torch.optim.Adam(\n            params=self.discrete_actor.parameters(), lr=self.alpha)\n        self.continuous_optimizer = torch.optim.Adam(\n            params=self.continuous_actor.parameters(), lr=self.alpha)\n        self.critic_optimizer = torch.optim.Adam(\n            params=self.critic.parameters(),\n                                                 lr=self.alpha)\n        # Memory\n        self.total_rewards: List[float] = []\n        self.terminal_timesteps: List[int] = []\n        self.discrete_actor_losses: List[float] = []\n        self.continuous_actor_losses: List[float] = []\n        self.critic_losses: List[float] = []\n        self.previous_print_length: int = 0\n        self.current_action = \"Initializing\"\n        self.last_save: int = 0\n\n    def print_status(self):\n        latest_reward = 0.0\n        average_reward = 0.0\n        best_reward = 0.0\n\n        latest_discrete_loss = 0.0\n        avg_discrete_loss = 0.0\n        latest_continuous_loss = 0.0\n        avg_continuous_loss = 0.0\n\n        latest_critic_loss = 0.0\n        avg_critic_loss = 0.0\n        recent_change = 0.0\n\n        if len(self.total_rewards) > 0:\n            latest_reward = self.total_rewards[-1]\n\n            last_n_episodes = 100\n            average_reward = np.mean(self.total_rewards[-last_n_episodes:])\n\n            episodes = [\n                i\n                for i in range(\n                    len(self.total_rewards[-last_n_episodes:]),\n                    min(last_n_episodes, 0),\n                    -1,\n                )\n            ]\n            coefficients = np.polyfit(\n                episodes,\n                self.total_rewards[-last_n_episodes:],\n                1,\n            )\n            recent_change = coefficients[0]\n\n            best_reward = max(self.total_rewards)\n\n        if len(self.discrete_actor_losses) > 0:\n            avg_count = 3 * self.timesteps_per_batch\n            latest_discrete_loss = self.discrete_actor_losses[-1]\n            avg_discrete_loss = np.mean(\n                self.discrete_actor_losses[-avg_count:])\n            latest_continuous_loss = self.continuous_actor_losses[-1]\n            avg_continuous_loss = np.mean(\n                self.continuous_actor_losses[-avg_count:])\n            latest_critic_loss = self.critic_losses[-1]\n            avg_critic_loss = np.mean(self.critic_losses[-avg_count:])\n\n        msg = f\"\"\"\n            =========================================\n            Timesteps: {self.current_timestep:,} / {self.timesteps:,} ({round((self.current_timestep / self.timesteps) * 100, 4)}%)\n            Episodes: {len(self.total_rewards):,}\n            Currently: {self.current_action}\n            Latest Reward: {round(latest_reward)}\n            Latest Avg Rewards: {round(average_reward)}\n            Recent Change: {round(recent_change, 2)}\n            Best Reward: {round(best_reward, 2)}\n            Latest Discrete Actor Loss: {round(latest_discrete_loss, 4)}\n            Latest Continuous Actor Loss: {round(latest_continuous_loss, 4)}\n            Avg Discrete Actor Loss: {round(avg_discrete_loss, 4)}\n            Avg Continuous Actor Loss: {round(avg_continuous_loss, 4)}\n            Latest Critic Loss: {round(latest_critic_loss, 4)}\n            Avg Critic Loss: {round(avg_critic_loss, 4)}\n            =========================================\n        \"\"\"\n\n        # We print to STDERR as a hack to get around the noisy pybullet\n        # environment. Hacky, but effective if paired w/ 1> /dev/null\n        print(msg, file=sys.stderr)\n\n    def create_plot(self, filepath: str):\n        last_n_episodes = 10\n\n        episodes = [i + 1 for i in range(len(self.total_rewards))]\n        averages = [\n            np.mean(self.total_rewards[i - last_n_episodes: i])\n            for i in range(len(self.total_rewards))\n        ]\n        trend_data = np.polyfit(episodes, self.total_rewards, 1)\n        trendline = np.poly1d(trend_data)\n\n        plt.scatter(\n            episodes, self.total_rewards, color=\"green\"\n        )  # , linestyle='None', marker='o', color='green')\n        plt.plot(episodes, averages, linestyle=\"solid\", color=\"red\")\n        plt.plot(episodes, trendline(episodes), linestyle=\"--\", color=\"blue\")\n\n        plt.title(\"Rewards per episode\")\n        plt.ylabel(\"Reward\")\n        plt.xlabel(\"Episode\")\n        plt.savefig(filepath)\n\n    def save(self, directory: str):\n        \"\"\"\n        save will save the models, state, and any additional\n        data to the given directory\n        \"\"\"\n        self.last_save = self.current_timestep\n\n        self.discrete_actor.save(f\"{directory}/discrete_actor.pth\")\n        self.continuous_actor.save(f\"{directory}/continuous_actor.pth\")\n        self.critic.save(f\"{directory}/critic.pth\")\n        self.create_plot(f\"{directory}/rewards.png\")\n\n        # Now save the trainer's state data\n        data = {\n            \"timesteps\": self.timesteps,\n            \"current_timestep\": self.current_timestep,\n            \"max_timesteps_per_episode\": self.max_timesteps_per_episode,\n            \"timesteps_per_batch\": self.timesteps_per_batch,\n            \"save_every_x_timesteps\": self.save_every_x_timesteps,\n            \"γ\": self.gamma,\n            \"ε\": self.epsilon,\n            \"α\": self.alpha,\n            \"training_cycles_per_batch\": self.training_cycles_per_batch,\n            \"total_rewards\": self.total_rewards,\n            \"terminal_timesteps\": self.terminal_timesteps,\n            \"discrete_actor_losses\": self.discrete_actor_losses,\n            \"continuous_actor_losses\": self.continuous_actor_losses,\n            \"critic_losses\": self.critic_losses,\n        }\n        pickle.dump(data, open(f\"{directory}/state.data\", \"wb\"))\n\n    def load(self, directory: str):\n        \"\"\"\n        Load will load the models, state, and any additional\n        data from the given directory\n        \"\"\"\n        # Load our models first; they're the simplest\n        self.discrete_actor.load(f\"{directory}/discrete_actor.pth\")\n        self.continuous_actor.load(f\"{directory}/continuous_actor.pth\")\n        self.critic.load(f\"{directory}/critic.pth\")\n\n        data = pickle.load(open(f\"{directory}/state.data\", \"rb\"))\n\n        self.timesteps = data[\"timesteps\"]\n        self.current_timestep = data[\"current_timestep\"]\n        self.last_save = self.current_timestep\n        self.max_timesteps_per_episode = data[\"max_timesteps_per_episode\"]\n        self.timesteps_per_batch = data[\"timesteps_per_batch\"]\n        self.save_every_x_timesteps = data[\"save_every_x_timesteps\"]\n\n        # Hyperparameters\n        self.gamma = data[\"γ\"]\n        self.epsilon = data[\"ε\"]\n        self.alpha = data[\"α\"]\n        self.training_cycles_per_batch = data[\"training_cycles_per_batch\"]\n\n        # Memory\n        self.total_rewards = data[\"total_rewards\"]\n        self.terminal_timesteps = data[\"terminal_timesteps\"]\n        self.discrete_actor_losses = data[\"discrete_actor_losses\"]\n        self.continuous_actor_losses = data[\"continuous_actor_losses\"]\n        self.critic_losses = data[\"critic_losses\"]\n\n        self.discrete_optimizer = torch.optim.Adam(\n            self.discrete_actor.parameters(), lr=self.alpha)\n        self.continuous_optimizer = torch.optim.Adam(\n            self.continuous_actor.parameters(), lr=self.alpha)\n        self.critic_optimizer = torch.optim.Adam(\n            self.critic.parameters(), lr=self.alpha)\n\n    def run_episode(self):\n        \"\"\"Run a single episode.\"\"\"\n        observation, _ = self.env.reset()\n        if isinstance(observation, dict):\n            observation = observation[\"observation\"]\n\n        timesteps = 0\n        observations = []\n        discrete_actions = []\n        continuous_params = []\n        discrete_log_probs = []\n        continuous_log_probs = []\n        rewards = []\n\n        while True:\n            timesteps += 1\n\n            observations.append(observation)\n\n            current_discrete_dist = self.discrete_actor(observation)\n            current_discrete_action = current_discrete_dist.sample()\n            current_discrete_log_prob = current_discrete_dist.log_prob(\n                current_discrete_action).detach().numpy()\n            current_discrete_action = current_discrete_action.detach().numpy()\n\n            current_continuous_params = self.continuous_actor(observation)\n            mean = current_continuous_params[current_discrete_action][\n                'mean']\n            std = current_continuous_params[current_discrete_action][\n                'std']\n            current_continuous_dist = torch.distributions.Normal(mean, std)\n            current_continuous_action = current_continuous_dist.sample()\n            continuous_log_prob = current_continuous_dist.log_prob(\n                current_continuous_action).detach().numpy()\n            current_continuous_action = current_continuous_action.detach().numpy()\n\n            action = {\n                'discrete': current_discrete_action,\n                'continuous': current_continuous_action\n            }\n\n            obs, reward, terminated, _, _ = self.env.step(action)\n\n\n            discrete_actions.append(current_discrete_action)\n            discrete_log_probs.append(current_discrete_log_prob)\n\n            continuous_params.append(current_continuous_action)\n            continuous_log_probs.append(continuous_log_prob)\n\n            rewards.append(reward)\n\n            if timesteps >= self.max_timesteps_per_episode:\n                terminated = True\n\n            if terminated:\n                break\n\n        # Calculate the discounted rewards for this episode\n        discounted_rewards = self.calculate_discounted_reward(rewards)\n\n        # Get the terminal reward and record for status tracking\n        self.total_rewards.append(sum(rewards))\n\n        return (observations, discrete_actions, continuous_params,\n                discrete_log_probs, continuous_log_probs, discounted_rewards)\n\n    def rollout(self):\n        \"\"\"Perform a rollout of the environment and return the memory of the\n        episode with the current actor models\n        \"\"\"\n        observations = []\n        discrete_log_probabilities = []\n        continuous_log_probabilities = []\n        discrete_actions = []\n        continuous_actions = []\n        rewards = []\n\n        while len(observations) < self.timesteps_per_batch:\n            self.current_action = \"Rollout\"\n            (\n                obs,\n                chosen_discrete_actions,\n                chosen_continuous_actions,\n                discrete_log_probs,\n                continuous_log_probs,\n                rwds\n            ) = self.run_episode()\n\n            # Combine these arrays into overall batch\n            observations += obs\n            discrete_actions += chosen_discrete_actions\n            continuous_actions += chosen_continuous_actions\n            discrete_log_probabilities += discrete_log_probs\n            continuous_log_probabilities += continuous_log_probs\n            rewards += rwds\n\n            # Increment count of timesteps\n            self.current_timestep += len(obs)\n\n            self.print_status()\n\n        # Trim the batch memory to the batch size\n        observations = observations[: self.timesteps_per_batch]\n        discrete_actions = discrete_actions[: self.timesteps_per_batch]\n        continuous_actions = continuous_actions[: self.timesteps_per_batch]\n        discrete_log_probabilities = discrete_log_probabilities[\n            : self.timesteps_per_batch]\n        continuous_log_probabilities = continuous_log_probabilities[\n            : self.timesteps_per_batch]\n        rewards = rewards[: self.timesteps_per_batch]\n\n        return (observations, discrete_actions, continuous_actions,\n                discrete_log_probabilities, continuous_log_probabilities,\n                rewards)\n\n    def calculate_discounted_reward(self, rewards):\n        \"\"\"Calculate the discounted reward of each timestep of an episode\n        given its initial rewards and episode length\"\"\"\n        discounted_rewards = []\n        discounted_reward = 0.0\n        for reward in reversed(rewards):\n            discounted_reward = reward + self.gamma * discounted_reward\n            discounted_rewards.insert(0, discounted_reward)\n\n        return discounted_rewards\n\n    def calculate_normalized_advantage(self, observations, rewards):\n        \"\"\"Calculate the normalized advantage of each timestep of a given\n        batch of episode \"\"\"\n        V = self.critic(observations).detach().squeeze()\n\n        advantage = Tensor(np.array(rewards, dtype=\"float32\")) - V\n        normalized_advantage = (advantage - advantage.mean()) / (\n            advantage.std() + 1e-8)\n\n        return normalized_advantage\n\n    def training_step(\n            self,\n            observations,\n            discrete_actions,\n            continuous_actions,\n            discrete_log_probabilities,\n            continuous_log_probabilities,\n            rewards,\n            normalized_advantage\n    ):\n        \"\"\"Peform a single epoch of training for the actors and critic model. Return the loss for each model at the end of the step\"\"\"\n        # ---- Discrete Actor ----\n        current_discrete_dist = self.discrete_actor(observations)\n        current_discrete_log_probs = current_discrete_dist.log_prob(\n            discrete_actions)\n        discrete_ratio = torch.exp(\n            current_discrete_log_probs - discrete_log_probabilities)\n        discrete_actor_loss = -torch.min(\n            discrete_ratio * normalized_advantage,\n            torch.clamp(discrete_ratio, 1 - self.epsilon, 1 +\n                        self.epsilon) * normalized_advantage\n        ).mean()\n\n        self.discrete_optimizer.zero_grad()\n        discrete_actor_loss.backward()\n        self.discrete_optimizer.step()\n\n        # ---- Continuous Actor ----\n        current_continuous_params = self.continuous_actor(observations)\n        means = [current_continuous_params[\n                                 int(discrete_action.item())]['mean']\n                             for discrete_action in discrete_actions]\n        stds = [current_continuous_params[\n                     int(discrete_action.item())]['std']\n                 for discrete_action in discrete_actions]\n\n        means = torch.stack(means)\n        stds = torch.stack(stds)\n\n        current_continuous_dist = torch.distributions.Normal(means, stds)\n        current_continuous_log_probs = current_continuous_dist.log_prob(\n            continuous_actions)\n        continuous_ratios = torch.exp(\n            current_continuous_log_probs - continuous_log_probabilities)\n\n        normalized_advantage = normalized_advantage.unsqueeze(1).unsqueeze(2)\n        continuous_actor_loss = -torch.min(\n            continuous_ratios * normalized_advantage,\n            torch.clamp(continuous_ratios, 1 - self.epsilon,\n                        1 + self.epsilon) * normalized_advantage\n        ).mean()\n\n        self.continuous_optimizer.zero_grad()\n        continuous_actor_loss.backward()\n        self.continuous_optimizer.step()\n\n        # ---- Critic Network ----\n        V = self.critic(observations)\n        reward_tensor = Tensor(rewards).unsqueeze(-1)\n        critic_loss = MSELoss()(V, reward_tensor)\n\n        self.critic_optimizer.zero_grad()\n        critic_loss.backward()\n        self.critic_optimizer.step()\n\n        return discrete_actor_loss.item(), continuous_actor_loss.item(), critic_loss.item()\n\n    def train(self):\n        while self.current_timestep <= self.timesteps:\n            # Rollout to get next training batch\n            observations, discrete_actions, continuous_actions, discrete_log_probabilities, continuous_log_probabilities, rewards = self.rollout()\n\n            # Convert to numpy arrays and then to tensors\n            observations = Tensor(np.array(observations, dtype=np.float32))\n            discrete_actions = Tensor(\n                np.array(discrete_actions, dtype=np.float32))\n            continuous_actions = Tensor(\n                np.array(continuous_actions, dtype=np.float32))\n            discrete_log_probabilities = Tensor(\n                np.array(discrete_log_probabilities, dtype=np.float32))\n            continuous_log_probabilities = Tensor(\n                np.array(continuous_log_probabilities, dtype=np.float32))\n            rewards = Tensor(np.array(rewards, dtype=np.float32))\n\n            # Perform training steps\n            for c in range(self.training_cycles_per_batch):\n                self.current_action = (\n                    f\"Training cycle {c+1}/{self.training_cycles_per_batch}\"\n                )\n                self.print_status()\n                # Calculate losses\n                normalized_advantage = self.calculate_normalized_advantage(\n                    observations, rewards)\n                discrete_loss, continuous_loss, critic_loss = self.training_step(\n                    observations, discrete_actions, continuous_actions, discrete_log_probabilities, continuous_log_probabilities, rewards, normalized_advantage)\n\n                self.discrete_actor_losses.append(discrete_loss)\n                self.continuous_actor_losses.append(continuous_loss)\n                self.critic_losses.append(critic_loss)\n\n            # Every x timesteps, save current status\n            if self.current_timestep - self.last_save >= self.save_every_x_timesteps:\n                self.current_action = \"Saving\"\n                self.print_status()\n                self.save(\"training\")\n\n        print(\"\")\n        print(\"Training complete!\")\n        self.save(\"training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:10:55.491123Z","iopub.execute_input":"2024-12-09T00:10:55.491686Z","iopub.status.idle":"2024-12-09T00:10:55.535633Z","shell.execute_reply.started":"2024-12-09T00:10:55.491648Z","shell.execute_reply":"2024-12-09T00:10:55.534757Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# from test_env import *\n# from model import DiscreteActor, ContinuousActor, Critic\nimport torch\n# from trainer import Trainer\n\nMOVE = 0\nPICK = 1\nPLACE = 2\n\naction_space = {\n    'discrete': {'Move': 0, 'Pick': 1, 'Place': 2},\n    'continuous': [4, 4, 4]\n}\n\ndiscrete_dim = len(action_space['discrete'])\ncontinuous_dim = action_space['continuous']\n\nenv = My_Arm_RobotEnv(\n    observation_type=0,\n    render_mode='rgb_array',\n    blocker_bar=True,\n    objects_count=2,\n    sorting_count=3,\n    renderer = \"Tiny\",\n)\nimport os\n\n# Create a directory named 'training' in the current working directory\nos.makedirs('training', exist_ok=True)\n\n# Verify if the directory was created\nprint(\"Directory 'training' created successfully\" if os.path.exists('training') else \"Failed to create directory\")\n\nobs, _ = env.reset()\nobs_dim = len(obs['observation'])\nd_actor = DiscreteActor(obs_dim=obs_dim, output_dim=discrete_dim)\nc_actor = ContinuousActor(obs_dim=obs_dim,\n                          continuous_param_dim=continuous_dim)\ncritic = Critic(obs_dim=obs_dim)\n\ntrainer = Trainer(\n    env=env,\n    discrete_actor=d_actor,\n    continuous_actor=c_actor,\n    critic=critic,\n    timesteps=2_000_000,\n    timesteps_per_batch=5_000,\n    max_timesteps_per_episode=750,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:36:33.174835Z","iopub.execute_input":"2024-12-09T00:36:33.175250Z"}},"outputs":[{"name":"stdout","text":"Directory 'training' created successfully\nObject 0 incorrectly sorted into sorting_two\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_23/1860987861.py:96: RankWarning: Polyfit may be poorly conditioned\n  coefficients = np.polyfit(\n\n            =========================================\n            Timesteps: 750 / 2,000,000 (0.0375%)\n            Episodes: 1\n            Currently: Rollout\n            Latest Reward: -272\n            Latest Avg Rewards: -272\n            Recent Change: -136.08\n            Best Reward: -272.16\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: 0.0\n            Avg Continuous Actor Loss: 0.0\n            Latest Critic Loss: 0.0\n            Avg Critic Loss: 0.0\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"argv[0]=--background_color_red=0.7843137383460999\nargv[1]=--background_color_green=0.7843137383460999\nargv[2]=--background_color_blue=0.7843137383460999\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 1,500 / 2,000,000 (0.075%)\n            Episodes: 2\n            Currently: Rollout\n            Latest Reward: -268\n            Latest Avg Rewards: -270\n            Recent Change: -4.32\n            Best Reward: -267.84\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: 0.0\n            Avg Continuous Actor Loss: 0.0\n            Latest Critic Loss: 0.0\n            Avg Critic Loss: 0.0\n            =========================================\n        \n\n            =========================================\n            Timesteps: 2,250 / 2,000,000 (0.1125%)\n            Episodes: 3\n            Currently: Rollout\n            Latest Reward: -432\n            Latest Avg Rewards: -324\n            Recent Change: 79.92\n            Best Reward: -267.84\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: 0.0\n            Avg Continuous Actor Loss: 0.0\n            Latest Critic Loss: 0.0\n            Avg Critic Loss: 0.0\n            =========================================\n        \n\n            =========================================\n            Timesteps: 3,000 / 2,000,000 (0.15%)\n            Episodes: 4\n            Currently: Rollout\n            Latest Reward: -475\n            Latest Avg Rewards: -362\n            Recent Change: 77.22\n            Best Reward: -267.84\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: 0.0\n            Avg Continuous Actor Loss: 0.0\n            Latest Critic Loss: 0.0\n            Avg Critic Loss: 0.0\n            =========================================\n        \n\n            =========================================\n            Timesteps: 3,750 / 2,000,000 (0.1875%)\n            Episodes: 5\n            Currently: Rollout\n            Latest Reward: -431\n            Latest Avg Rewards: -376\n            Recent Change: 52.4\n            Best Reward: -267.84\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: 0.0\n            Avg Continuous Actor Loss: 0.0\n            Latest Critic Loss: 0.0\n            Avg Critic Loss: 0.0\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 3,890 / 2,000,000 (0.1945%)\n            Episodes: 6\n            Currently: Rollout\n            Latest Reward: -160\n            Latest Avg Rewards: -340\n            Recent Change: -0.88\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: 0.0\n            Avg Continuous Actor Loss: 0.0\n            Latest Critic Loss: 0.0\n            Avg Critic Loss: 0.0\n            =========================================\n        \n\n            =========================================\n            Timesteps: 4,640 / 2,000,000 (0.232%)\n            Episodes: 7\n            Currently: Rollout\n            Latest Reward: -348\n            Latest Avg Rewards: -341\n            Recent Change: 0.32\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: 0.0\n            Avg Continuous Actor Loss: 0.0\n            Latest Critic Loss: 0.0\n            Avg Critic Loss: 0.0\n            =========================================\n        \n\n            =========================================\n            Timesteps: 5,390 / 2,000,000 (0.2695%)\n            Episodes: 8\n            Currently: Rollout\n            Latest Reward: -261\n            Latest Avg Rewards: -331\n            Recent Change: -6.45\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: 0.0\n            Avg Continuous Actor Loss: 0.0\n            Latest Critic Loss: 0.0\n            Avg Critic Loss: 0.0\n            =========================================\n        \n\n            =========================================\n            Timesteps: 5,390 / 2,000,000 (0.2695%)\n            Episodes: 8\n            Currently: Training cycle 1/5\n            Latest Reward: -261\n            Latest Avg Rewards: -331\n            Recent Change: -6.45\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: 0.0\n            Avg Continuous Actor Loss: 0.0\n            Latest Critic Loss: 0.0\n            Avg Critic Loss: 0.0\n            =========================================\n        \n\n            =========================================\n            Timesteps: 5,390 / 2,000,000 (0.2695%)\n            Episodes: 8\n            Currently: Training cycle 2/5\n            Latest Reward: -261\n            Latest Avg Rewards: -331\n            Recent Change: -6.45\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0191\n            Avg Discrete Actor Loss: -0.0\n            Avg Continuous Actor Loss: 0.0191\n            Latest Critic Loss: 2524.2578\n            Avg Critic Loss: 2524.2578\n            =========================================\n        \n\n            =========================================\n            Timesteps: 5,390 / 2,000,000 (0.2695%)\n            Episodes: 8\n            Currently: Training cycle 3/5\n            Latest Reward: -261\n            Latest Avg Rewards: -331\n            Recent Change: -6.45\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0181\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0186\n            Latest Critic Loss: 2523.5139\n            Avg Critic Loss: 2523.8859\n            =========================================\n        \n\n            =========================================\n            Timesteps: 5,390 / 2,000,000 (0.2695%)\n            Episodes: 8\n            Currently: Training cycle 4/5\n            Latest Reward: -261\n            Latest Avg Rewards: -331\n            Recent Change: -6.45\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0173\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0182\n            Latest Critic Loss: 2522.782\n            Avg Critic Loss: 2523.5179\n            =========================================\n        \n\n            =========================================\n            Timesteps: 5,390 / 2,000,000 (0.2695%)\n            Episodes: 8\n            Currently: Training cycle 5/5\n            Latest Reward: -261\n            Latest Avg Rewards: -331\n            Recent Change: -6.45\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0165\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0177\n            Latest Critic Loss: 2522.0671\n            Avg Critic Loss: 2523.1552\n            =========================================\n        \n\n            =========================================\n            Timesteps: 6,140 / 2,000,000 (0.307%)\n            Episodes: 9\n            Currently: Rollout\n            Latest Reward: -246\n            Latest Avg Rewards: -321\n            Recent Change: -10.14\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0157\n            Avg Discrete Actor Loss: -0.0003\n            Avg Continuous Actor Loss: 0.0173\n            Latest Critic Loss: 2521.3652\n            Avg Critic Loss: 2522.7972\n            =========================================\n        \n\n            =========================================\n            Timesteps: 6,890 / 2,000,000 (0.3445%)\n            Episodes: 10\n            Currently: Rollout\n            Latest Reward: -486\n            Latest Avg Rewards: -338\n            Recent Change: 1.58\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0157\n            Avg Discrete Actor Loss: -0.0003\n            Avg Continuous Actor Loss: 0.0173\n            Latest Critic Loss: 2521.3652\n            Avg Critic Loss: 2522.7972\n            =========================================\n        \n\n            =========================================\n            Timesteps: 7,640 / 2,000,000 (0.382%)\n            Episodes: 11\n            Currently: Rollout\n            Latest Reward: -231\n            Latest Avg Rewards: -328\n            Recent Change: -3.66\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0157\n            Avg Discrete Actor Loss: -0.0003\n            Avg Continuous Actor Loss: 0.0173\n            Latest Critic Loss: 2521.3652\n            Avg Critic Loss: 2522.7972\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 8,025 / 2,000,000 (0.4012%)\n            Episodes: 12\n            Currently: Rollout\n            Latest Reward: -210\n            Latest Avg Rewards: -318\n            Recent Change: -7.34\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0157\n            Avg Discrete Actor Loss: -0.0003\n            Avg Continuous Actor Loss: 0.0173\n            Latest Critic Loss: 2521.3652\n            Avg Critic Loss: 2522.7972\n            =========================================\n        \n\n            =========================================\n            Timesteps: 8,775 / 2,000,000 (0.4387%)\n            Episodes: 13\n            Currently: Rollout\n            Latest Reward: -304\n            Latest Avg Rewards: -317\n            Recent Change: -6.24\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0157\n            Avg Discrete Actor Loss: -0.0003\n            Avg Continuous Actor Loss: 0.0173\n            Latest Critic Loss: 2521.3652\n            Avg Critic Loss: 2522.7972\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 9,525 / 2,000,000 (0.4763%)\n            Episodes: 14\n            Currently: Rollout\n            Latest Reward: -316\n            Latest Avg Rewards: -317\n            Recent Change: -5.02\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0157\n            Avg Discrete Actor Loss: -0.0003\n            Avg Continuous Actor Loss: 0.0173\n            Latest Critic Loss: 2521.3652\n            Avg Critic Loss: 2522.7972\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 10,275 / 2,000,000 (0.5137%)\n            Episodes: 15\n            Currently: Rollout\n            Latest Reward: -265\n            Latest Avg Rewards: -314\n            Recent Change: -5.37\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0157\n            Avg Discrete Actor Loss: -0.0003\n            Avg Continuous Actor Loss: 0.0173\n            Latest Critic Loss: 2521.3652\n            Avg Critic Loss: 2522.7972\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 11,025 / 2,000,000 (0.5513%)\n            Episodes: 16\n            Currently: Rollout\n            Latest Reward: -256\n            Latest Avg Rewards: -310\n            Recent Change: -5.7\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0157\n            Avg Discrete Actor Loss: -0.0003\n            Avg Continuous Actor Loss: 0.0173\n            Latest Critic Loss: 2521.3652\n            Avg Critic Loss: 2522.7972\n            =========================================\n        \n\n            =========================================\n            Timesteps: 11,025 / 2,000,000 (0.5513%)\n            Episodes: 16\n            Currently: Training cycle 1/5\n            Latest Reward: -256\n            Latest Avg Rewards: -310\n            Recent Change: -5.7\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0157\n            Avg Discrete Actor Loss: -0.0003\n            Avg Continuous Actor Loss: 0.0173\n            Latest Critic Loss: 2521.3652\n            Avg Critic Loss: 2522.7972\n            =========================================\n        \n\n            =========================================\n            Timesteps: 11,025 / 2,000,000 (0.5513%)\n            Episodes: 16\n            Currently: Training cycle 2/5\n            Latest Reward: -256\n            Latest Avg Rewards: -310\n            Recent Change: -5.7\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0094\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.016\n            Latest Critic Loss: 1538.8203\n            Avg Critic Loss: 2358.8011\n            =========================================\n        \n\n            =========================================\n            Timesteps: 11,025 / 2,000,000 (0.5513%)\n            Episodes: 16\n            Currently: Training cycle 3/5\n            Latest Reward: -256\n            Latest Avg Rewards: -310\n            Recent Change: -5.7\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0089\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.015\n            Latest Critic Loss: 1538.3223\n            Avg Critic Loss: 2241.5898\n            =========================================\n        \n\n            =========================================\n            Timesteps: 11,025 / 2,000,000 (0.5513%)\n            Episodes: 16\n            Currently: Training cycle 4/5\n            Latest Reward: -256\n            Latest Avg Rewards: -310\n            Recent Change: -5.7\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0085\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0142\n            Latest Critic Loss: 1537.826\n            Avg Critic Loss: 2153.6193\n            =========================================\n        \n\n            =========================================\n            Timesteps: 11,025 / 2,000,000 (0.5513%)\n            Episodes: 16\n            Currently: Training cycle 5/5\n            Latest Reward: -256\n            Latest Avg Rewards: -310\n            Recent Change: -5.7\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.008\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0135\n            Latest Critic Loss: 1537.332\n            Avg Critic Loss: 2085.143\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 11,775 / 2,000,000 (0.5887%)\n            Episodes: 17\n            Currently: Rollout\n            Latest Reward: -405\n            Latest Avg Rewards: -316\n            Recent Change: -2.89\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0076\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0129\n            Latest Critic Loss: 1536.8218\n            Avg Critic Loss: 2030.3109\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 12,525 / 2,000,000 (0.6262%)\n            Episodes: 18\n            Currently: Rollout\n            Latest Reward: -337\n            Latest Avg Rewards: -317\n            Recent Change: -2.07\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0076\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0129\n            Latest Critic Loss: 1536.8218\n            Avg Critic Loss: 2030.3109\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 13,275 / 2,000,000 (0.6638%)\n            Episodes: 19\n            Currently: Rollout\n            Latest Reward: -297\n            Latest Avg Rewards: -316\n            Recent Change: -2.07\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0076\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0129\n            Latest Critic Loss: 1536.8218\n            Avg Critic Loss: 2030.3109\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 14,025 / 2,000,000 (0.7012%)\n            Episodes: 20\n            Currently: Rollout\n            Latest Reward: -417\n            Latest Avg Rewards: -321\n            Recent Change: -0.32\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0076\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0129\n            Latest Critic Loss: 1536.8218\n            Avg Critic Loss: 2030.3109\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 14,775 / 2,000,000 (0.7388%)\n            Episodes: 21\n            Currently: Rollout\n            Latest Reward: -413\n            Latest Avg Rewards: -325\n            Recent Change: 0.92\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0076\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0129\n            Latest Critic Loss: 1536.8218\n            Avg Critic Loss: 2030.3109\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 15,525 / 2,000,000 (0.7762%)\n            Episodes: 22\n            Currently: Rollout\n            Latest Reward: -280\n            Latest Avg Rewards: -323\n            Recent Change: 0.27\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0076\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0129\n            Latest Critic Loss: 1536.8218\n            Avg Critic Loss: 2030.3109\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 16,275 / 2,000,000 (0.8138%)\n            Episodes: 23\n            Currently: Rollout\n            Latest Reward: -228\n            Latest Avg Rewards: -319\n            Recent Change: -0.8\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0076\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0129\n            Latest Critic Loss: 1536.8218\n            Avg Critic Loss: 2030.3109\n            =========================================\n        \n\n            =========================================\n            Timesteps: 16,275 / 2,000,000 (0.8138%)\n            Episodes: 23\n            Currently: Training cycle 1/5\n            Latest Reward: -228\n            Latest Avg Rewards: -319\n            Recent Change: -0.8\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0076\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0129\n            Latest Critic Loss: 1536.8218\n            Avg Critic Loss: 2030.3109\n            =========================================\n        \n\n            =========================================\n            Timesteps: 16,275 / 2,000,000 (0.8138%)\n            Episodes: 23\n            Currently: Training cycle 2/5\n            Latest Reward: -228\n            Latest Avg Rewards: -319\n            Recent Change: -0.8\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0061\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0123\n            Latest Critic Loss: 1726.5502\n            Avg Critic Loss: 2002.6962\n            =========================================\n        \n\n            =========================================\n            Timesteps: 16,275 / 2,000,000 (0.8138%)\n            Episodes: 23\n            Currently: Training cycle 3/5\n            Latest Reward: -228\n            Latest Avg Rewards: -319\n            Recent Change: -0.8\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0057\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0117\n            Latest Critic Loss: 1725.9476\n            Avg Critic Loss: 1979.6339\n            =========================================\n        \n\n            =========================================\n            Timesteps: 16,275 / 2,000,000 (0.8138%)\n            Episodes: 23\n            Currently: Training cycle 4/5\n            Latest Reward: -228\n            Latest Avg Rewards: -319\n            Recent Change: -0.8\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0054\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0113\n            Latest Critic Loss: 1725.3286\n            Avg Critic Loss: 1960.0719\n            =========================================\n        \n\n            =========================================\n            Timesteps: 16,275 / 2,000,000 (0.8138%)\n            Episodes: 23\n            Currently: Training cycle 5/5\n            Latest Reward: -228\n            Latest Avg Rewards: -319\n            Recent Change: -0.8\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0051\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0108\n            Latest Critic Loss: 1724.6984\n            Avg Critic Loss: 1943.2595\n            =========================================\n        \n\n            =========================================\n            Timesteps: 17,025 / 2,000,000 (0.8512%)\n            Episodes: 24\n            Currently: Rollout\n            Latest Reward: -263\n            Latest Avg Rewards: -317\n            Recent Change: -1.26\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0048\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0104\n            Latest Critic Loss: 1724.0717\n            Avg Critic Loss: 1928.647\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 17,775 / 2,000,000 (0.8887%)\n            Episodes: 25\n            Currently: Rollout\n            Latest Reward: -299\n            Latest Avg Rewards: -316\n            Recent Change: -1.27\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0048\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0104\n            Latest Critic Loss: 1724.0717\n            Avg Critic Loss: 1928.647\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 18,525 / 2,000,000 (0.9263%)\n            Episodes: 26\n            Currently: Rollout\n            Latest Reward: -346\n            Latest Avg Rewards: -317\n            Recent Change: -0.88\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0048\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0104\n            Latest Critic Loss: 1724.0717\n            Avg Critic Loss: 1928.647\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 18,858 / 2,000,000 (0.9429%)\n            Episodes: 27\n            Currently: Rollout\n            Latest Reward: -233\n            Latest Avg Rewards: -314\n            Recent Change: -1.45\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0048\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0104\n            Latest Critic Loss: 1724.0717\n            Avg Critic Loss: 1928.647\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 19,107 / 2,000,000 (0.9553%)\n            Episodes: 28\n            Currently: Rollout\n            Latest Reward: -183\n            Latest Avg Rewards: -309\n            Recent Change: -2.27\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0048\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0104\n            Latest Critic Loss: 1724.0717\n            Avg Critic Loss: 1928.647\n            =========================================\n        \n\n            =========================================\n            Timesteps: 19,857 / 2,000,000 (0.9929%)\n            Episodes: 29\n            Currently: Rollout\n            Latest Reward: -469\n            Latest Avg Rewards: -315\n            Recent Change: -0.95\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0048\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0104\n            Latest Critic Loss: 1724.0717\n            Avg Critic Loss: 1928.647\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 20,607 / 2,000,000 (1.0304%)\n            Episodes: 30\n            Currently: Rollout\n            Latest Reward: -419\n            Latest Avg Rewards: -318\n            Recent Change: -0.19\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0048\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0104\n            Latest Critic Loss: 1724.0717\n            Avg Critic Loss: 1928.647\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 21,357 / 2,000,000 (1.0678%)\n            Episodes: 31\n            Currently: Rollout\n            Latest Reward: -330\n            Latest Avg Rewards: -319\n            Recent Change: -0.1\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0048\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0104\n            Latest Critic Loss: 1724.0717\n            Avg Critic Loss: 1928.647\n            =========================================\n        \n\n            =========================================\n            Timesteps: 21,357 / 2,000,000 (1.0678%)\n            Episodes: 31\n            Currently: Training cycle 1/5\n            Latest Reward: -330\n            Latest Avg Rewards: -319\n            Recent Change: -0.1\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0048\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0104\n            Latest Critic Loss: 1724.0717\n            Avg Critic Loss: 1928.647\n            =========================================\n        \n\n            =========================================\n            Timesteps: 21,357 / 2,000,000 (1.0678%)\n            Episodes: 31\n            Currently: Training cycle 2/5\n            Latest Reward: -330\n            Latest Avg Rewards: -319\n            Recent Change: -0.1\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0043\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.01\n            Latest Critic Loss: 2054.1189\n            Avg Critic Loss: 1936.489\n            =========================================\n        \n\n            =========================================\n            Timesteps: 21,357 / 2,000,000 (1.0678%)\n            Episodes: 31\n            Currently: Training cycle 3/5\n            Latest Reward: -330\n            Latest Avg Rewards: -319\n            Recent Change: -0.1\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0041\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0097\n            Latest Critic Loss: 2053.3567\n            Avg Critic Loss: 1943.3636\n            =========================================\n        \n\n            =========================================\n            Timesteps: 21,357 / 2,000,000 (1.0678%)\n            Episodes: 31\n            Currently: Training cycle 4/5\n            Latest Reward: -330\n            Latest Avg Rewards: -319\n            Recent Change: -0.1\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0038\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0094\n            Latest Critic Loss: 2052.5891\n            Avg Critic Loss: 1949.4316\n            =========================================\n        \n\n            =========================================\n            Timesteps: 21,357 / 2,000,000 (1.0678%)\n            Episodes: 31\n            Currently: Training cycle 5/5\n            Latest Reward: -330\n            Latest Avg Rewards: -319\n            Recent Change: -0.1\n            Best Reward: -159.76\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0036\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0091\n            Latest Critic Loss: 2051.7937\n            Avg Critic Loss: 1954.8191\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 21,524 / 2,000,000 (1.0762%)\n            Episodes: 32\n            Currently: Rollout\n            Latest Reward: -150\n            Latest Avg Rewards: -313\n            Recent Change: -1.05\n            Best Reward: -150.47\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 22,274 / 2,000,000 (1.1137%)\n            Episodes: 33\n            Currently: Rollout\n            Latest Reward: -282\n            Latest Avg Rewards: -312\n            Recent Change: -1.12\n            Best Reward: -150.47\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n\n            =========================================\n            Timesteps: 23,024 / 2,000,000 (1.1512%)\n            Episodes: 34\n            Currently: Rollout\n            Latest Reward: -262\n            Latest Avg Rewards: -311\n            Recent Change: -1.28\n            Best Reward: -150.47\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 23,774 / 2,000,000 (1.1887%)\n            Episodes: 35\n            Currently: Rollout\n            Latest Reward: -286\n            Latest Avg Rewards: -310\n            Recent Change: -1.29\n            Best Reward: -150.47\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n\n            =========================================\n            Timesteps: 23,796 / 2,000,000 (1.1898%)\n            Episodes: 36\n            Currently: Rollout\n            Latest Reward: -109\n            Latest Avg Rewards: -305\n            Recent Change: -2.09\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 24,546 / 2,000,000 (1.2273%)\n            Episodes: 37\n            Currently: Rollout\n            Latest Reward: -428\n            Latest Avg Rewards: -308\n            Recent Change: -1.4\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n\n            =========================================\n            Timesteps: 24,573 / 2,000,000 (1.2287%)\n            Episodes: 38\n            Currently: Rollout\n            Latest Reward: -111\n            Latest Avg Rewards: -303\n            Recent Change: -2.09\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 24,840 / 2,000,000 (1.242%)\n            Episodes: 39\n            Currently: Rollout\n            Latest Reward: -229\n            Latest Avg Rewards: -301\n            Recent Change: -2.22\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 24,997 / 2,000,000 (1.2498%)\n            Episodes: 40\n            Currently: Rollout\n            Latest Reward: -151\n            Latest Avg Rewards: -297\n            Recent Change: -2.61\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 incorrectly sorted into sorting_two\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 25,122 / 2,000,000 (1.2561%)\n            Episodes: 41\n            Currently: Rollout\n            Latest Reward: -111\n            Latest Avg Rewards: -293\n            Recent Change: -3.07\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n\n            =========================================\n            Timesteps: 25,872 / 2,000,000 (1.2936%)\n            Episodes: 42\n            Currently: Rollout\n            Latest Reward: -325\n            Latest Avg Rewards: -293\n            Recent Change: -2.75\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 26,622 / 2,000,000 (1.3311%)\n            Episodes: 43\n            Currently: Rollout\n            Latest Reward: -534\n            Latest Avg Rewards: -299\n            Recent Change: -1.8\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n\n            =========================================\n            Timesteps: 26,622 / 2,000,000 (1.3311%)\n            Episodes: 43\n            Currently: Training cycle 1/5\n            Latest Reward: -534\n            Latest Avg Rewards: -299\n            Recent Change: -1.8\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0034\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0088\n            Latest Critic Loss: 2050.9773\n            Avg Critic Loss: 1959.627\n            =========================================\n        \n\n            =========================================\n            Timesteps: 26,622 / 2,000,000 (1.3311%)\n            Episodes: 43\n            Currently: Training cycle 2/5\n            Latest Reward: -534\n            Latest Avg Rewards: -299\n            Recent Change: -1.8\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0022\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0085\n            Latest Critic Loss: 2025.1353\n            Avg Critic Loss: 1962.7465\n            =========================================\n        \n\n            =========================================\n            Timesteps: 26,622 / 2,000,000 (1.3311%)\n            Episodes: 43\n            Currently: Training cycle 3/5\n            Latest Reward: -534\n            Latest Avg Rewards: -299\n            Recent Change: -1.8\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0021\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0082\n            Latest Critic Loss: 2024.2964\n            Avg Critic Loss: 1965.5442\n            =========================================\n        \n\n            =========================================\n            Timesteps: 26,622 / 2,000,000 (1.3311%)\n            Episodes: 43\n            Currently: Training cycle 4/5\n            Latest Reward: -534\n            Latest Avg Rewards: -299\n            Recent Change: -1.8\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.002\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0079\n            Latest Critic Loss: 2023.4364\n            Avg Critic Loss: 1968.0612\n            =========================================\n        \n\n            =========================================\n            Timesteps: 26,622 / 2,000,000 (1.3311%)\n            Episodes: 43\n            Currently: Training cycle 5/5\n            Latest Reward: -534\n            Latest Avg Rewards: -299\n            Recent Change: -1.8\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0019\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0077\n            Latest Critic Loss: 2022.5468\n            Avg Critic Loss: 1970.3315\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 26,753 / 2,000,000 (1.3377%)\n            Episodes: 44\n            Currently: Rollout\n            Latest Reward: -142\n            Latest Avg Rewards: -295\n            Recent Change: -2.15\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0018\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0074\n            Latest Critic Loss: 2021.6132\n            Avg Critic Loss: 1972.3827\n            =========================================\n        \n\n            =========================================\n            Timesteps: 27,503 / 2,000,000 (1.3752%)\n            Episodes: 45\n            Currently: Rollout\n            Latest Reward: -350\n            Latest Avg Rewards: -297\n            Recent Change: -1.85\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0018\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0074\n            Latest Critic Loss: 2021.6132\n            Avg Critic Loss: 1972.3827\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 28,253 / 2,000,000 (1.4126%)\n            Episodes: 46\n            Currently: Rollout\n            Latest Reward: -208\n            Latest Avg Rewards: -295\n            Recent Change: -1.98\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0018\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0074\n            Latest Critic Loss: 2021.6132\n            Avg Critic Loss: 1972.3827\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 28,494 / 2,000,000 (1.4247%)\n            Episodes: 47\n            Currently: Rollout\n            Latest Reward: -191\n            Latest Avg Rewards: -293\n            Recent Change: -2.13\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0018\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0074\n            Latest Critic Loss: 2021.6132\n            Avg Critic Loss: 1972.3827\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 29,244 / 2,000,000 (1.4622%)\n            Episodes: 48\n            Currently: Rollout\n            Latest Reward: -288\n            Latest Avg Rewards: -292\n            Recent Change: -2.01\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0018\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0074\n            Latest Critic Loss: 2021.6132\n            Avg Critic Loss: 1972.3827\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 29,522 / 2,000,000 (1.4761%)\n            Episodes: 49\n            Currently: Rollout\n            Latest Reward: -183\n            Latest Avg Rewards: -290\n            Recent Change: -2.16\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0018\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0074\n            Latest Critic Loss: 2021.6132\n            Avg Critic Loss: 1972.3827\n            =========================================\n        \n\n            =========================================\n            Timesteps: 30,272 / 2,000,000 (1.5136%)\n            Episodes: 50\n            Currently: Rollout\n            Latest Reward: -419\n            Latest Avg Rewards: -293\n            Recent Change: -1.73\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0018\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0074\n            Latest Critic Loss: 2021.6132\n            Avg Critic Loss: 1972.3827\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 31,022 / 2,000,000 (1.5511%)\n            Episodes: 51\n            Currently: Rollout\n            Latest Reward: -260\n            Latest Avg Rewards: -292\n            Recent Change: -1.7\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0018\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0074\n            Latest Critic Loss: 2021.6132\n            Avg Critic Loss: 1972.3827\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 31,772 / 2,000,000 (1.5886%)\n            Episodes: 52\n            Currently: Rollout\n            Latest Reward: -285\n            Latest Avg Rewards: -292\n            Recent Change: -1.62\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0018\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0074\n            Latest Critic Loss: 2021.6132\n            Avg Critic Loss: 1972.3827\n            =========================================\n        \n\n            =========================================\n            Timesteps: 31,772 / 2,000,000 (1.5886%)\n            Episodes: 52\n            Currently: Training cycle 1/5\n            Latest Reward: -285\n            Latest Avg Rewards: -292\n            Recent Change: -1.62\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0018\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0074\n            Latest Critic Loss: 2021.6132\n            Avg Critic Loss: 1972.3827\n            =========================================\n        \n\n            =========================================\n            Timesteps: 31,772 / 2,000,000 (1.5886%)\n            Episodes: 52\n            Currently: Training cycle 2/5\n            Latest Reward: -285\n            Latest Avg Rewards: -292\n            Recent Change: -1.62\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0016\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0072\n            Latest Critic Loss: 1404.0265\n            Avg Critic Loss: 1950.5229\n            =========================================\n        \n\n            =========================================\n            Timesteps: 31,772 / 2,000,000 (1.5886%)\n            Episodes: 52\n            Currently: Training cycle 3/5\n            Latest Reward: -285\n            Latest Avg Rewards: -292\n            Recent Change: -1.62\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0015\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.007\n            Latest Critic Loss: 1403.2\n            Avg Critic Loss: 1930.2517\n            =========================================\n        \n\n            =========================================\n            Timesteps: 31,772 / 2,000,000 (1.5886%)\n            Episodes: 52\n            Currently: Training cycle 4/5\n            Latest Reward: -285\n            Latest Avg Rewards: -292\n            Recent Change: -1.62\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0015\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0068\n            Latest Critic Loss: 1402.345\n            Avg Critic Loss: 1911.3979\n            =========================================\n        \n\n            =========================================\n            Timesteps: 31,772 / 2,000,000 (1.5886%)\n            Episodes: 52\n            Currently: Training cycle 5/5\n            Latest Reward: -285\n            Latest Avg Rewards: -292\n            Recent Change: -1.62\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0014\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0066\n            Latest Critic Loss: 1401.458\n            Avg Critic Loss: 1893.8137\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 31,892 / 2,000,000 (1.5946%)\n            Episodes: 53\n            Currently: Rollout\n            Latest Reward: -139\n            Latest Avg Rewards: -289\n            Recent Change: -1.85\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0014\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0064\n            Latest Critic Loss: 1400.5413\n            Avg Critic Loss: 1877.3713\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 32,642 / 2,000,000 (1.6321%)\n            Episodes: 54\n            Currently: Rollout\n            Latest Reward: -352\n            Latest Avg Rewards: -290\n            Recent Change: -1.62\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0014\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0064\n            Latest Critic Loss: 1400.5413\n            Avg Critic Loss: 1877.3713\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 33,392 / 2,000,000 (1.6696%)\n            Episodes: 55\n            Currently: Rollout\n            Latest Reward: -227\n            Latest Avg Rewards: -289\n            Recent Change: -1.66\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0014\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0064\n            Latest Critic Loss: 1400.5413\n            Avg Critic Loss: 1877.3713\n            =========================================\n        \n\n            =========================================\n            Timesteps: 34,142 / 2,000,000 (1.7071%)\n            Episodes: 56\n            Currently: Rollout\n            Latest Reward: -206\n            Latest Avg Rewards: -288\n            Recent Change: -1.73\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0014\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0064\n            Latest Critic Loss: 1400.5413\n            Avg Critic Loss: 1877.3713\n            =========================================\n        \n\n            =========================================\n            Timesteps: 34,892 / 2,000,000 (1.7446%)\n            Episodes: 57\n            Currently: Rollout\n            Latest Reward: -289\n            Latest Avg Rewards: -288\n            Recent Change: -1.64\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0014\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0064\n            Latest Critic Loss: 1400.5413\n            Avg Critic Loss: 1877.3713\n            =========================================\n        \n\n            =========================================\n            Timesteps: 35,642 / 2,000,000 (1.7821%)\n            Episodes: 58\n            Currently: Rollout\n            Latest Reward: -237\n            Latest Avg Rewards: -287\n            Recent Change: -1.64\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0014\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0064\n            Latest Critic Loss: 1400.5413\n            Avg Critic Loss: 1877.3713\n            =========================================\n        \n\n            =========================================\n            Timesteps: 36,392 / 2,000,000 (1.8196%)\n            Episodes: 59\n            Currently: Rollout\n            Latest Reward: -622\n            Latest Avg Rewards: -292\n            Recent Change: -0.99\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0014\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0064\n            Latest Critic Loss: 1400.5413\n            Avg Critic Loss: 1877.3713\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 36,663 / 2,000,000 (1.8332%)\n            Episodes: 60\n            Currently: Rollout\n            Latest Reward: -210\n            Latest Avg Rewards: -291\n            Recent Change: -1.08\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0014\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0064\n            Latest Critic Loss: 1400.5413\n            Avg Critic Loss: 1877.3713\n            =========================================\n        \n\n            =========================================\n            Timesteps: 37,413 / 2,000,000 (1.8707%)\n            Episodes: 61\n            Currently: Rollout\n            Latest Reward: -214\n            Latest Avg Rewards: -290\n            Recent Change: -1.15\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0014\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0064\n            Latest Critic Loss: 1400.5413\n            Avg Critic Loss: 1877.3713\n            =========================================\n        \n\n            =========================================\n            Timesteps: 37,413 / 2,000,000 (1.8707%)\n            Episodes: 61\n            Currently: Training cycle 1/5\n            Latest Reward: -214\n            Latest Avg Rewards: -290\n            Recent Change: -1.15\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0014\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0064\n            Latest Critic Loss: 1400.5413\n            Avg Critic Loss: 1877.3713\n            =========================================\n        \n\n            =========================================\n            Timesteps: 37,413 / 2,000,000 (1.8707%)\n            Episodes: 61\n            Currently: Training cycle 2/5\n            Latest Reward: -214\n            Latest Avg Rewards: -290\n            Recent Change: -1.15\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0062\n            Latest Critic Loss: 2150.9336\n            Avg Critic Loss: 1886.1959\n            =========================================\n        \n\n            =========================================\n            Timesteps: 37,413 / 2,000,000 (1.8707%)\n            Episodes: 61\n            Currently: Training cycle 3/5\n            Latest Reward: -214\n            Latest Avg Rewards: -290\n            Recent Change: -1.15\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0061\n            Latest Critic Loss: 2149.7849\n            Avg Critic Loss: 1894.4331\n            =========================================\n        \n\n            =========================================\n            Timesteps: 37,413 / 2,000,000 (1.8707%)\n            Episodes: 61\n            Currently: Training cycle 4/5\n            Latest Reward: -214\n            Latest Avg Rewards: -290\n            Recent Change: -1.15\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0059\n            Latest Critic Loss: 2148.5896\n            Avg Critic Loss: 1902.1348\n            =========================================\n        \n\n            =========================================\n            Timesteps: 37,413 / 2,000,000 (1.8707%)\n            Episodes: 61\n            Currently: Training cycle 5/5\n            Latest Reward: -214\n            Latest Avg Rewards: -290\n            Recent Change: -1.15\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0058\n            Latest Critic Loss: 2147.3401\n            Avg Critic Loss: 1909.3467\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 38,163 / 2,000,000 (1.9082%)\n            Episodes: 62\n            Currently: Rollout\n            Latest Reward: -260\n            Latest Avg Rewards: -289\n            Recent Change: -1.14\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0008\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0056\n            Latest Critic Loss: 2146.0396\n            Avg Critic Loss: 1916.1093\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 38,913 / 2,000,000 (1.9457%)\n            Episodes: 63\n            Currently: Rollout\n            Latest Reward: -327\n            Latest Avg Rewards: -290\n            Recent Change: -1.03\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0008\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0056\n            Latest Critic Loss: 2146.0396\n            Avg Critic Loss: 1916.1093\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 39,663 / 2,000,000 (1.9831%)\n            Episodes: 64\n            Currently: Rollout\n            Latest Reward: -317\n            Latest Avg Rewards: -290\n            Recent Change: -0.95\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0008\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0056\n            Latest Critic Loss: 2146.0396\n            Avg Critic Loss: 1916.1093\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 40,413 / 2,000,000 (2.0206%)\n            Episodes: 65\n            Currently: Rollout\n            Latest Reward: -333\n            Latest Avg Rewards: -291\n            Recent Change: -0.84\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0008\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0056\n            Latest Critic Loss: 2146.0396\n            Avg Critic Loss: 1916.1093\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 41,163 / 2,000,000 (2.0581%)\n            Episodes: 66\n            Currently: Rollout\n            Latest Reward: -223\n            Latest Avg Rewards: -290\n            Recent Change: -0.9\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0008\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0056\n            Latest Critic Loss: 2146.0396\n            Avg Critic Loss: 1916.1093\n            =========================================\n        \n\n            =========================================\n            Timesteps: 41,913 / 2,000,000 (2.0957%)\n            Episodes: 67\n            Currently: Rollout\n            Latest Reward: -197\n            Latest Avg Rewards: -289\n            Recent Change: -0.98\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0008\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0056\n            Latest Critic Loss: 2146.0396\n            Avg Critic Loss: 1916.1093\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 42,663 / 2,000,000 (2.1332%)\n            Episodes: 68\n            Currently: Rollout\n            Latest Reward: -358\n            Latest Avg Rewards: -290\n            Recent Change: -0.85\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0008\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0056\n            Latest Critic Loss: 2146.0396\n            Avg Critic Loss: 1916.1093\n            =========================================\n        \n\n            =========================================\n            Timesteps: 42,663 / 2,000,000 (2.1332%)\n            Episodes: 68\n            Currently: Training cycle 1/5\n            Latest Reward: -358\n            Latest Avg Rewards: -290\n            Recent Change: -0.85\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0008\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0056\n            Latest Critic Loss: 2146.0396\n            Avg Critic Loss: 1916.1093\n            =========================================\n        \n\n            =========================================\n            Timesteps: 42,663 / 2,000,000 (2.1332%)\n            Episodes: 68\n            Currently: Training cycle 2/5\n            Latest Reward: -358\n            Latest Avg Rewards: -290\n            Recent Change: -0.85\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0011\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0055\n            Latest Critic Loss: 1209.4896\n            Avg Critic Loss: 1896.481\n            =========================================\n        \n\n            =========================================\n            Timesteps: 42,663 / 2,000,000 (2.1332%)\n            Episodes: 68\n            Currently: Training cycle 3/5\n            Latest Reward: -358\n            Latest Avg Rewards: -290\n            Recent Change: -0.85\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0054\n            Latest Critic Loss: 1208.401\n            Avg Critic Loss: 1877.8843\n            =========================================\n        \n\n            =========================================\n            Timesteps: 42,663 / 2,000,000 (2.1332%)\n            Episodes: 68\n            Currently: Training cycle 4/5\n            Latest Reward: -358\n            Latest Avg Rewards: -290\n            Recent Change: -0.85\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0053\n            Latest Critic Loss: 1207.2756\n            Avg Critic Loss: 1860.2367\n            =========================================\n        \n\n            =========================================\n            Timesteps: 42,663 / 2,000,000 (2.1332%)\n            Episodes: 68\n            Currently: Training cycle 5/5\n            Latest Reward: -358\n            Latest Avg Rewards: -290\n            Recent Change: -0.85\n            Best Reward: -108.67\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0052\n            Latest Critic Loss: 1206.1122\n            Avg Critic Loss: 1843.4642\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 42,685 / 2,000,000 (2.1343%)\n            Episodes: 69\n            Currently: Rollout\n            Latest Reward: -108\n            Latest Avg Rewards: -287\n            Recent Change: -1.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0051\n            Latest Critic Loss: 1204.9008\n            Avg Critic Loss: 1827.5002\n            =========================================\n        \n\n            =========================================\n            Timesteps: 43,435 / 2,000,000 (2.1718%)\n            Episodes: 70\n            Currently: Rollout\n            Latest Reward: -224\n            Latest Avg Rewards: -286\n            Recent Change: -1.07\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0051\n            Latest Critic Loss: 1204.9008\n            Avg Critic Loss: 1827.5002\n            =========================================\n        \n\n            =========================================\n            Timesteps: 44,185 / 2,000,000 (2.2092%)\n            Episodes: 71\n            Currently: Rollout\n            Latest Reward: -246\n            Latest Avg Rewards: -286\n            Recent Change: -1.07\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0051\n            Latest Critic Loss: 1204.9008\n            Avg Critic Loss: 1827.5002\n            =========================================\n        \n\n            =========================================\n            Timesteps: 44,935 / 2,000,000 (2.2468%)\n            Episodes: 72\n            Currently: Rollout\n            Latest Reward: -230\n            Latest Avg Rewards: -285\n            Recent Change: -1.09\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0051\n            Latest Critic Loss: 1204.9008\n            Avg Critic Loss: 1827.5002\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 45,240 / 2,000,000 (2.262%)\n            Episodes: 73\n            Currently: Rollout\n            Latest Reward: -200\n            Latest Avg Rewards: -284\n            Recent Change: -1.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0051\n            Latest Critic Loss: 1204.9008\n            Avg Critic Loss: 1827.5002\n            =========================================\n        \n\n            =========================================\n            Timesteps: 45,990 / 2,000,000 (2.2995%)\n            Episodes: 74\n            Currently: Rollout\n            Latest Reward: -294\n            Latest Avg Rewards: -284\n            Recent Change: -1.09\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0051\n            Latest Critic Loss: 1204.9008\n            Avg Critic Loss: 1827.5002\n            =========================================\n        \n\n            =========================================\n            Timesteps: 46,740 / 2,000,000 (2.337%)\n            Episodes: 75\n            Currently: Rollout\n            Latest Reward: -252\n            Latest Avg Rewards: -283\n            Recent Change: -1.08\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0051\n            Latest Critic Loss: 1204.9008\n            Avg Critic Loss: 1827.5002\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 47,490 / 2,000,000 (2.3745%)\n            Episodes: 76\n            Currently: Rollout\n            Latest Reward: -524\n            Latest Avg Rewards: -286\n            Recent Change: -0.79\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0051\n            Latest Critic Loss: 1204.9008\n            Avg Critic Loss: 1827.5002\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 48,240 / 2,000,000 (2.412%)\n            Episodes: 77\n            Currently: Rollout\n            Latest Reward: -340\n            Latest Avg Rewards: -287\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0051\n            Latest Critic Loss: 1204.9008\n            Avg Critic Loss: 1827.5002\n            =========================================\n        \n\n            =========================================\n            Timesteps: 48,240 / 2,000,000 (2.412%)\n            Episodes: 77\n            Currently: Training cycle 1/5\n            Latest Reward: -340\n            Latest Avg Rewards: -287\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0009\n            Avg Discrete Actor Loss: -0.0002\n            Avg Continuous Actor Loss: 0.0051\n            Latest Critic Loss: 1204.9008\n            Avg Critic Loss: 1827.5002\n            =========================================\n        \n\n            =========================================\n            Timesteps: 48,240 / 2,000,000 (2.412%)\n            Episodes: 77\n            Currently: Training cycle 2/5\n            Latest Reward: -340\n            Latest Avg Rewards: -287\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0007\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0049\n            Latest Critic Loss: 1536.9894\n            Avg Critic Loss: 1820.4145\n            =========================================\n        \n\n            =========================================\n            Timesteps: 48,240 / 2,000,000 (2.412%)\n            Episodes: 77\n            Currently: Training cycle 3/5\n            Latest Reward: -340\n            Latest Avg Rewards: -287\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0007\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0048\n            Latest Critic Loss: 1535.4991\n            Avg Critic Loss: 1813.6308\n            =========================================\n        \n\n            =========================================\n            Timesteps: 48,240 / 2,000,000 (2.412%)\n            Episodes: 77\n            Currently: Training cycle 4/5\n            Latest Reward: -340\n            Latest Avg Rewards: -287\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0007\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0047\n            Latest Critic Loss: 1533.9299\n            Avg Critic Loss: 1807.1262\n            =========================================\n        \n\n            =========================================\n            Timesteps: 48,240 / 2,000,000 (2.412%)\n            Episodes: 77\n            Currently: Training cycle 5/5\n            Latest Reward: -340\n            Latest Avg Rewards: -287\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0047\n            Latest Critic Loss: 1532.2712\n            Avg Critic Loss: 1800.8795\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 48,990 / 2,000,000 (2.4495%)\n            Episodes: 78\n            Currently: Rollout\n            Latest Reward: -276\n            Latest Avg Rewards: -287\n            Recent Change: -0.69\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0046\n            Latest Critic Loss: 1530.5286\n            Avg Critic Loss: 1794.8717\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 49,044 / 2,000,000 (2.4522%)\n            Episodes: 79\n            Currently: Rollout\n            Latest Reward: -123\n            Latest Avg Rewards: -285\n            Recent Change: -0.82\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0046\n            Latest Critic Loss: 1530.5286\n            Avg Critic Loss: 1794.8717\n            =========================================\n        \n\n            =========================================\n            Timesteps: 49,794 / 2,000,000 (2.4897%)\n            Episodes: 80\n            Currently: Rollout\n            Latest Reward: -299\n            Latest Avg Rewards: -285\n            Recent Change: -0.78\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0046\n            Latest Critic Loss: 1530.5286\n            Avg Critic Loss: 1794.8717\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 50,159 / 2,000,000 (2.508%)\n            Episodes: 81\n            Currently: Rollout\n            Latest Reward: -193\n            Latest Avg Rewards: -284\n            Recent Change: -0.83\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0046\n            Latest Critic Loss: 1530.5286\n            Avg Critic Loss: 1794.8717\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 50,229 / 2,000,000 (2.5114%)\n            Episodes: 82\n            Currently: Rollout\n            Latest Reward: -127\n            Latest Avg Rewards: -282\n            Recent Change: -0.94\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0046\n            Latest Critic Loss: 1530.5286\n            Avg Critic Loss: 1794.8717\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 50,979 / 2,000,000 (2.5489%)\n            Episodes: 83\n            Currently: Rollout\n            Latest Reward: -387\n            Latest Avg Rewards: -283\n            Recent Change: -0.82\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0046\n            Latest Critic Loss: 1530.5286\n            Avg Critic Loss: 1794.8717\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 51,729 / 2,000,000 (2.5864%)\n            Episodes: 84\n            Currently: Rollout\n            Latest Reward: -292\n            Latest Avg Rewards: -283\n            Recent Change: -0.78\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0046\n            Latest Critic Loss: 1530.5286\n            Avg Critic Loss: 1794.8717\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 52,479 / 2,000,000 (2.6239%)\n            Episodes: 85\n            Currently: Rollout\n            Latest Reward: -355\n            Latest Avg Rewards: -284\n            Recent Change: -0.69\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0046\n            Latest Critic Loss: 1530.5286\n            Avg Critic Loss: 1794.8717\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 53,229 / 2,000,000 (2.6614%)\n            Episodes: 86\n            Currently: Rollout\n            Latest Reward: -249\n            Latest Avg Rewards: -284\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0046\n            Latest Critic Loss: 1530.5286\n            Avg Critic Loss: 1794.8717\n            =========================================\n        \n\n            =========================================\n            Timesteps: 53,979 / 2,000,000 (2.6989%)\n            Episodes: 87\n            Currently: Rollout\n            Latest Reward: -344\n            Latest Avg Rewards: -285\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0046\n            Latest Critic Loss: 1530.5286\n            Avg Critic Loss: 1794.8717\n            =========================================\n        \n\n            =========================================\n            Timesteps: 53,979 / 2,000,000 (2.6989%)\n            Episodes: 87\n            Currently: Training cycle 1/5\n            Latest Reward: -344\n            Latest Avg Rewards: -285\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0046\n            Latest Critic Loss: 1530.5286\n            Avg Critic Loss: 1794.8717\n            =========================================\n        \n\n            =========================================\n            Timesteps: 53,979 / 2,000,000 (2.6989%)\n            Episodes: 87\n            Currently: Training cycle 2/5\n            Latest Reward: -344\n            Latest Avg Rewards: -285\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0045\n            Latest Critic Loss: 1556.6439\n            Avg Critic Loss: 1789.6928\n            =========================================\n        \n\n            =========================================\n            Timesteps: 53,979 / 2,000,000 (2.6989%)\n            Episodes: 87\n            Currently: Training cycle 3/5\n            Latest Reward: -344\n            Latest Avg Rewards: -285\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0044\n            Latest Critic Loss: 1554.7421\n            Avg Critic Loss: 1784.6938\n            =========================================\n        \n\n            =========================================\n            Timesteps: 53,979 / 2,000,000 (2.6989%)\n            Episodes: 87\n            Currently: Training cycle 4/5\n            Latest Reward: -344\n            Latest Avg Rewards: -285\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0006\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0043\n            Latest Critic Loss: 1552.755\n            Avg Critic Loss: 1779.8618\n            =========================================\n        \n\n            =========================================\n            Timesteps: 53,979 / 2,000,000 (2.6989%)\n            Episodes: 87\n            Currently: Training cycle 5/5\n            Latest Reward: -344\n            Latest Avg Rewards: -285\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0042\n            Latest Critic Loss: 1550.6829\n            Avg Critic Loss: 1775.1847\n            =========================================\n        \n\n            =========================================\n            Timesteps: 53,979 / 2,000,000 (2.6989%)\n            Episodes: 87\n            Currently: Saving\n            Latest Reward: -344\n            Latest Avg Rewards: -285\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0042\n            Latest Critic Loss: 1548.515\n            Avg Critic Loss: 1770.6513\n            =========================================\n        \n/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n  return _methods._mean(a, axis=axis, dtype=dtype,\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 54,729 / 2,000,000 (2.7365%)\n            Episodes: 88\n            Currently: Rollout\n            Latest Reward: -254\n            Latest Avg Rewards: -284\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0042\n            Latest Critic Loss: 1548.515\n            Avg Critic Loss: 1770.6513\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 55,479 / 2,000,000 (2.774%)\n            Episodes: 89\n            Currently: Rollout\n            Latest Reward: -209\n            Latest Avg Rewards: -283\n            Recent Change: -0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0042\n            Latest Critic Loss: 1548.515\n            Avg Critic Loss: 1770.6513\n            =========================================\n        \n\n            =========================================\n            Timesteps: 56,229 / 2,000,000 (2.8115%)\n            Episodes: 90\n            Currently: Rollout\n            Latest Reward: -298\n            Latest Avg Rewards: -284\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0042\n            Latest Critic Loss: 1548.515\n            Avg Critic Loss: 1770.6513\n            =========================================\n        \n\n            =========================================\n            Timesteps: 56,979 / 2,000,000 (2.849%)\n            Episodes: 91\n            Currently: Rollout\n            Latest Reward: -259\n            Latest Avg Rewards: -283\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0042\n            Latest Critic Loss: 1548.515\n            Avg Critic Loss: 1770.6513\n            =========================================\n        \n\n            =========================================\n            Timesteps: 57,729 / 2,000,000 (2.8864%)\n            Episodes: 92\n            Currently: Rollout\n            Latest Reward: -445\n            Latest Avg Rewards: -285\n            Recent Change: -0.49\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0042\n            Latest Critic Loss: 1548.515\n            Avg Critic Loss: 1770.6513\n            =========================================\n        \n\n            =========================================\n            Timesteps: 58,479 / 2,000,000 (2.924%)\n            Episodes: 93\n            Currently: Rollout\n            Latest Reward: -220\n            Latest Avg Rewards: -284\n            Recent Change: -0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0042\n            Latest Critic Loss: 1548.515\n            Avg Critic Loss: 1770.6513\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 59,098 / 2,000,000 (2.9549%)\n            Episodes: 94\n            Currently: Rollout\n            Latest Reward: -360\n            Latest Avg Rewards: -285\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0042\n            Latest Critic Loss: 1548.515\n            Avg Critic Loss: 1770.6513\n            =========================================\n        \n\n            =========================================\n            Timesteps: 59,098 / 2,000,000 (2.9549%)\n            Episodes: 94\n            Currently: Training cycle 1/5\n            Latest Reward: -360\n            Latest Avg Rewards: -285\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0042\n            Latest Critic Loss: 1548.515\n            Avg Critic Loss: 1770.6513\n            =========================================\n        \n\n            =========================================\n            Timesteps: 59,098 / 2,000,000 (2.9549%)\n            Episodes: 94\n            Currently: Training cycle 2/5\n            Latest Reward: -360\n            Latest Avg Rewards: -285\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0041\n            Latest Critic Loss: 1368.0822\n            Avg Critic Loss: 1762.7578\n            =========================================\n        \n\n            =========================================\n            Timesteps: 59,098 / 2,000,000 (2.9549%)\n            Episodes: 94\n            Currently: Training cycle 3/5\n            Latest Reward: -360\n            Latest Avg Rewards: -285\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.004\n            Latest Critic Loss: 1365.9095\n            Avg Critic Loss: 1755.1261\n            =========================================\n        \n\n            =========================================\n            Timesteps: 59,098 / 2,000,000 (2.9549%)\n            Episodes: 94\n            Currently: Training cycle 4/5\n            Latest Reward: -360\n            Latest Avg Rewards: -285\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.004\n            Latest Critic Loss: 1363.6519\n            Avg Critic Loss: 1747.7398\n            =========================================\n        \n\n            =========================================\n            Timesteps: 59,098 / 2,000,000 (2.9549%)\n            Episodes: 94\n            Currently: Training cycle 5/5\n            Latest Reward: -360\n            Latest Avg Rewards: -285\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0005\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0039\n            Latest Critic Loss: 1361.3052\n            Avg Critic Loss: 1740.5836\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 59,848 / 2,000,000 (2.9924%)\n            Episodes: 95\n            Currently: Rollout\n            Latest Reward: -230\n            Latest Avg Rewards: -285\n            Recent Change: -0.48\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0038\n            Latest Critic Loss: 1358.8687\n            Avg Critic Loss: 1733.6433\n            =========================================\n        \n\n            =========================================\n            Timesteps: 60,598 / 2,000,000 (3.0299%)\n            Episodes: 96\n            Currently: Rollout\n            Latest Reward: -203\n            Latest Avg Rewards: -284\n            Recent Change: -0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0038\n            Latest Critic Loss: 1358.8687\n            Avg Critic Loss: 1733.6433\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 60,882 / 2,000,000 (3.0441%)\n            Episodes: 97\n            Currently: Rollout\n            Latest Reward: -186\n            Latest Avg Rewards: -283\n            Recent Change: -0.56\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0038\n            Latest Critic Loss: 1358.8687\n            Avg Critic Loss: 1733.6433\n            =========================================\n        \n\n            =========================================\n            Timesteps: 61,632 / 2,000,000 (3.0816%)\n            Episodes: 98\n            Currently: Rollout\n            Latest Reward: -568\n            Latest Avg Rewards: -286\n            Recent Change: -0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0038\n            Latest Critic Loss: 1358.8687\n            Avg Critic Loss: 1733.6433\n            =========================================\n        \n\n            =========================================\n            Timesteps: 62,382 / 2,000,000 (3.1191%)\n            Episodes: 99\n            Currently: Rollout\n            Latest Reward: -384\n            Latest Avg Rewards: -287\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0038\n            Latest Critic Loss: 1358.8687\n            Avg Critic Loss: 1733.6433\n            =========================================\n        \n\n            =========================================\n            Timesteps: 63,132 / 2,000,000 (3.1566%)\n            Episodes: 100\n            Currently: Rollout\n            Latest Reward: -455\n            Latest Avg Rewards: -288\n            Recent Change: -0.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0038\n            Latest Critic Loss: 1358.8687\n            Avg Critic Loss: 1733.6433\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 63,882 / 2,000,000 (3.1941%)\n            Episodes: 101\n            Currently: Rollout\n            Latest Reward: -283\n            Latest Avg Rewards: -288\n            Recent Change: -0.2\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0038\n            Latest Critic Loss: 1358.8687\n            Avg Critic Loss: 1733.6433\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 64,632 / 2,000,000 (3.2316%)\n            Episodes: 102\n            Currently: Rollout\n            Latest Reward: -288\n            Latest Avg Rewards: -289\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0038\n            Latest Critic Loss: 1358.8687\n            Avg Critic Loss: 1733.6433\n            =========================================\n        \n\n            =========================================\n            Timesteps: 64,632 / 2,000,000 (3.2316%)\n            Episodes: 102\n            Currently: Training cycle 1/5\n            Latest Reward: -288\n            Latest Avg Rewards: -289\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0038\n            Latest Critic Loss: 1358.8687\n            Avg Critic Loss: 1733.6433\n            =========================================\n        \n\n            =========================================\n            Timesteps: 64,632 / 2,000,000 (3.2316%)\n            Episodes: 102\n            Currently: Training cycle 2/5\n            Latest Reward: -288\n            Latest Avg Rewards: -289\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0038\n            Latest Critic Loss: 2149.5425\n            Avg Critic Loss: 1741.0701\n            =========================================\n        \n\n            =========================================\n            Timesteps: 64,632 / 2,000,000 (3.2316%)\n            Episodes: 102\n            Currently: Training cycle 3/5\n            Latest Reward: -288\n            Latest Avg Rewards: -289\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0037\n            Latest Critic Loss: 2146.2771\n            Avg Critic Loss: 1748.179\n            =========================================\n        \n\n            =========================================\n            Timesteps: 64,632 / 2,000,000 (3.2316%)\n            Episodes: 102\n            Currently: Training cycle 4/5\n            Latest Reward: -288\n            Latest Avg Rewards: -289\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0037\n            Latest Critic Loss: 2142.8467\n            Avg Critic Loss: 1754.9836\n            =========================================\n        \n\n            =========================================\n            Timesteps: 64,632 / 2,000,000 (3.2316%)\n            Episodes: 102\n            Currently: Training cycle 5/5\n            Latest Reward: -288\n            Latest Avg Rewards: -289\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0036\n            Latest Critic Loss: 2139.2463\n            Avg Critic Loss: 1761.4965\n            =========================================\n        \n\n            =========================================\n            Timesteps: 65,382 / 2,000,000 (3.2691%)\n            Episodes: 103\n            Currently: Rollout\n            Latest Reward: -284\n            Latest Avg Rewards: -287\n            Recent Change: -0.13\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0035\n            Latest Critic Loss: 2135.4829\n            Avg Critic Loss: 1767.7296\n            =========================================\n        \n\n            =========================================\n            Timesteps: 66,132 / 2,000,000 (3.3066%)\n            Episodes: 104\n            Currently: Rollout\n            Latest Reward: -439\n            Latest Avg Rewards: -287\n            Recent Change: 0.07\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0035\n            Latest Critic Loss: 2135.4829\n            Avg Critic Loss: 1767.7296\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 66,882 / 2,000,000 (3.3441%)\n            Episodes: 105\n            Currently: Rollout\n            Latest Reward: -260\n            Latest Avg Rewards: -285\n            Recent Change: 0.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0035\n            Latest Critic Loss: 2135.4829\n            Avg Critic Loss: 1767.7296\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 67,632 / 2,000,000 (3.3816%)\n            Episodes: 106\n            Currently: Rollout\n            Latest Reward: -265\n            Latest Avg Rewards: -286\n            Recent Change: 0.06\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0035\n            Latest Critic Loss: 2135.4829\n            Avg Critic Loss: 1767.7296\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 68,382 / 2,000,000 (3.4191%)\n            Episodes: 107\n            Currently: Rollout\n            Latest Reward: -278\n            Latest Avg Rewards: -285\n            Recent Change: 0.09\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0035\n            Latest Critic Loss: 2135.4829\n            Avg Critic Loss: 1767.7296\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 69,132 / 2,000,000 (3.4566%)\n            Episodes: 108\n            Currently: Rollout\n            Latest Reward: -502\n            Latest Avg Rewards: -288\n            Recent Change: 0.2\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0035\n            Latest Critic Loss: 2135.4829\n            Avg Critic Loss: 1767.7296\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 69,882 / 2,000,000 (3.4941%)\n            Episodes: 109\n            Currently: Rollout\n            Latest Reward: -452\n            Latest Avg Rewards: -290\n            Recent Change: 0.28\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0035\n            Latest Critic Loss: 2135.4829\n            Avg Critic Loss: 1767.7296\n            =========================================\n        \n\n            =========================================\n            Timesteps: 69,882 / 2,000,000 (3.4941%)\n            Episodes: 109\n            Currently: Training cycle 1/5\n            Latest Reward: -452\n            Latest Avg Rewards: -290\n            Recent Change: 0.28\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0035\n            Latest Critic Loss: 2135.4829\n            Avg Critic Loss: 1767.7296\n            =========================================\n        \n\n            =========================================\n            Timesteps: 69,882 / 2,000,000 (3.4941%)\n            Episodes: 109\n            Currently: Training cycle 2/5\n            Latest Reward: -452\n            Latest Avg Rewards: -290\n            Recent Change: 0.28\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0035\n            Latest Critic Loss: 1871.769\n            Avg Critic Loss: 1769.4352\n            =========================================\n        \n\n            =========================================\n            Timesteps: 69,882 / 2,000,000 (3.4941%)\n            Episodes: 109\n            Currently: Training cycle 3/5\n            Latest Reward: -452\n            Latest Avg Rewards: -290\n            Recent Change: 0.28\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0004\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0034\n            Latest Critic Loss: 1867.8192\n            Avg Critic Loss: 1771.022\n            =========================================\n        \n\n            =========================================\n            Timesteps: 69,882 / 2,000,000 (3.4941%)\n            Episodes: 109\n            Currently: Training cycle 4/5\n            Latest Reward: -452\n            Latest Avg Rewards: -290\n            Recent Change: 0.28\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0034\n            Latest Critic Loss: 1863.6876\n            Avg Critic Loss: 1772.4929\n            =========================================\n        \n\n            =========================================\n            Timesteps: 69,882 / 2,000,000 (3.4941%)\n            Episodes: 109\n            Currently: Training cycle 5/5\n            Latest Reward: -452\n            Latest Avg Rewards: -290\n            Recent Change: 0.28\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0033\n            Latest Critic Loss: 1859.3688\n            Avg Critic Loss: 1773.8503\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 70,632 / 2,000,000 (3.5316%)\n            Episodes: 110\n            Currently: Rollout\n            Latest Reward: -336\n            Latest Avg Rewards: -288\n            Recent Change: 0.42\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0033\n            Latest Critic Loss: 1854.8658\n            Avg Critic Loss: 1775.0967\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 71,382 / 2,000,000 (3.5691%)\n            Episodes: 111\n            Currently: Rollout\n            Latest Reward: -311\n            Latest Avg Rewards: -289\n            Recent Change: 0.4\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0033\n            Latest Critic Loss: 1854.8658\n            Avg Critic Loss: 1775.0967\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 72,132 / 2,000,000 (3.6066%)\n            Episodes: 112\n            Currently: Rollout\n            Latest Reward: -309\n            Latest Avg Rewards: -290\n            Recent Change: 0.36\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0033\n            Latest Critic Loss: 1854.8658\n            Avg Critic Loss: 1775.0967\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 72,686 / 2,000,000 (3.6343%)\n            Episodes: 113\n            Currently: Rollout\n            Latest Reward: -294\n            Latest Avg Rewards: -290\n            Recent Change: 0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0033\n            Latest Critic Loss: 1854.8658\n            Avg Critic Loss: 1775.0967\n            =========================================\n        \n\n            =========================================\n            Timesteps: 73,436 / 2,000,000 (3.6718%)\n            Episodes: 114\n            Currently: Rollout\n            Latest Reward: -212\n            Latest Avg Rewards: -289\n            Recent Change: 0.34\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0033\n            Latest Critic Loss: 1854.8658\n            Avg Critic Loss: 1775.0967\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 73,557 / 2,000,000 (3.6778%)\n            Episodes: 115\n            Currently: Rollout\n            Latest Reward: -140\n            Latest Avg Rewards: -288\n            Recent Change: 0.24\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0033\n            Latest Critic Loss: 1854.8658\n            Avg Critic Loss: 1775.0967\n            =========================================\n        \n\n            =========================================\n            Timesteps: 74,307 / 2,000,000 (3.7153%)\n            Episodes: 116\n            Currently: Rollout\n            Latest Reward: -327\n            Latest Avg Rewards: -288\n            Recent Change: 0.25\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0033\n            Latest Critic Loss: 1854.8658\n            Avg Critic Loss: 1775.0967\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 75,057 / 2,000,000 (3.7529%)\n            Episodes: 117\n            Currently: Rollout\n            Latest Reward: -376\n            Latest Avg Rewards: -288\n            Recent Change: 0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0033\n            Latest Critic Loss: 1854.8658\n            Avg Critic Loss: 1775.0967\n            =========================================\n        \n\n            =========================================\n            Timesteps: 75,057 / 2,000,000 (3.7529%)\n            Episodes: 117\n            Currently: Training cycle 1/5\n            Latest Reward: -376\n            Latest Avg Rewards: -288\n            Recent Change: 0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0003\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0033\n            Latest Critic Loss: 1854.8658\n            Avg Critic Loss: 1775.0967\n            =========================================\n        \n\n            =========================================\n            Timesteps: 75,057 / 2,000,000 (3.7529%)\n            Episodes: 117\n            Currently: Training cycle 2/5\n            Latest Reward: -376\n            Latest Avg Rewards: -288\n            Recent Change: 0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0032\n            Latest Critic Loss: 1415.6111\n            Avg Critic Loss: 1769.65\n            =========================================\n        \n\n            =========================================\n            Timesteps: 75,057 / 2,000,000 (3.7529%)\n            Episodes: 117\n            Currently: Training cycle 3/5\n            Latest Reward: -376\n            Latest Avg Rewards: -288\n            Recent Change: 0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0032\n            Latest Critic Loss: 1411.296\n            Avg Critic Loss: 1764.3014\n            =========================================\n        \n\n            =========================================\n            Timesteps: 75,057 / 2,000,000 (3.7529%)\n            Episodes: 117\n            Currently: Training cycle 4/5\n            Latest Reward: -376\n            Latest Avg Rewards: -288\n            Recent Change: 0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0032\n            Latest Critic Loss: 1406.8301\n            Avg Critic Loss: 1759.0445\n            =========================================\n        \n\n            =========================================\n            Timesteps: 75,057 / 2,000,000 (3.7529%)\n            Episodes: 117\n            Currently: Training cycle 5/5\n            Latest Reward: -376\n            Latest Avg Rewards: -288\n            Recent Change: 0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0031\n            Latest Critic Loss: 1402.2094\n            Avg Critic Loss: 1753.8729\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 75,807 / 2,000,000 (3.7904%)\n            Episodes: 118\n            Currently: Rollout\n            Latest Reward: -298\n            Latest Avg Rewards: -288\n            Recent Change: 0.4\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0031\n            Latest Critic Loss: 1397.4285\n            Avg Critic Loss: 1748.7809\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 incorrectly sorted into sorting_one\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 76,557 / 2,000,000 (3.8279%)\n            Episodes: 119\n            Currently: Rollout\n            Latest Reward: -377\n            Latest Avg Rewards: -289\n            Recent Change: 0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0031\n            Latest Critic Loss: 1397.4285\n            Avg Critic Loss: 1748.7809\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 77,307 / 2,000,000 (3.8653%)\n            Episodes: 120\n            Currently: Rollout\n            Latest Reward: -448\n            Latest Avg Rewards: -289\n            Recent Change: 0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0031\n            Latest Critic Loss: 1397.4285\n            Avg Critic Loss: 1748.7809\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 78,057 / 2,000,000 (3.9028%)\n            Episodes: 121\n            Currently: Rollout\n            Latest Reward: -405\n            Latest Avg Rewards: -289\n            Recent Change: 0.78\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0031\n            Latest Critic Loss: 1397.4285\n            Avg Critic Loss: 1748.7809\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 78,807 / 2,000,000 (3.9404%)\n            Episodes: 122\n            Currently: Rollout\n            Latest Reward: -263\n            Latest Avg Rewards: -289\n            Recent Change: 0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0031\n            Latest Critic Loss: 1397.4285\n            Avg Critic Loss: 1748.7809\n            =========================================\n        \n\n            =========================================\n            Timesteps: 79,557 / 2,000,000 (3.9779%)\n            Episodes: 123\n            Currently: Rollout\n            Latest Reward: -218\n            Latest Avg Rewards: -289\n            Recent Change: 0.68\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0031\n            Latest Critic Loss: 1397.4285\n            Avg Critic Loss: 1748.7809\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 80,307 / 2,000,000 (4.0153%)\n            Episodes: 124\n            Currently: Rollout\n            Latest Reward: -443\n            Latest Avg Rewards: -290\n            Recent Change: 0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0031\n            Latest Critic Loss: 1397.4285\n            Avg Critic Loss: 1748.7809\n            =========================================\n        \n\n            =========================================\n            Timesteps: 80,307 / 2,000,000 (4.0153%)\n            Episodes: 124\n            Currently: Training cycle 1/5\n            Latest Reward: -443\n            Latest Avg Rewards: -290\n            Recent Change: 0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0031\n            Latest Critic Loss: 1397.4285\n            Avg Critic Loss: 1748.7809\n            =========================================\n        \n\n            =========================================\n            Timesteps: 80,307 / 2,000,000 (4.0153%)\n            Episodes: 124\n            Currently: Training cycle 2/5\n            Latest Reward: -443\n            Latest Avg Rewards: -290\n            Recent Change: 0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.003\n            Latest Critic Loss: 1533.5349\n            Avg Critic Loss: 1745.7492\n            =========================================\n        \n\n            =========================================\n            Timesteps: 80,307 / 2,000,000 (4.0153%)\n            Episodes: 124\n            Currently: Training cycle 3/5\n            Latest Reward: -443\n            Latest Avg Rewards: -290\n            Recent Change: 0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.003\n            Latest Critic Loss: 1528.2654\n            Avg Critic Loss: 1742.7286\n            =========================================\n        \n\n            =========================================\n            Timesteps: 80,307 / 2,000,000 (4.0153%)\n            Episodes: 124\n            Currently: Training cycle 4/5\n            Latest Reward: -443\n            Latest Avg Rewards: -290\n            Recent Change: 0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.003\n            Latest Critic Loss: 1522.8005\n            Avg Critic Loss: 1739.7159\n            =========================================\n        \n\n            =========================================\n            Timesteps: 80,307 / 2,000,000 (4.0153%)\n            Episodes: 124\n            Currently: Training cycle 5/5\n            Latest Reward: -443\n            Latest Avg Rewards: -290\n            Recent Change: 0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0029\n            Latest Critic Loss: 1517.1364\n            Avg Critic Loss: 1736.7081\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 81,057 / 2,000,000 (4.0529%)\n            Episodes: 125\n            Currently: Rollout\n            Latest Reward: -458\n            Latest Avg Rewards: -292\n            Recent Change: 0.86\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0029\n            Latest Critic Loss: 1511.2657\n            Avg Critic Loss: 1733.7022\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 81,807 / 2,000,000 (4.0903%)\n            Episodes: 126\n            Currently: Rollout\n            Latest Reward: -521\n            Latest Avg Rewards: -294\n            Recent Change: 1.03\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0029\n            Latest Critic Loss: 1511.2657\n            Avg Critic Loss: 1733.7022\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 82,557 / 2,000,000 (4.1279%)\n            Episodes: 127\n            Currently: Rollout\n            Latest Reward: -399\n            Latest Avg Rewards: -295\n            Recent Change: 1.06\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0029\n            Latest Critic Loss: 1511.2657\n            Avg Critic Loss: 1733.7022\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 83,307 / 2,000,000 (4.1654%)\n            Episodes: 128\n            Currently: Rollout\n            Latest Reward: -320\n            Latest Avg Rewards: -297\n            Recent Change: 1.0\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0029\n            Latest Critic Loss: 1511.2657\n            Avg Critic Loss: 1733.7022\n            =========================================\n        \n\n            =========================================\n            Timesteps: 84,057 / 2,000,000 (4.2029%)\n            Episodes: 129\n            Currently: Rollout\n            Latest Reward: -261\n            Latest Avg Rewards: -295\n            Recent Change: 1.08\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0029\n            Latest Critic Loss: 1511.2657\n            Avg Critic Loss: 1733.7022\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 84,807 / 2,000,000 (4.2403%)\n            Episodes: 130\n            Currently: Rollout\n            Latest Reward: -299\n            Latest Avg Rewards: -293\n            Recent Change: 1.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0029\n            Latest Critic Loss: 1511.2657\n            Avg Critic Loss: 1733.7022\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 85,557 / 2,000,000 (4.2778%)\n            Episodes: 131\n            Currently: Rollout\n            Latest Reward: -295\n            Latest Avg Rewards: -293\n            Recent Change: 1.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0029\n            Latest Critic Loss: 1511.2657\n            Avg Critic Loss: 1733.7022\n            =========================================\n        \n\n            =========================================\n            Timesteps: 85,557 / 2,000,000 (4.2778%)\n            Episodes: 131\n            Currently: Training cycle 1/5\n            Latest Reward: -295\n            Latest Avg Rewards: -293\n            Recent Change: 1.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0002\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0029\n            Latest Critic Loss: 1511.2657\n            Avg Critic Loss: 1733.7022\n            =========================================\n        \n\n            =========================================\n            Timesteps: 85,557 / 2,000,000 (4.2778%)\n            Episodes: 131\n            Currently: Training cycle 2/5\n            Latest Reward: -295\n            Latest Avg Rewards: -293\n            Recent Change: 1.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0028\n            Latest Critic Loss: 1978.4659\n            Avg Critic Loss: 1736.9228\n            =========================================\n        \n\n            =========================================\n            Timesteps: 85,557 / 2,000,000 (4.2778%)\n            Episodes: 131\n            Currently: Training cycle 3/5\n            Latest Reward: -295\n            Latest Avg Rewards: -293\n            Recent Change: 1.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0028\n            Latest Critic Loss: 1971.0201\n            Avg Critic Loss: 1739.963\n            =========================================\n        \n\n            =========================================\n            Timesteps: 85,557 / 2,000,000 (4.2778%)\n            Episodes: 131\n            Currently: Training cycle 4/5\n            Latest Reward: -295\n            Latest Avg Rewards: -293\n            Recent Change: 1.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0028\n            Latest Critic Loss: 1963.2308\n            Avg Critic Loss: 1742.8254\n            =========================================\n        \n\n            =========================================\n            Timesteps: 85,557 / 2,000,000 (4.2778%)\n            Episodes: 131\n            Currently: Training cycle 5/5\n            Latest Reward: -295\n            Latest Avg Rewards: -293\n            Recent Change: 1.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0027\n            Latest Critic Loss: 1955.0992\n            Avg Critic Loss: 1745.5124\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 86,307 / 2,000,000 (4.3153%)\n            Episodes: 132\n            Currently: Rollout\n            Latest Reward: -498\n            Latest Avg Rewards: -297\n            Recent Change: 1.22\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0027\n            Latest Critic Loss: 1946.6241\n            Avg Critic Loss: 1748.0263\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 87,057 / 2,000,000 (4.3529%)\n            Episodes: 133\n            Currently: Rollout\n            Latest Reward: -256\n            Latest Avg Rewards: -296\n            Recent Change: 1.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0027\n            Latest Critic Loss: 1946.6241\n            Avg Critic Loss: 1748.0263\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 87,211 / 2,000,000 (4.3605%)\n            Episodes: 134\n            Currently: Rollout\n            Latest Reward: -156\n            Latest Avg Rewards: -295\n            Recent Change: 1.08\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0027\n            Latest Critic Loss: 1946.6241\n            Avg Critic Loss: 1748.0263\n            =========================================\n        \n\n            =========================================\n            Timesteps: 87,961 / 2,000,000 (4.398%)\n            Episodes: 135\n            Currently: Rollout\n            Latest Reward: -350\n            Latest Avg Rewards: -296\n            Recent Change: 1.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0027\n            Latest Critic Loss: 1946.6241\n            Avg Critic Loss: 1748.0263\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 88,711 / 2,000,000 (4.4356%)\n            Episodes: 136\n            Currently: Rollout\n            Latest Reward: -386\n            Latest Avg Rewards: -299\n            Recent Change: 1.05\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0027\n            Latest Critic Loss: 1946.6241\n            Avg Critic Loss: 1748.0263\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 89,461 / 2,000,000 (4.473%)\n            Episodes: 137\n            Currently: Rollout\n            Latest Reward: -386\n            Latest Avg Rewards: -298\n            Recent Change: 1.18\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0027\n            Latest Critic Loss: 1946.6241\n            Avg Critic Loss: 1748.0263\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 90,211 / 2,000,000 (4.5106%)\n            Episodes: 138\n            Currently: Rollout\n            Latest Reward: -320\n            Latest Avg Rewards: -300\n            Recent Change: 1.08\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0027\n            Latest Critic Loss: 1946.6241\n            Avg Critic Loss: 1748.0263\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 90,961 / 2,000,000 (4.548%)\n            Episodes: 139\n            Currently: Rollout\n            Latest Reward: -180\n            Latest Avg Rewards: -300\n            Recent Change: 0.97\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0027\n            Latest Critic Loss: 1946.6241\n            Avg Critic Loss: 1748.0263\n            =========================================\n        \n\n            =========================================\n            Timesteps: 90,961 / 2,000,000 (4.548%)\n            Episodes: 139\n            Currently: Training cycle 1/5\n            Latest Reward: -180\n            Latest Avg Rewards: -300\n            Recent Change: 0.97\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0027\n            Latest Critic Loss: 1946.6241\n            Avg Critic Loss: 1748.0263\n            =========================================\n        \n\n            =========================================\n            Timesteps: 90,961 / 2,000,000 (4.548%)\n            Episodes: 139\n            Currently: Training cycle 2/5\n            Latest Reward: -180\n            Latest Avg Rewards: -300\n            Recent Change: 0.97\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0027\n            Latest Critic Loss: 1735.3615\n            Avg Critic Loss: 1747.87\n            =========================================\n        \n\n            =========================================\n            Timesteps: 90,961 / 2,000,000 (4.548%)\n            Episodes: 139\n            Currently: Training cycle 3/5\n            Latest Reward: -180\n            Latest Avg Rewards: -300\n            Recent Change: 0.97\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1726.8997\n            Avg Critic Loss: 1747.6142\n            =========================================\n        \n\n            =========================================\n            Timesteps: 90,961 / 2,000,000 (4.548%)\n            Episodes: 139\n            Currently: Training cycle 4/5\n            Latest Reward: -180\n            Latest Avg Rewards: -300\n            Recent Change: 0.97\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1718.1464\n            Avg Critic Loss: 1747.2592\n            =========================================\n        \n\n            =========================================\n            Timesteps: 90,961 / 2,000,000 (4.548%)\n            Episodes: 139\n            Currently: Training cycle 5/5\n            Latest Reward: -180\n            Latest Avg Rewards: -300\n            Recent Change: 0.97\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1709.0924\n            Avg Critic Loss: 1746.8048\n            =========================================\n        \n\n            =========================================\n            Timesteps: 91,711 / 2,000,000 (4.5856%)\n            Episodes: 140\n            Currently: Rollout\n            Latest Reward: -205\n            Latest Avg Rewards: -300\n            Recent Change: 0.82\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1699.731\n            Avg Critic Loss: 1746.251\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 92,461 / 2,000,000 (4.6231%)\n            Episodes: 141\n            Currently: Rollout\n            Latest Reward: -257\n            Latest Avg Rewards: -302\n            Recent Change: 0.68\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1699.731\n            Avg Critic Loss: 1746.251\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 93,211 / 2,000,000 (4.6605%)\n            Episodes: 142\n            Currently: Rollout\n            Latest Reward: -371\n            Latest Avg Rewards: -302\n            Recent Change: 0.73\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1699.731\n            Avg Critic Loss: 1746.251\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 93,439 / 2,000,000 (4.6719%)\n            Episodes: 143\n            Currently: Rollout\n            Latest Reward: -177\n            Latest Avg Rewards: -299\n            Recent Change: 0.8\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1699.731\n            Avg Critic Loss: 1746.251\n            =========================================\n        \n\n            =========================================\n            Timesteps: 94,189 / 2,000,000 (4.7094%)\n            Episodes: 144\n            Currently: Rollout\n            Latest Reward: -438\n            Latest Avg Rewards: -302\n            Recent Change: 0.79\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1699.731\n            Avg Critic Loss: 1746.251\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 94,939 / 2,000,000 (4.747%)\n            Episodes: 145\n            Currently: Rollout\n            Latest Reward: -182\n            Latest Avg Rewards: -300\n            Recent Change: 0.75\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1699.731\n            Avg Critic Loss: 1746.251\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 95,120 / 2,000,000 (4.756%)\n            Episodes: 146\n            Currently: Rollout\n            Latest Reward: -170\n            Latest Avg Rewards: -300\n            Recent Change: 0.61\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1699.731\n            Avg Critic Loss: 1746.251\n            =========================================\n        \n\n            =========================================\n            Timesteps: 95,870 / 2,000,000 (4.7935%)\n            Episodes: 147\n            Currently: Rollout\n            Latest Reward: -261\n            Latest Avg Rewards: -300\n            Recent Change: 0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1699.731\n            Avg Critic Loss: 1746.251\n            =========================================\n        \n\n            =========================================\n            Timesteps: 96,620 / 2,000,000 (4.831%)\n            Episodes: 148\n            Currently: Rollout\n            Latest Reward: -229\n            Latest Avg Rewards: -300\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1699.731\n            Avg Critic Loss: 1746.251\n            =========================================\n        \n\n            =========================================\n            Timesteps: 96,620 / 2,000,000 (4.831%)\n            Episodes: 148\n            Currently: Training cycle 1/5\n            Latest Reward: -229\n            Latest Avg Rewards: -300\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0026\n            Latest Critic Loss: 1699.731\n            Avg Critic Loss: 1746.251\n            =========================================\n        \n\n            =========================================\n            Timesteps: 96,620 / 2,000,000 (4.831%)\n            Episodes: 148\n            Currently: Training cycle 2/5\n            Latest Reward: -229\n            Latest Avg Rewards: -300\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0025\n            Latest Critic Loss: 1218.5449\n            Avg Critic Loss: 1740.1149\n            =========================================\n        \n\n            =========================================\n            Timesteps: 96,620 / 2,000,000 (4.831%)\n            Episodes: 148\n            Currently: Training cycle 3/5\n            Latest Reward: -229\n            Latest Avg Rewards: -300\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0025\n            Latest Critic Loss: 1210.5024\n            Avg Critic Loss: 1734.0274\n            =========================================\n        \n\n            =========================================\n            Timesteps: 96,620 / 2,000,000 (4.831%)\n            Episodes: 148\n            Currently: Training cycle 4/5\n            Latest Reward: -229\n            Latest Avg Rewards: -300\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0025\n            Latest Critic Loss: 1202.2865\n            Avg Critic Loss: 1727.9849\n            =========================================\n        \n\n            =========================================\n            Timesteps: 96,620 / 2,000,000 (4.831%)\n            Episodes: 148\n            Currently: Training cycle 5/5\n            Latest Reward: -229\n            Latest Avg Rewards: -300\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1193.8912\n            Avg Critic Loss: 1721.9838\n            =========================================\n        \n\n            =========================================\n            Timesteps: 97,370 / 2,000,000 (4.8685%)\n            Episodes: 149\n            Currently: Rollout\n            Latest Reward: -272\n            Latest Avg Rewards: -301\n            Recent Change: 0.39\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1185.3058\n            Avg Critic Loss: 1716.0207\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 98,120 / 2,000,000 (4.906%)\n            Episodes: 150\n            Currently: Rollout\n            Latest Reward: -336\n            Latest Avg Rewards: -300\n            Recent Change: 0.48\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1185.3058\n            Avg Critic Loss: 1716.0207\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 98,870 / 2,000,000 (4.9435%)\n            Episodes: 151\n            Currently: Rollout\n            Latest Reward: -338\n            Latest Avg Rewards: -301\n            Recent Change: 0.48\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1185.3058\n            Avg Critic Loss: 1716.0207\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 99,015 / 2,000,000 (4.9508%)\n            Episodes: 152\n            Currently: Rollout\n            Latest Reward: -164\n            Latest Avg Rewards: -299\n            Recent Change: 0.39\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1185.3058\n            Avg Critic Loss: 1716.0207\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 99,765 / 2,000,000 (4.9883%)\n            Episodes: 153\n            Currently: Rollout\n            Latest Reward: -299\n            Latest Avg Rewards: -301\n            Recent Change: 0.29\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1185.3058\n            Avg Critic Loss: 1716.0207\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 100,515 / 2,000,000 (5.0257%)\n            Episodes: 154\n            Currently: Rollout\n            Latest Reward: -231\n            Latest Avg Rewards: -300\n            Recent Change: 0.28\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1185.3058\n            Avg Critic Loss: 1716.0207\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 101,265 / 2,000,000 (5.0633%)\n            Episodes: 155\n            Currently: Rollout\n            Latest Reward: -521\n            Latest Avg Rewards: -303\n            Recent Change: 0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1185.3058\n            Avg Critic Loss: 1716.0207\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 102,015 / 2,000,000 (5.1007%)\n            Episodes: 156\n            Currently: Rollout\n            Latest Reward: -216\n            Latest Avg Rewards: -303\n            Recent Change: 0.26\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1185.3058\n            Avg Critic Loss: 1716.0207\n            =========================================\n        \n\n            =========================================\n            Timesteps: 102,015 / 2,000,000 (5.1007%)\n            Episodes: 156\n            Currently: Training cycle 1/5\n            Latest Reward: -216\n            Latest Avg Rewards: -303\n            Recent Change: 0.26\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1185.3058\n            Avg Critic Loss: 1716.0207\n            =========================================\n        \n\n            =========================================\n            Timesteps: 102,015 / 2,000,000 (5.1007%)\n            Episodes: 156\n            Currently: Training cycle 2/5\n            Latest Reward: -216\n            Latest Avg Rewards: -303\n            Recent Change: 0.26\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1506.9479\n            Avg Critic Loss: 1713.7232\n            =========================================\n        \n\n            =========================================\n            Timesteps: 102,015 / 2,000,000 (5.1007%)\n            Episodes: 156\n            Currently: Training cycle 3/5\n            Latest Reward: -216\n            Latest Avg Rewards: -303\n            Recent Change: 0.26\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0024\n            Latest Critic Loss: 1496.7181\n            Avg Critic Loss: 1711.3645\n            =========================================\n        \n\n            =========================================\n            Timesteps: 102,015 / 2,000,000 (5.1007%)\n            Episodes: 156\n            Currently: Training cycle 4/5\n            Latest Reward: -216\n            Latest Avg Rewards: -303\n            Recent Change: 0.26\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1486.1562\n            Avg Critic Loss: 1708.9429\n            =========================================\n        \n\n            =========================================\n            Timesteps: 102,015 / 2,000,000 (5.1007%)\n            Episodes: 156\n            Currently: Training cycle 5/5\n            Latest Reward: -216\n            Latest Avg Rewards: -303\n            Recent Change: 0.26\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1475.262\n            Avg Critic Loss: 1706.4569\n            =========================================\n        \n\n            =========================================\n            Timesteps: 102,765 / 2,000,000 (5.1382%)\n            Episodes: 157\n            Currently: Rollout\n            Latest Reward: -333\n            Latest Avg Rewards: -303\n            Recent Change: 0.27\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1464.0308\n            Avg Critic Loss: 1703.9051\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 103,515 / 2,000,000 (5.1757%)\n            Episodes: 158\n            Currently: Rollout\n            Latest Reward: -418\n            Latest Avg Rewards: -305\n            Recent Change: 0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1464.0308\n            Avg Critic Loss: 1703.9051\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 103,840 / 2,000,000 (5.192%)\n            Episodes: 159\n            Currently: Rollout\n            Latest Reward: -210\n            Latest Avg Rewards: -301\n            Recent Change: 0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1464.0308\n            Avg Critic Loss: 1703.9051\n            =========================================\n        \n\n            =========================================\n            Timesteps: 104,590 / 2,000,000 (5.2295%)\n            Episodes: 160\n            Currently: Rollout\n            Latest Reward: -214\n            Latest Avg Rewards: -301\n            Recent Change: 0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1464.0308\n            Avg Critic Loss: 1703.9051\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 105,340 / 2,000,000 (5.267%)\n            Episodes: 161\n            Currently: Rollout\n            Latest Reward: -438\n            Latest Avg Rewards: -303\n            Recent Change: 0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1464.0308\n            Avg Critic Loss: 1703.9051\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 106,090 / 2,000,000 (5.3045%)\n            Episodes: 162\n            Currently: Rollout\n            Latest Reward: -287\n            Latest Avg Rewards: -303\n            Recent Change: 0.32\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1464.0308\n            Avg Critic Loss: 1703.9051\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 106,840 / 2,000,000 (5.342%)\n            Episodes: 163\n            Currently: Rollout\n            Latest Reward: -367\n            Latest Avg Rewards: -304\n            Recent Change: 0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1464.0308\n            Avg Critic Loss: 1703.9051\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 107,590 / 2,000,000 (5.3795%)\n            Episodes: 164\n            Currently: Rollout\n            Latest Reward: -234\n            Latest Avg Rewards: -303\n            Recent Change: 0.34\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1464.0308\n            Avg Critic Loss: 1703.9051\n            =========================================\n        \n\n            =========================================\n            Timesteps: 107,590 / 2,000,000 (5.3795%)\n            Episodes: 164\n            Currently: Training cycle 1/5\n            Latest Reward: -234\n            Latest Avg Rewards: -303\n            Recent Change: 0.34\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1464.0308\n            Avg Critic Loss: 1703.9051\n            =========================================\n        \n\n            =========================================\n            Timesteps: 107,590 / 2,000,000 (5.3795%)\n            Episodes: 164\n            Currently: Training cycle 2/5\n            Latest Reward: -234\n            Latest Avg Rewards: -303\n            Recent Change: 0.34\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0023\n            Latest Critic Loss: 1424.1744\n            Avg Critic Loss: 1700.9912\n            =========================================\n        \n\n            =========================================\n            Timesteps: 107,590 / 2,000,000 (5.3795%)\n            Episodes: 164\n            Currently: Training cycle 3/5\n            Latest Reward: -234\n            Latest Avg Rewards: -303\n            Recent Change: 0.34\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1411.71\n            Avg Critic Loss: 1698.0089\n            =========================================\n        \n\n            =========================================\n            Timesteps: 107,590 / 2,000,000 (5.3795%)\n            Episodes: 164\n            Currently: Training cycle 4/5\n            Latest Reward: -234\n            Latest Avg Rewards: -303\n            Recent Change: 0.34\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1398.8412\n            Avg Critic Loss: 1694.9562\n            =========================================\n        \n\n            =========================================\n            Timesteps: 107,590 / 2,000,000 (5.3795%)\n            Episodes: 164\n            Currently: Training cycle 5/5\n            Latest Reward: -234\n            Latest Avg Rewards: -303\n            Recent Change: 0.34\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1385.5725\n            Avg Critic Loss: 1691.8311\n            =========================================\n        \n\n            =========================================\n            Timesteps: 107,590 / 2,000,000 (5.3795%)\n            Episodes: 164\n            Currently: Saving\n            Latest Reward: -234\n            Latest Avg Rewards: -303\n            Recent Change: 0.34\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1371.9062\n            Avg Critic Loss: 1688.6319\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 108,340 / 2,000,000 (5.417%)\n            Episodes: 165\n            Currently: Rollout\n            Latest Reward: -305\n            Latest Avg Rewards: -303\n            Recent Change: 0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1371.9062\n            Avg Critic Loss: 1688.6319\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 109,090 / 2,000,000 (5.4545%)\n            Episodes: 166\n            Currently: Rollout\n            Latest Reward: -288\n            Latest Avg Rewards: -303\n            Recent Change: 0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1371.9062\n            Avg Critic Loss: 1688.6319\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 109,840 / 2,000,000 (5.492%)\n            Episodes: 167\n            Currently: Rollout\n            Latest Reward: -343\n            Latest Avg Rewards: -305\n            Recent Change: 0.26\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1371.9062\n            Avg Critic Loss: 1688.6319\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 110,590 / 2,000,000 (5.5295%)\n            Episodes: 168\n            Currently: Rollout\n            Latest Reward: -241\n            Latest Avg Rewards: -304\n            Recent Change: 0.25\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1371.9062\n            Avg Critic Loss: 1688.6319\n            =========================================\n        \n\n            =========================================\n            Timesteps: 111,340 / 2,000,000 (5.567%)\n            Episodes: 169\n            Currently: Rollout\n            Latest Reward: -325\n            Latest Avg Rewards: -306\n            Recent Change: 0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1371.9062\n            Avg Critic Loss: 1688.6319\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 111,410 / 2,000,000 (5.5705%)\n            Episodes: 170\n            Currently: Rollout\n            Latest Reward: -127\n            Latest Avg Rewards: -305\n            Recent Change: -0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1371.9062\n            Avg Critic Loss: 1688.6319\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 112,160 / 2,000,000 (5.608%)\n            Episodes: 171\n            Currently: Rollout\n            Latest Reward: -304\n            Latest Avg Rewards: -305\n            Recent Change: -0.05\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1371.9062\n            Avg Critic Loss: 1688.6319\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 112,910 / 2,000,000 (5.6455%)\n            Episodes: 172\n            Currently: Rollout\n            Latest Reward: -212\n            Latest Avg Rewards: -305\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1371.9062\n            Avg Critic Loss: 1688.6319\n            =========================================\n        \n\n            =========================================\n            Timesteps: 112,910 / 2,000,000 (5.6455%)\n            Episodes: 172\n            Currently: Training cycle 1/5\n            Latest Reward: -212\n            Latest Avg Rewards: -305\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0001\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1371.9062\n            Avg Critic Loss: 1688.6319\n            =========================================\n        \n\n            =========================================\n            Timesteps: 112,910 / 2,000,000 (5.6455%)\n            Episodes: 172\n            Currently: Training cycle 2/5\n            Latest Reward: -212\n            Latest Avg Rewards: -305\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0022\n            Latest Critic Loss: 1020.0133\n            Avg Critic Loss: 1682.0119\n            =========================================\n        \n\n            =========================================\n            Timesteps: 112,910 / 2,000,000 (5.6455%)\n            Episodes: 172\n            Currently: Training cycle 3/5\n            Latest Reward: -212\n            Latest Avg Rewards: -305\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 1008.1207\n            Avg Critic Loss: 1675.4051\n            =========================================\n        \n\n            =========================================\n            Timesteps: 112,910 / 2,000,000 (5.6455%)\n            Episodes: 172\n            Currently: Training cycle 4/5\n            Latest Reward: -212\n            Latest Avg Rewards: -305\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 995.9914\n            Avg Critic Loss: 1668.8088\n            =========================================\n        \n\n            =========================================\n            Timesteps: 112,910 / 2,000,000 (5.6455%)\n            Episodes: 172\n            Currently: Training cycle 5/5\n            Latest Reward: -212\n            Latest Avg Rewards: -305\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 983.6264\n            Avg Critic Loss: 1662.2206\n            =========================================\n        \n\n            =========================================\n            Timesteps: 113,660 / 2,000,000 (5.683%)\n            Episodes: 173\n            Currently: Rollout\n            Latest Reward: -556\n            Latest Avg Rewards: -309\n            Recent Change: -0.06\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 971.0241\n            Avg Critic Loss: 1655.6377\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 114,410 / 2,000,000 (5.7205%)\n            Episodes: 174\n            Currently: Rollout\n            Latest Reward: -291\n            Latest Avg Rewards: -309\n            Recent Change: -0.08\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 971.0241\n            Avg Critic Loss: 1655.6377\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 115,160 / 2,000,000 (5.758%)\n            Episodes: 175\n            Currently: Rollout\n            Latest Reward: -249\n            Latest Avg Rewards: -309\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 971.0241\n            Avg Critic Loss: 1655.6377\n            =========================================\n        \n\n            =========================================\n            Timesteps: 115,910 / 2,000,000 (5.7955%)\n            Episodes: 176\n            Currently: Rollout\n            Latest Reward: -299\n            Latest Avg Rewards: -307\n            Recent Change: -0.03\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 971.0241\n            Avg Critic Loss: 1655.6377\n            =========================================\n        \n\n            =========================================\n            Timesteps: 116,660 / 2,000,000 (5.833%)\n            Episodes: 177\n            Currently: Rollout\n            Latest Reward: -259\n            Latest Avg Rewards: -306\n            Recent Change: -0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 971.0241\n            Avg Critic Loss: 1655.6377\n            =========================================\n        \n\n            =========================================\n            Timesteps: 117,410 / 2,000,000 (5.8705%)\n            Episodes: 178\n            Currently: Rollout\n            Latest Reward: -253\n            Latest Avg Rewards: -306\n            Recent Change: -0.08\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 971.0241\n            Avg Critic Loss: 1655.6377\n            =========================================\n        \n\n            =========================================\n            Timesteps: 118,160 / 2,000,000 (5.908%)\n            Episodes: 179\n            Currently: Rollout\n            Latest Reward: -450\n            Latest Avg Rewards: -309\n            Recent Change: -0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 971.0241\n            Avg Critic Loss: 1655.6377\n            =========================================\n        \n\n            =========================================\n            Timesteps: 118,160 / 2,000,000 (5.908%)\n            Episodes: 179\n            Currently: Training cycle 1/5\n            Latest Reward: -450\n            Latest Avg Rewards: -309\n            Recent Change: -0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 971.0241\n            Avg Critic Loss: 1655.6377\n            =========================================\n        \n\n            =========================================\n            Timesteps: 118,160 / 2,000,000 (5.908%)\n            Episodes: 179\n            Currently: Training cycle 2/5\n            Latest Reward: -450\n            Latest Avg Rewards: -309\n            Recent Change: -0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0021\n            Latest Critic Loss: 1384.6212\n            Avg Critic Loss: 1653.081\n            =========================================\n        \n\n            =========================================\n            Timesteps: 118,160 / 2,000,000 (5.908%)\n            Episodes: 179\n            Currently: Training cycle 3/5\n            Latest Reward: -450\n            Latest Avg Rewards: -309\n            Recent Change: -0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 1369.2072\n            Avg Critic Loss: 1650.4279\n            =========================================\n        \n\n            =========================================\n            Timesteps: 118,160 / 2,000,000 (5.908%)\n            Episodes: 179\n            Currently: Training cycle 4/5\n            Latest Reward: -450\n            Latest Avg Rewards: -309\n            Recent Change: -0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 1353.3397\n            Avg Critic Loss: 1647.6771\n            =========================================\n        \n\n            =========================================\n            Timesteps: 118,160 / 2,000,000 (5.908%)\n            Episodes: 179\n            Currently: Training cycle 5/5\n            Latest Reward: -450\n            Latest Avg Rewards: -309\n            Recent Change: -0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 1337.0337\n            Avg Critic Loss: 1644.8272\n            =========================================\n        \n\n            =========================================\n            Timesteps: 118,910 / 2,000,000 (5.9455%)\n            Episodes: 180\n            Currently: Rollout\n            Latest Reward: -233\n            Latest Avg Rewards: -308\n            Recent Change: -0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 1320.3049\n            Avg Critic Loss: 1641.877\n            =========================================\n        \n\n            =========================================\n            Timesteps: 119,660 / 2,000,000 (5.983%)\n            Episodes: 181\n            Currently: Rollout\n            Latest Reward: -189\n            Latest Avg Rewards: -308\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 1320.3049\n            Avg Critic Loss: 1641.877\n            =========================================\n        \n\n            =========================================\n            Timesteps: 120,410 / 2,000,000 (6.0205%)\n            Episodes: 182\n            Currently: Rollout\n            Latest Reward: -248\n            Latest Avg Rewards: -309\n            Recent Change: -0.45\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 1320.3049\n            Avg Critic Loss: 1641.877\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 121,160 / 2,000,000 (6.058%)\n            Episodes: 183\n            Currently: Rollout\n            Latest Reward: -430\n            Latest Avg Rewards: -310\n            Recent Change: -0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 1320.3049\n            Avg Critic Loss: 1641.877\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 121,910 / 2,000,000 (6.0955%)\n            Episodes: 184\n            Currently: Rollout\n            Latest Reward: -193\n            Latest Avg Rewards: -309\n            Recent Change: -0.41\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 1320.3049\n            Avg Critic Loss: 1641.877\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 122,660 / 2,000,000 (6.133%)\n            Episodes: 185\n            Currently: Rollout\n            Latest Reward: -277\n            Latest Avg Rewards: -308\n            Recent Change: -0.4\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 1320.3049\n            Avg Critic Loss: 1641.877\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 123,410 / 2,000,000 (6.1705%)\n            Episodes: 186\n            Currently: Rollout\n            Latest Reward: -263\n            Latest Avg Rewards: -308\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 1320.3049\n            Avg Critic Loss: 1641.877\n            =========================================\n        \n\n            =========================================\n            Timesteps: 123,410 / 2,000,000 (6.1705%)\n            Episodes: 186\n            Currently: Training cycle 1/5\n            Latest Reward: -263\n            Latest Avg Rewards: -308\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 1320.3049\n            Avg Critic Loss: 1641.877\n            =========================================\n        \n\n            =========================================\n            Timesteps: 123,410 / 2,000,000 (6.1705%)\n            Episodes: 186\n            Currently: Training cycle 2/5\n            Latest Reward: -263\n            Latest Avg Rewards: -308\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.002\n            Latest Critic Loss: 618.6524\n            Avg Critic Loss: 1632.6587\n            =========================================\n        \n\n            =========================================\n            Timesteps: 123,410 / 2,000,000 (6.1705%)\n            Episodes: 186\n            Currently: Training cycle 3/5\n            Latest Reward: -263\n            Latest Avg Rewards: -308\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 607.3491\n            Avg Critic Loss: 1623.5042\n            =========================================\n        \n\n            =========================================\n            Timesteps: 123,410 / 2,000,000 (6.1705%)\n            Episodes: 186\n            Currently: Training cycle 4/5\n            Latest Reward: -263\n            Latest Avg Rewards: -308\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 596.0955\n            Avg Critic Loss: 1614.4121\n            =========================================\n        \n\n            =========================================\n            Timesteps: 123,410 / 2,000,000 (6.1705%)\n            Episodes: 186\n            Currently: Training cycle 5/5\n            Latest Reward: -263\n            Latest Avg Rewards: -308\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 584.8807\n            Avg Critic Loss: 1605.3811\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 123,538 / 2,000,000 (6.1769%)\n            Episodes: 187\n            Currently: Rollout\n            Latest Reward: -137\n            Latest Avg Rewards: -306\n            Recent Change: -0.54\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 573.6969\n            Avg Critic Loss: 1596.4099\n            =========================================\n        \n\n            =========================================\n            Timesteps: 124,288 / 2,000,000 (6.2144%)\n            Episodes: 188\n            Currently: Rollout\n            Latest Reward: -252\n            Latest Avg Rewards: -306\n            Recent Change: -0.6\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 573.6969\n            Avg Critic Loss: 1596.4099\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 125,038 / 2,000,000 (6.2519%)\n            Episodes: 189\n            Currently: Rollout\n            Latest Reward: -270\n            Latest Avg Rewards: -307\n            Recent Change: -0.69\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 573.6969\n            Avg Critic Loss: 1596.4099\n            =========================================\n        \n\n            =========================================\n            Timesteps: 125,080 / 2,000,000 (6.254%)\n            Episodes: 190\n            Currently: Rollout\n            Latest Reward: -114\n            Latest Avg Rewards: -305\n            Recent Change: -0.8\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 573.6969\n            Avg Critic Loss: 1596.4099\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 125,830 / 2,000,000 (6.2915%)\n            Episodes: 191\n            Currently: Rollout\n            Latest Reward: -477\n            Latest Avg Rewards: -307\n            Recent Change: -0.73\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 573.6969\n            Avg Critic Loss: 1596.4099\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 126,580 / 2,000,000 (6.329%)\n            Episodes: 192\n            Currently: Rollout\n            Latest Reward: -336\n            Latest Avg Rewards: -306\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 573.6969\n            Avg Critic Loss: 1596.4099\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 127,330 / 2,000,000 (6.3665%)\n            Episodes: 193\n            Currently: Rollout\n            Latest Reward: -369\n            Latest Avg Rewards: -307\n            Recent Change: -0.64\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 573.6969\n            Avg Critic Loss: 1596.4099\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 128,080 / 2,000,000 (6.404%)\n            Episodes: 194\n            Currently: Rollout\n            Latest Reward: -343\n            Latest Avg Rewards: -307\n            Recent Change: -0.59\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 573.6969\n            Avg Critic Loss: 1596.4099\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 128,830 / 2,000,000 (6.4415%)\n            Episodes: 195\n            Currently: Rollout\n            Latest Reward: -284\n            Latest Avg Rewards: -308\n            Recent Change: -0.65\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 573.6969\n            Avg Critic Loss: 1596.4099\n            =========================================\n        \n\n            =========================================\n            Timesteps: 128,830 / 2,000,000 (6.4415%)\n            Episodes: 195\n            Currently: Training cycle 1/5\n            Latest Reward: -284\n            Latest Avg Rewards: -308\n            Recent Change: -0.65\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 573.6969\n            Avg Critic Loss: 1596.4099\n            =========================================\n        \n\n            =========================================\n            Timesteps: 128,830 / 2,000,000 (6.4415%)\n            Episodes: 195\n            Currently: Training cycle 2/5\n            Latest Reward: -284\n            Latest Avg Rewards: -308\n            Recent Change: -0.65\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 1276.4235\n            Avg Critic Loss: 1593.6514\n            =========================================\n        \n\n            =========================================\n            Timesteps: 128,830 / 2,000,000 (6.4415%)\n            Episodes: 195\n            Currently: Training cycle 3/5\n            Latest Reward: -284\n            Latest Avg Rewards: -308\n            Recent Change: -0.65\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 1258.0579\n            Avg Critic Loss: 1590.7831\n            =========================================\n        \n\n            =========================================\n            Timesteps: 128,830 / 2,000,000 (6.4415%)\n            Episodes: 195\n            Currently: Training cycle 4/5\n            Latest Reward: -284\n            Latest Avg Rewards: -308\n            Recent Change: -0.65\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0019\n            Latest Critic Loss: 1239.0188\n            Avg Critic Loss: 1587.8021\n            =========================================\n        \n\n            =========================================\n            Timesteps: 128,830 / 2,000,000 (6.4415%)\n            Episodes: 195\n            Currently: Training cycle 5/5\n            Latest Reward: -284\n            Latest Avg Rewards: -308\n            Recent Change: -0.65\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 1219.3621\n            Avg Critic Loss: 1584.7059\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 128,911 / 2,000,000 (6.4455%)\n            Episodes: 196\n            Currently: Rollout\n            Latest Reward: -132\n            Latest Avg Rewards: -307\n            Recent Change: -0.82\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 1199.147\n            Avg Critic Loss: 1581.4929\n            =========================================\n        \n\n            =========================================\n            Timesteps: 129,661 / 2,000,000 (6.483%)\n            Episodes: 197\n            Currently: Rollout\n            Latest Reward: -279\n            Latest Avg Rewards: -308\n            Recent Change: -0.91\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 1199.147\n            Avg Critic Loss: 1581.4929\n            =========================================\n        \n\n            =========================================\n            Timesteps: 130,411 / 2,000,000 (6.5206%)\n            Episodes: 198\n            Currently: Rollout\n            Latest Reward: -241\n            Latest Avg Rewards: -305\n            Recent Change: -0.79\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 1199.147\n            Avg Critic Loss: 1581.4929\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 131,161 / 2,000,000 (6.558%)\n            Episodes: 199\n            Currently: Rollout\n            Latest Reward: -274\n            Latest Avg Rewards: -304\n            Recent Change: -0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 1199.147\n            Avg Critic Loss: 1581.4929\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 131,911 / 2,000,000 (6.5956%)\n            Episodes: 200\n            Currently: Rollout\n            Latest Reward: -233\n            Latest Avg Rewards: -301\n            Recent Change: -0.71\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 1199.147\n            Avg Critic Loss: 1581.4929\n            =========================================\n        \n\n            =========================================\n            Timesteps: 132,661 / 2,000,000 (6.633%)\n            Episodes: 201\n            Currently: Rollout\n            Latest Reward: -380\n            Latest Avg Rewards: -302\n            Recent Change: -0.68\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 1199.147\n            Avg Critic Loss: 1581.4929\n            =========================================\n        \n\n            =========================================\n            Timesteps: 133,411 / 2,000,000 (6.6706%)\n            Episodes: 202\n            Currently: Rollout\n            Latest Reward: -207\n            Latest Avg Rewards: -302\n            Recent Change: -0.74\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 1199.147\n            Avg Critic Loss: 1581.4929\n            =========================================\n        \n\n            =========================================\n            Timesteps: 134,161 / 2,000,000 (6.7081%)\n            Episodes: 203\n            Currently: Rollout\n            Latest Reward: -236\n            Latest Avg Rewards: -301\n            Recent Change: -0.79\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 1199.147\n            Avg Critic Loss: 1581.4929\n            =========================================\n        \n\n            =========================================\n            Timesteps: 134,161 / 2,000,000 (6.7081%)\n            Episodes: 203\n            Currently: Training cycle 1/5\n            Latest Reward: -236\n            Latest Avg Rewards: -301\n            Recent Change: -0.79\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 1199.147\n            Avg Critic Loss: 1581.4929\n            =========================================\n        \n\n            =========================================\n            Timesteps: 134,161 / 2,000,000 (6.7081%)\n            Episodes: 203\n            Currently: Training cycle 2/5\n            Latest Reward: -236\n            Latest Avg Rewards: -301\n            Recent Change: -0.79\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 615.4282\n            Avg Critic Loss: 1573.5089\n            =========================================\n        \n\n            =========================================\n            Timesteps: 134,161 / 2,000,000 (6.7081%)\n            Episodes: 203\n            Currently: Training cycle 3/5\n            Latest Reward: -236\n            Latest Avg Rewards: -301\n            Recent Change: -0.79\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 600.5561\n            Avg Critic Loss: 1565.5339\n            =========================================\n        \n\n            =========================================\n            Timesteps: 134,161 / 2,000,000 (6.7081%)\n            Episodes: 203\n            Currently: Training cycle 4/5\n            Latest Reward: -236\n            Latest Avg Rewards: -301\n            Recent Change: -0.79\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 585.749\n            Avg Critic Loss: 1557.5682\n            =========================================\n        \n\n            =========================================\n            Timesteps: 134,161 / 2,000,000 (6.7081%)\n            Episodes: 203\n            Currently: Training cycle 5/5\n            Latest Reward: -236\n            Latest Avg Rewards: -301\n            Recent Change: -0.79\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0018\n            Latest Critic Loss: 570.9981\n            Avg Critic Loss: 1549.612\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 134,911 / 2,000,000 (6.7455%)\n            Episodes: 204\n            Currently: Rollout\n            Latest Reward: -330\n            Latest Avg Rewards: -300\n            Recent Change: -0.69\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 556.3082\n            Avg Critic Loss: 1541.6655\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 135,661 / 2,000,000 (6.7831%)\n            Episodes: 205\n            Currently: Rollout\n            Latest Reward: -239\n            Latest Avg Rewards: -300\n            Recent Change: -0.75\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 556.3082\n            Avg Critic Loss: 1541.6655\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 136,411 / 2,000,000 (6.8205%)\n            Episodes: 206\n            Currently: Rollout\n            Latest Reward: -370\n            Latest Avg Rewards: -301\n            Recent Change: -0.73\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 556.3082\n            Avg Critic Loss: 1541.6655\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 137,161 / 2,000,000 (6.8581%)\n            Episodes: 207\n            Currently: Rollout\n            Latest Reward: -612\n            Latest Avg Rewards: -304\n            Recent Change: -0.56\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 556.3082\n            Avg Critic Loss: 1541.6655\n            =========================================\n        \n\n            =========================================\n            Timesteps: 137,195 / 2,000,000 (6.8598%)\n            Episodes: 208\n            Currently: Rollout\n            Latest Reward: -112\n            Latest Avg Rewards: -300\n            Recent Change: -0.55\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 556.3082\n            Avg Critic Loss: 1541.6655\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 137,945 / 2,000,000 (6.8973%)\n            Episodes: 209\n            Currently: Rollout\n            Latest Reward: -240\n            Latest Avg Rewards: -298\n            Recent Change: -0.5\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 556.3082\n            Avg Critic Loss: 1541.6655\n            =========================================\n        \n\n            =========================================\n            Timesteps: 138,695 / 2,000,000 (6.9348%)\n            Episodes: 210\n            Currently: Rollout\n            Latest Reward: -235\n            Latest Avg Rewards: -297\n            Recent Change: -0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 556.3082\n            Avg Critic Loss: 1541.6655\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 139,445 / 2,000,000 (6.9723%)\n            Episodes: 211\n            Currently: Rollout\n            Latest Reward: -286\n            Latest Avg Rewards: -297\n            Recent Change: -0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 556.3082\n            Avg Critic Loss: 1541.6655\n            =========================================\n        \n\n            =========================================\n            Timesteps: 139,445 / 2,000,000 (6.9723%)\n            Episodes: 211\n            Currently: Training cycle 1/5\n            Latest Reward: -286\n            Latest Avg Rewards: -297\n            Recent Change: -0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 556.3082\n            Avg Critic Loss: 1541.6655\n            =========================================\n        \n\n            =========================================\n            Timesteps: 139,445 / 2,000,000 (6.9723%)\n            Episodes: 211\n            Currently: Training cycle 2/5\n            Latest Reward: -286\n            Latest Avg Rewards: -297\n            Recent Change: -0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1115.2556\n            Avg Critic Loss: 1538.2813\n            =========================================\n        \n\n            =========================================\n            Timesteps: 139,445 / 2,000,000 (6.9723%)\n            Episodes: 211\n            Currently: Training cycle 3/5\n            Latest Reward: -286\n            Latest Avg Rewards: -297\n            Recent Change: -0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1095.8804\n            Avg Critic Loss: 1534.7979\n            =========================================\n        \n\n            =========================================\n            Timesteps: 139,445 / 2,000,000 (6.9723%)\n            Episodes: 211\n            Currently: Training cycle 4/5\n            Latest Reward: -286\n            Latest Avg Rewards: -297\n            Recent Change: -0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1076.1213\n            Avg Critic Loss: 1531.2144\n            =========================================\n        \n\n            =========================================\n            Timesteps: 139,445 / 2,000,000 (6.9723%)\n            Episodes: 211\n            Currently: Training cycle 5/5\n            Latest Reward: -286\n            Latest Avg Rewards: -297\n            Recent Change: -0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1056.0143\n            Avg Critic Loss: 1527.5307\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 139,486 / 2,000,000 (6.9743%)\n            Episodes: 212\n            Currently: Rollout\n            Latest Reward: -117\n            Latest Avg Rewards: -295\n            Recent Change: -0.61\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n\n            =========================================\n            Timesteps: 140,236 / 2,000,000 (7.0118%)\n            Episodes: 213\n            Currently: Rollout\n            Latest Reward: -181\n            Latest Avg Rewards: -294\n            Recent Change: -0.68\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n\n            =========================================\n            Timesteps: 140,986 / 2,000,000 (7.0493%)\n            Episodes: 214\n            Currently: Rollout\n            Latest Reward: -485\n            Latest Avg Rewards: -297\n            Recent Change: -0.61\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 141,115 / 2,000,000 (7.0557%)\n            Episodes: 215\n            Currently: Rollout\n            Latest Reward: -167\n            Latest Avg Rewards: -297\n            Recent Change: -0.79\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 141,325 / 2,000,000 (7.0663%)\n            Episodes: 216\n            Currently: Rollout\n            Latest Reward: -202\n            Latest Avg Rewards: -296\n            Recent Change: -0.82\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n\n            =========================================\n            Timesteps: 142,075 / 2,000,000 (7.1038%)\n            Episodes: 217\n            Currently: Rollout\n            Latest Reward: -254\n            Latest Avg Rewards: -294\n            Recent Change: -0.8\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 142,825 / 2,000,000 (7.1413%)\n            Episodes: 218\n            Currently: Rollout\n            Latest Reward: -282\n            Latest Avg Rewards: -294\n            Recent Change: -0.8\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 143,575 / 2,000,000 (7.1788%)\n            Episodes: 219\n            Currently: Rollout\n            Latest Reward: -355\n            Latest Avg Rewards: -294\n            Recent Change: -0.72\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n\n            =========================================\n            Timesteps: 143,619 / 2,000,000 (7.181%)\n            Episodes: 220\n            Currently: Rollout\n            Latest Reward: -119\n            Latest Avg Rewards: -291\n            Recent Change: -0.73\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 144,369 / 2,000,000 (7.2184%)\n            Episodes: 221\n            Currently: Rollout\n            Latest Reward: -404\n            Latest Avg Rewards: -291\n            Recent Change: -0.59\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 144,473 / 2,000,000 (7.2236%)\n            Episodes: 222\n            Currently: Rollout\n            Latest Reward: -145\n            Latest Avg Rewards: -289\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n\n            =========================================\n            Timesteps: 144,473 / 2,000,000 (7.2236%)\n            Episodes: 222\n            Currently: Training cycle 1/5\n            Latest Reward: -145\n            Latest Avg Rewards: -289\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1035.6281\n            Avg Critic Loss: 1523.7469\n            =========================================\n        \n\n            =========================================\n            Timesteps: 144,473 / 2,000,000 (7.2236%)\n            Episodes: 222\n            Currently: Training cycle 2/5\n            Latest Reward: -145\n            Latest Avg Rewards: -289\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1078.2654\n            Avg Critic Loss: 1520.3462\n            =========================================\n        \n\n            =========================================\n            Timesteps: 144,473 / 2,000,000 (7.2236%)\n            Episodes: 222\n            Currently: Training cycle 3/5\n            Latest Reward: -145\n            Latest Avg Rewards: -289\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0017\n            Latest Critic Loss: 1055.6812\n            Avg Critic Loss: 1516.826\n            =========================================\n        \n\n            =========================================\n            Timesteps: 144,473 / 2,000,000 (7.2236%)\n            Episodes: 222\n            Currently: Training cycle 4/5\n            Latest Reward: -145\n            Latest Avg Rewards: -289\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 1032.7433\n            Avg Critic Loss: 1513.1863\n            =========================================\n        \n\n            =========================================\n            Timesteps: 144,473 / 2,000,000 (7.2236%)\n            Episodes: 222\n            Currently: Training cycle 5/5\n            Latest Reward: -145\n            Latest Avg Rewards: -289\n            Recent Change: -0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 1009.5272\n            Avg Critic Loss: 1509.4277\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 145,223 / 2,000,000 (7.2611%)\n            Episodes: 223\n            Currently: Rollout\n            Latest Reward: -296\n            Latest Avg Rewards: -290\n            Recent Change: -0.74\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 986.1021\n            Avg Critic Loss: 1505.5512\n            =========================================\n        \n\n            =========================================\n            Timesteps: 145,973 / 2,000,000 (7.2986%)\n            Episodes: 224\n            Currently: Rollout\n            Latest Reward: -259\n            Latest Avg Rewards: -288\n            Recent Change: -0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 986.1021\n            Avg Critic Loss: 1505.5512\n            =========================================\n        \n\n            =========================================\n            Timesteps: 146,723 / 2,000,000 (7.3361%)\n            Episodes: 225\n            Currently: Rollout\n            Latest Reward: -356\n            Latest Avg Rewards: -287\n            Recent Change: -0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 986.1021\n            Avg Critic Loss: 1505.5512\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 147,473 / 2,000,000 (7.3736%)\n            Episodes: 226\n            Currently: Rollout\n            Latest Reward: -303\n            Latest Avg Rewards: -285\n            Recent Change: -0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 986.1021\n            Avg Critic Loss: 1505.5512\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 148,223 / 2,000,000 (7.4111%)\n            Episodes: 227\n            Currently: Rollout\n            Latest Reward: -575\n            Latest Avg Rewards: -287\n            Recent Change: -0.13\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 986.1021\n            Avg Critic Loss: 1505.5512\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 148,973 / 2,000,000 (7.4486%)\n            Episodes: 228\n            Currently: Rollout\n            Latest Reward: -313\n            Latest Avg Rewards: -287\n            Recent Change: -0.09\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 986.1021\n            Avg Critic Loss: 1505.5512\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 149,180 / 2,000,000 (7.459%)\n            Episodes: 229\n            Currently: Rollout\n            Latest Reward: -170\n            Latest Avg Rewards: -286\n            Recent Change: -0.18\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 986.1021\n            Avg Critic Loss: 1505.5512\n            =========================================\n        \n\n            =========================================\n            Timesteps: 149,930 / 2,000,000 (7.4965%)\n            Episodes: 230\n            Currently: Rollout\n            Latest Reward: -268\n            Latest Avg Rewards: -286\n            Recent Change: -0.18\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 986.1021\n            Avg Critic Loss: 1505.5512\n            =========================================\n        \n\n            =========================================\n            Timesteps: 149,930 / 2,000,000 (7.4965%)\n            Episodes: 230\n            Currently: Training cycle 1/5\n            Latest Reward: -268\n            Latest Avg Rewards: -286\n            Recent Change: -0.18\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 986.1021\n            Avg Critic Loss: 1505.5512\n            =========================================\n        \n\n            =========================================\n            Timesteps: 149,930 / 2,000,000 (7.4965%)\n            Episodes: 230\n            Currently: Training cycle 2/5\n            Latest Reward: -268\n            Latest Avg Rewards: -286\n            Recent Change: -0.18\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 879.5047\n            Avg Critic Loss: 1500.9479\n            =========================================\n        \n\n            =========================================\n            Timesteps: 149,930 / 2,000,000 (7.4965%)\n            Episodes: 230\n            Currently: Training cycle 3/5\n            Latest Reward: -268\n            Latest Avg Rewards: -286\n            Recent Change: -0.18\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 855.2837\n            Avg Critic Loss: 1496.235\n            =========================================\n        \n\n            =========================================\n            Timesteps: 149,930 / 2,000,000 (7.4965%)\n            Episodes: 230\n            Currently: Training cycle 4/5\n            Latest Reward: -268\n            Latest Avg Rewards: -286\n            Recent Change: -0.18\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 830.9364\n            Avg Critic Loss: 1491.414\n            =========================================\n        \n\n            =========================================\n            Timesteps: 149,930 / 2,000,000 (7.4965%)\n            Episodes: 230\n            Currently: Training cycle 5/5\n            Latest Reward: -268\n            Latest Avg Rewards: -286\n            Recent Change: -0.18\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 806.5441\n            Avg Critic Loss: 1486.4869\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 150,680 / 2,000,000 (7.534%)\n            Episodes: 231\n            Currently: Rollout\n            Latest Reward: -311\n            Latest Avg Rewards: -286\n            Recent Change: -0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 782.1748\n            Avg Critic Loss: 1481.4561\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 151,430 / 2,000,000 (7.5715%)\n            Episodes: 232\n            Currently: Rollout\n            Latest Reward: -288\n            Latest Avg Rewards: -284\n            Recent Change: -0.03\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 782.1748\n            Avg Critic Loss: 1481.4561\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 152,180 / 2,000,000 (7.609%)\n            Episodes: 233\n            Currently: Rollout\n            Latest Reward: -515\n            Latest Avg Rewards: -286\n            Recent Change: 0.09\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 782.1748\n            Avg Critic Loss: 1481.4561\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 152,930 / 2,000,000 (7.6465%)\n            Episodes: 234\n            Currently: Rollout\n            Latest Reward: -267\n            Latest Avg Rewards: -287\n            Recent Change: 0.0\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 782.1748\n            Avg Critic Loss: 1481.4561\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 153,680 / 2,000,000 (7.684%)\n            Episodes: 235\n            Currently: Rollout\n            Latest Reward: -334\n            Latest Avg Rewards: -287\n            Recent Change: 0.07\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 782.1748\n            Avg Critic Loss: 1481.4561\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 154,430 / 2,000,000 (7.7215%)\n            Episodes: 236\n            Currently: Rollout\n            Latest Reward: -387\n            Latest Avg Rewards: -287\n            Recent Change: 0.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 782.1748\n            Avg Critic Loss: 1481.4561\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 155,180 / 2,000,000 (7.759%)\n            Episodes: 237\n            Currently: Rollout\n            Latest Reward: -390\n            Latest Avg Rewards: -287\n            Recent Change: 0.31\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 782.1748\n            Avg Critic Loss: 1481.4561\n            =========================================\n        \n\n            =========================================\n            Timesteps: 155,180 / 2,000,000 (7.759%)\n            Episodes: 237\n            Currently: Training cycle 1/5\n            Latest Reward: -390\n            Latest Avg Rewards: -287\n            Recent Change: 0.31\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 782.1748\n            Avg Critic Loss: 1481.4561\n            =========================================\n        \n\n            =========================================\n            Timesteps: 155,180 / 2,000,000 (7.759%)\n            Episodes: 237\n            Currently: Training cycle 2/5\n            Latest Reward: -390\n            Latest Avg Rewards: -287\n            Recent Change: 0.31\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0016\n            Latest Critic Loss: 729.4265\n            Avg Critic Loss: 1476.1226\n            =========================================\n        \n\n            =========================================\n            Timesteps: 155,180 / 2,000,000 (7.759%)\n            Episodes: 237\n            Currently: Training cycle 3/5\n            Latest Reward: -390\n            Latest Avg Rewards: -287\n            Recent Change: 0.31\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 705.7344\n            Avg Critic Loss: 1470.6973\n            =========================================\n        \n\n            =========================================\n            Timesteps: 155,180 / 2,000,000 (7.759%)\n            Episodes: 237\n            Currently: Training cycle 4/5\n            Latest Reward: -390\n            Latest Avg Rewards: -287\n            Recent Change: 0.31\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 682.2645\n            Avg Critic Loss: 1465.1838\n            =========================================\n        \n\n            =========================================\n            Timesteps: 155,180 / 2,000,000 (7.759%)\n            Episodes: 237\n            Currently: Training cycle 5/5\n            Latest Reward: -390\n            Latest Avg Rewards: -287\n            Recent Change: 0.31\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 659.0753\n            Avg Critic Loss: 1459.5858\n            =========================================\n        \n\n            =========================================\n            Timesteps: 155,930 / 2,000,000 (7.7965%)\n            Episodes: 238\n            Currently: Rollout\n            Latest Reward: -246\n            Latest Avg Rewards: -287\n            Recent Change: 0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 636.2181\n            Avg Critic Loss: 1453.9074\n            =========================================\n        \n\n            =========================================\n            Timesteps: 156,680 / 2,000,000 (7.834%)\n            Episodes: 239\n            Currently: Rollout\n            Latest Reward: -283\n            Latest Avg Rewards: -288\n            Recent Change: 0.24\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 636.2181\n            Avg Critic Loss: 1453.9074\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 157,430 / 2,000,000 (7.8715%)\n            Episodes: 240\n            Currently: Rollout\n            Latest Reward: -331\n            Latest Avg Rewards: -289\n            Recent Change: 0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 636.2181\n            Avg Critic Loss: 1453.9074\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 157,541 / 2,000,000 (7.877%)\n            Episodes: 241\n            Currently: Rollout\n            Latest Reward: -149\n            Latest Avg Rewards: -288\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 636.2181\n            Avg Critic Loss: 1453.9074\n            =========================================\n        \n\n            =========================================\n            Timesteps: 158,291 / 2,000,000 (7.9145%)\n            Episodes: 242\n            Currently: Rollout\n            Latest Reward: -252\n            Latest Avg Rewards: -287\n            Recent Change: 0.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 636.2181\n            Avg Critic Loss: 1453.9074\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 159,041 / 2,000,000 (7.952%)\n            Episodes: 243\n            Currently: Rollout\n            Latest Reward: -510\n            Latest Avg Rewards: -290\n            Recent Change: 0.2\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 636.2181\n            Avg Critic Loss: 1453.9074\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 159,154 / 2,000,000 (7.9577%)\n            Episodes: 244\n            Currently: Rollout\n            Latest Reward: -138\n            Latest Avg Rewards: -287\n            Recent Change: 0.2\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 636.2181\n            Avg Critic Loss: 1453.9074\n            =========================================\n        \n\n            =========================================\n            Timesteps: 159,904 / 2,000,000 (7.9952%)\n            Episodes: 245\n            Currently: Rollout\n            Latest Reward: -246\n            Latest Avg Rewards: -288\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 636.2181\n            Avg Critic Loss: 1453.9074\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 160,654 / 2,000,000 (8.0327%)\n            Episodes: 246\n            Currently: Rollout\n            Latest Reward: -396\n            Latest Avg Rewards: -290\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 636.2181\n            Avg Critic Loss: 1453.9074\n            =========================================\n        \n\n            =========================================\n            Timesteps: 160,654 / 2,000,000 (8.0327%)\n            Episodes: 246\n            Currently: Training cycle 1/5\n            Latest Reward: -396\n            Latest Avg Rewards: -290\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 636.2181\n            Avg Critic Loss: 1453.9074\n            =========================================\n        \n\n            =========================================\n            Timesteps: 160,654 / 2,000,000 (8.0327%)\n            Episodes: 246\n            Currently: Training cycle 2/5\n            Latest Reward: -396\n            Latest Avg Rewards: -290\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 512.4632\n            Avg Critic Loss: 1447.4592\n            =========================================\n        \n\n            =========================================\n            Timesteps: 160,654 / 2,000,000 (8.0327%)\n            Episodes: 246\n            Currently: Training cycle 3/5\n            Latest Reward: -396\n            Latest Avg Rewards: -290\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 494.1128\n            Avg Critic Loss: 1440.9738\n            =========================================\n        \n\n            =========================================\n            Timesteps: 160,654 / 2,000,000 (8.0327%)\n            Episodes: 246\n            Currently: Training cycle 4/5\n            Latest Reward: -396\n            Latest Avg Rewards: -290\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 476.4683\n            Avg Critic Loss: 1434.4569\n            =========================================\n        \n\n            =========================================\n            Timesteps: 160,654 / 2,000,000 (8.0327%)\n            Episodes: 246\n            Currently: Training cycle 5/5\n            Latest Reward: -396\n            Latest Avg Rewards: -290\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 459.542\n            Avg Critic Loss: 1427.9138\n            =========================================\n        \n\n            =========================================\n            Timesteps: 160,654 / 2,000,000 (8.0327%)\n            Episodes: 246\n            Currently: Saving\n            Latest Reward: -396\n            Latest Avg Rewards: -290\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 443.3466\n            Avg Critic Loss: 1421.35\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 161,404 / 2,000,000 (8.0702%)\n            Episodes: 247\n            Currently: Rollout\n            Latest Reward: -201\n            Latest Avg Rewards: -289\n            Recent Change: 0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 443.3466\n            Avg Critic Loss: 1421.35\n            =========================================\n        \n\n            =========================================\n            Timesteps: 162,154 / 2,000,000 (8.1077%)\n            Episodes: 248\n            Currently: Rollout\n            Latest Reward: -457\n            Latest Avg Rewards: -292\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 443.3466\n            Avg Critic Loss: 1421.35\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 162,904 / 2,000,000 (8.1452%)\n            Episodes: 249\n            Currently: Rollout\n            Latest Reward: -294\n            Latest Avg Rewards: -292\n            Recent Change: 0.09\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 443.3466\n            Avg Critic Loss: 1421.35\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 162,945 / 2,000,000 (8.1472%)\n            Episodes: 250\n            Currently: Rollout\n            Latest Reward: -114\n            Latest Avg Rewards: -290\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 443.3466\n            Avg Critic Loss: 1421.35\n            =========================================\n        \n\n            =========================================\n            Timesteps: 163,695 / 2,000,000 (8.1848%)\n            Episodes: 251\n            Currently: Rollout\n            Latest Reward: -248\n            Latest Avg Rewards: -289\n            Recent Change: 0.02\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 443.3466\n            Avg Critic Loss: 1421.35\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 164,445 / 2,000,000 (8.2223%)\n            Episodes: 252\n            Currently: Rollout\n            Latest Reward: -375\n            Latest Avg Rewards: -291\n            Recent Change: -0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 443.3466\n            Avg Critic Loss: 1421.35\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 165,195 / 2,000,000 (8.2598%)\n            Episodes: 253\n            Currently: Rollout\n            Latest Reward: -412\n            Latest Avg Rewards: -292\n            Recent Change: 0.07\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 443.3466\n            Avg Critic Loss: 1421.35\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 165,945 / 2,000,000 (8.2973%)\n            Episodes: 254\n            Currently: Rollout\n            Latest Reward: -261\n            Latest Avg Rewards: -292\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 443.3466\n            Avg Critic Loss: 1421.35\n            =========================================\n        \n\n            =========================================\n            Timesteps: 165,945 / 2,000,000 (8.2973%)\n            Episodes: 254\n            Currently: Training cycle 1/5\n            Latest Reward: -261\n            Latest Avg Rewards: -292\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 443.3466\n            Avg Critic Loss: 1421.35\n            =========================================\n        \n\n            =========================================\n            Timesteps: 165,945 / 2,000,000 (8.2973%)\n            Episodes: 254\n            Currently: Training cycle 2/5\n            Latest Reward: -261\n            Latest Avg Rewards: -292\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0015\n            Latest Critic Loss: 534.3693\n            Avg Critic Loss: 1415.476\n            =========================================\n        \n\n            =========================================\n            Timesteps: 165,945 / 2,000,000 (8.2973%)\n            Episodes: 254\n            Currently: Training cycle 3/5\n            Latest Reward: -261\n            Latest Avg Rewards: -292\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 519.2753\n            Avg Critic Loss: 1409.5799\n            =========================================\n        \n\n            =========================================\n            Timesteps: 165,945 / 2,000,000 (8.2973%)\n            Episodes: 254\n            Currently: Training cycle 4/5\n            Latest Reward: -261\n            Latest Avg Rewards: -292\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 504.8983\n            Avg Critic Loss: 1403.667\n            =========================================\n        \n\n            =========================================\n            Timesteps: 165,945 / 2,000,000 (8.2973%)\n            Episodes: 254\n            Currently: Training cycle 5/5\n            Latest Reward: -261\n            Latest Avg Rewards: -292\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 491.2638\n            Avg Critic Loss: 1397.7423\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 166,695 / 2,000,000 (8.3347%)\n            Episodes: 255\n            Currently: Rollout\n            Latest Reward: -366\n            Latest Avg Rewards: -291\n            Recent Change: 0.2\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 478.3944\n            Avg Critic Loss: 1391.811\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 166,885 / 2,000,000 (8.3443%)\n            Episodes: 256\n            Currently: Rollout\n            Latest Reward: -173\n            Latest Avg Rewards: -290\n            Recent Change: 0.08\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 478.3944\n            Avg Critic Loss: 1391.811\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 167,635 / 2,000,000 (8.3818%)\n            Episodes: 257\n            Currently: Rollout\n            Latest Reward: -389\n            Latest Avg Rewards: -291\n            Recent Change: 0.17\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 478.3944\n            Avg Critic Loss: 1391.811\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 168,385 / 2,000,000 (8.4192%)\n            Episodes: 258\n            Currently: Rollout\n            Latest Reward: -385\n            Latest Avg Rewards: -290\n            Recent Change: 0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 478.3944\n            Avg Critic Loss: 1391.811\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 169,135 / 2,000,000 (8.4567%)\n            Episodes: 259\n            Currently: Rollout\n            Latest Reward: -275\n            Latest Avg Rewards: -291\n            Recent Change: 0.24\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 478.3944\n            Avg Critic Loss: 1391.811\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 169,885 / 2,000,000 (8.4943%)\n            Episodes: 260\n            Currently: Rollout\n            Latest Reward: -232\n            Latest Avg Rewards: -291\n            Recent Change: 0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 478.3944\n            Avg Critic Loss: 1391.811\n            =========================================\n        \n\n            =========================================\n            Timesteps: 170,635 / 2,000,000 (8.5318%)\n            Episodes: 261\n            Currently: Rollout\n            Latest Reward: -249\n            Latest Avg Rewards: -289\n            Recent Change: 0.22\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 478.3944\n            Avg Critic Loss: 1391.811\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 171,385 / 2,000,000 (8.5693%)\n            Episodes: 262\n            Currently: Rollout\n            Latest Reward: -784\n            Latest Avg Rewards: -294\n            Recent Change: 0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 478.3944\n            Avg Critic Loss: 1391.811\n            =========================================\n        \n\n            =========================================\n            Timesteps: 171,385 / 2,000,000 (8.5693%)\n            Episodes: 262\n            Currently: Training cycle 1/5\n            Latest Reward: -784\n            Latest Avg Rewards: -294\n            Recent Change: 0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 478.3944\n            Avg Critic Loss: 1391.811\n            =========================================\n        \n\n            =========================================\n            Timesteps: 171,385 / 2,000,000 (8.5693%)\n            Episodes: 262\n            Currently: Training cycle 2/5\n            Latest Reward: -784\n            Latest Avg Rewards: -294\n            Recent Change: 0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 611.1464\n            Avg Critic Loss: 1386.8068\n            =========================================\n        \n\n            =========================================\n            Timesteps: 171,385 / 2,000,000 (8.5693%)\n            Episodes: 262\n            Currently: Training cycle 3/5\n            Latest Reward: -784\n            Latest Avg Rewards: -294\n            Recent Change: 0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 597.4617\n            Avg Critic Loss: 1381.7791\n            =========================================\n        \n\n            =========================================\n            Timesteps: 171,385 / 2,000,000 (8.5693%)\n            Episodes: 262\n            Currently: Training cycle 4/5\n            Latest Reward: -784\n            Latest Avg Rewards: -294\n            Recent Change: 0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 584.3818\n            Avg Critic Loss: 1376.7323\n            =========================================\n        \n\n            =========================================\n            Timesteps: 171,385 / 2,000,000 (8.5693%)\n            Episodes: 262\n            Currently: Training cycle 5/5\n            Latest Reward: -784\n            Latest Avg Rewards: -294\n            Recent Change: 0.51\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 571.9506\n            Avg Critic Loss: 1371.6707\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 172,135 / 2,000,000 (8.6067%)\n            Episodes: 263\n            Currently: Rollout\n            Latest Reward: -368\n            Latest Avg Rewards: -294\n            Recent Change: 0.6\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 560.2044\n            Avg Critic Loss: 1366.5991\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 172,885 / 2,000,000 (8.6443%)\n            Episodes: 264\n            Currently: Rollout\n            Latest Reward: -308\n            Latest Avg Rewards: -295\n            Recent Change: 0.57\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 560.2044\n            Avg Critic Loss: 1366.5991\n            =========================================\n        \n\n            =========================================\n            Timesteps: 173,635 / 2,000,000 (8.6818%)\n            Episodes: 265\n            Currently: Rollout\n            Latest Reward: -270\n            Latest Avg Rewards: -295\n            Recent Change: 0.56\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 560.2044\n            Avg Critic Loss: 1366.5991\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 174,385 / 2,000,000 (8.7193%)\n            Episodes: 266\n            Currently: Rollout\n            Latest Reward: -282\n            Latest Avg Rewards: -295\n            Recent Change: 0.55\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 560.2044\n            Avg Critic Loss: 1366.5991\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 175,135 / 2,000,000 (8.7568%)\n            Episodes: 267\n            Currently: Rollout\n            Latest Reward: -198\n            Latest Avg Rewards: -293\n            Recent Change: 0.53\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 560.2044\n            Avg Critic Loss: 1366.5991\n            =========================================\n        \n\n            =========================================\n            Timesteps: 175,885 / 2,000,000 (8.7942%)\n            Episodes: 268\n            Currently: Rollout\n            Latest Reward: -254\n            Latest Avg Rewards: -293\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 560.2044\n            Avg Critic Loss: 1366.5991\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 176,635 / 2,000,000 (8.8317%)\n            Episodes: 269\n            Currently: Rollout\n            Latest Reward: -254\n            Latest Avg Rewards: -293\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 560.2044\n            Avg Critic Loss: 1366.5991\n            =========================================\n        \n\n            =========================================\n            Timesteps: 176,635 / 2,000,000 (8.8317%)\n            Episodes: 269\n            Currently: Training cycle 1/5\n            Latest Reward: -254\n            Latest Avg Rewards: -293\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 560.2044\n            Avg Critic Loss: 1366.5991\n            =========================================\n        \n\n            =========================================\n            Timesteps: 176,635 / 2,000,000 (8.8317%)\n            Episodes: 269\n            Currently: Training cycle 2/5\n            Latest Reward: -254\n            Latest Avg Rewards: -293\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 167.1085\n            Avg Critic Loss: 1359.1488\n            =========================================\n        \n\n            =========================================\n            Timesteps: 176,635 / 2,000,000 (8.8317%)\n            Episodes: 269\n            Currently: Training cycle 3/5\n            Latest Reward: -254\n            Latest Avg Rewards: -293\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0014\n            Latest Critic Loss: 166.8686\n            Avg Critic Loss: 1351.7891\n            =========================================\n        \n\n            =========================================\n            Timesteps: 176,635 / 2,000,000 (8.8317%)\n            Episodes: 269\n            Currently: Training cycle 4/5\n            Latest Reward: -254\n            Latest Avg Rewards: -293\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 167.0625\n            Avg Critic Loss: 1344.5208\n            =========================================\n        \n\n            =========================================\n            Timesteps: 176,635 / 2,000,000 (8.8317%)\n            Episodes: 269\n            Currently: Training cycle 5/5\n            Latest Reward: -254\n            Latest Avg Rewards: -293\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 167.5655\n            Avg Critic Loss: 1337.3443\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 177,385 / 2,000,000 (8.8692%)\n            Episodes: 270\n            Currently: Rollout\n            Latest Reward: -245\n            Latest Avg Rewards: -294\n            Recent Change: 0.34\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 168.268\n            Avg Critic Loss: 1330.2589\n            =========================================\n        \n\n            =========================================\n            Timesteps: 178,135 / 2,000,000 (8.9067%)\n            Episodes: 271\n            Currently: Rollout\n            Latest Reward: -516\n            Latest Avg Rewards: -296\n            Recent Change: 0.48\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 168.268\n            Avg Critic Loss: 1330.2589\n            =========================================\n        \n\n            =========================================\n            Timesteps: 178,885 / 2,000,000 (8.9443%)\n            Episodes: 272\n            Currently: Rollout\n            Latest Reward: -304\n            Latest Avg Rewards: -297\n            Recent Change: 0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 168.268\n            Avg Critic Loss: 1330.2589\n            =========================================\n        \n\n            =========================================\n            Timesteps: 179,635 / 2,000,000 (8.9817%)\n            Episodes: 273\n            Currently: Rollout\n            Latest Reward: -190\n            Latest Avg Rewards: -293\n            Recent Change: 0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 168.268\n            Avg Critic Loss: 1330.2589\n            =========================================\n        \n\n            =========================================\n            Timesteps: 180,385 / 2,000,000 (9.0192%)\n            Episodes: 274\n            Currently: Rollout\n            Latest Reward: -314\n            Latest Avg Rewards: -293\n            Recent Change: 0.53\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 168.268\n            Avg Critic Loss: 1330.2589\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 180,571 / 2,000,000 (9.0286%)\n            Episodes: 275\n            Currently: Rollout\n            Latest Reward: -155\n            Latest Avg Rewards: -292\n            Recent Change: 0.42\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 168.268\n            Avg Critic Loss: 1330.2589\n            =========================================\n        \n\n            =========================================\n            Timesteps: 181,321 / 2,000,000 (9.0661%)\n            Episodes: 276\n            Currently: Rollout\n            Latest Reward: -321\n            Latest Avg Rewards: -293\n            Recent Change: 0.45\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 168.268\n            Avg Critic Loss: 1330.2589\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 182,071 / 2,000,000 (9.1036%)\n            Episodes: 277\n            Currently: Rollout\n            Latest Reward: -294\n            Latest Avg Rewards: -293\n            Recent Change: 0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 168.268\n            Avg Critic Loss: 1330.2589\n            =========================================\n        \n\n            =========================================\n            Timesteps: 182,071 / 2,000,000 (9.1036%)\n            Episodes: 277\n            Currently: Training cycle 1/5\n            Latest Reward: -294\n            Latest Avg Rewards: -293\n            Recent Change: 0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 168.268\n            Avg Critic Loss: 1330.2589\n            =========================================\n        \n\n            =========================================\n            Timesteps: 182,071 / 2,000,000 (9.1036%)\n            Episodes: 277\n            Currently: Training cycle 2/5\n            Latest Reward: -294\n            Latest Avg Rewards: -293\n            Recent Change: 0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 382.2029\n            Avg Critic Loss: 1324.5478\n            =========================================\n        \n\n            =========================================\n            Timesteps: 182,071 / 2,000,000 (9.1036%)\n            Episodes: 277\n            Currently: Training cycle 3/5\n            Latest Reward: -294\n            Latest Avg Rewards: -293\n            Recent Change: 0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 379.545\n            Avg Critic Loss: 1318.8891\n            =========================================\n        \n\n            =========================================\n            Timesteps: 182,071 / 2,000,000 (9.1036%)\n            Episodes: 277\n            Currently: Training cycle 4/5\n            Latest Reward: -294\n            Latest Avg Rewards: -293\n            Recent Change: 0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 377.1054\n            Avg Critic Loss: 1313.2832\n            =========================================\n        \n\n            =========================================\n            Timesteps: 182,071 / 2,000,000 (9.1036%)\n            Episodes: 277\n            Currently: Training cycle 5/5\n            Latest Reward: -294\n            Latest Avg Rewards: -293\n            Recent Change: 0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 374.8814\n            Avg Critic Loss: 1307.7305\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 182,821 / 2,000,000 (9.141%)\n            Episodes: 278\n            Currently: Rollout\n            Latest Reward: -314\n            Latest Avg Rewards: -294\n            Recent Change: 0.41\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 372.8675\n            Avg Critic Loss: 1302.2313\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 183,571 / 2,000,000 (9.1786%)\n            Episodes: 279\n            Currently: Rollout\n            Latest Reward: -241\n            Latest Avg Rewards: -292\n            Recent Change: 0.48\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 372.8675\n            Avg Critic Loss: 1302.2313\n            =========================================\n        \n\n            =========================================\n            Timesteps: 184,321 / 2,000,000 (9.2161%)\n            Episodes: 280\n            Currently: Rollout\n            Latest Reward: -552\n            Latest Avg Rewards: -295\n            Recent Change: 0.6\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 372.8675\n            Avg Critic Loss: 1302.2313\n            =========================================\n        \n\n            =========================================\n            Timesteps: 185,071 / 2,000,000 (9.2536%)\n            Episodes: 281\n            Currently: Rollout\n            Latest Reward: -184\n            Latest Avg Rewards: -295\n            Recent Change: 0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 372.8675\n            Avg Critic Loss: 1302.2313\n            =========================================\n        \n\n            =========================================\n            Timesteps: 185,821 / 2,000,000 (9.291%)\n            Episodes: 282\n            Currently: Rollout\n            Latest Reward: -615\n            Latest Avg Rewards: -298\n            Recent Change: 0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 372.8675\n            Avg Critic Loss: 1302.2313\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 186,571 / 2,000,000 (9.3285%)\n            Episodes: 283\n            Currently: Rollout\n            Latest Reward: -344\n            Latest Avg Rewards: -297\n            Recent Change: 0.74\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 372.8675\n            Avg Critic Loss: 1302.2313\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 187,128 / 2,000,000 (9.3564%)\n            Episodes: 284\n            Currently: Rollout\n            Latest Reward: -280\n            Latest Avg Rewards: -298\n            Recent Change: 0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 372.8675\n            Avg Critic Loss: 1302.2313\n            =========================================\n        \n\n            =========================================\n            Timesteps: 187,128 / 2,000,000 (9.3564%)\n            Episodes: 284\n            Currently: Training cycle 1/5\n            Latest Reward: -280\n            Latest Avg Rewards: -298\n            Recent Change: 0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 372.8675\n            Avg Critic Loss: 1302.2313\n            =========================================\n        \n\n            =========================================\n            Timesteps: 187,128 / 2,000,000 (9.3564%)\n            Episodes: 284\n            Currently: Training cycle 2/5\n            Latest Reward: -280\n            Latest Avg Rewards: -298\n            Recent Change: 0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 667.713\n            Avg Critic Loss: 1298.5207\n            =========================================\n        \n\n            =========================================\n            Timesteps: 187,128 / 2,000,000 (9.3564%)\n            Episodes: 284\n            Currently: Training cycle 3/5\n            Latest Reward: -280\n            Latest Avg Rewards: -298\n            Recent Change: 0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 662.1464\n            Avg Critic Loss: 1294.8209\n            =========================================\n        \n\n            =========================================\n            Timesteps: 187,128 / 2,000,000 (9.3564%)\n            Episodes: 284\n            Currently: Training cycle 4/5\n            Latest Reward: -280\n            Latest Avg Rewards: -298\n            Recent Change: 0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 656.2492\n            Avg Critic Loss: 1291.1297\n            =========================================\n        \n\n            =========================================\n            Timesteps: 187,128 / 2,000,000 (9.3564%)\n            Episodes: 284\n            Currently: Training cycle 5/5\n            Latest Reward: -280\n            Latest Avg Rewards: -298\n            Recent Change: 0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 650.1479\n            Avg Critic Loss: 1287.4459\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 187,878 / 2,000,000 (9.3939%)\n            Episodes: 285\n            Currently: Rollout\n            Latest Reward: -520\n            Latest Avg Rewards: -301\n            Recent Change: 0.78\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 643.954\n            Avg Critic Loss: 1283.7688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 188,628 / 2,000,000 (9.4314%)\n            Episodes: 286\n            Currently: Rollout\n            Latest Reward: -210\n            Latest Avg Rewards: -300\n            Recent Change: 0.7\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 643.954\n            Avg Critic Loss: 1283.7688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 189,378 / 2,000,000 (9.4689%)\n            Episodes: 287\n            Currently: Rollout\n            Latest Reward: -386\n            Latest Avg Rewards: -303\n            Recent Change: 0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 643.954\n            Avg Critic Loss: 1283.7688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 190,128 / 2,000,000 (9.5064%)\n            Episodes: 288\n            Currently: Rollout\n            Latest Reward: -391\n            Latest Avg Rewards: -304\n            Recent Change: 0.68\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 643.954\n            Avg Critic Loss: 1283.7688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 190,878 / 2,000,000 (9.5439%)\n            Episodes: 289\n            Currently: Rollout\n            Latest Reward: -527\n            Latest Avg Rewards: -307\n            Recent Change: 0.79\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 643.954\n            Avg Critic Loss: 1283.7688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 191,628 / 2,000,000 (9.5814%)\n            Episodes: 290\n            Currently: Rollout\n            Latest Reward: -257\n            Latest Avg Rewards: -308\n            Recent Change: 0.64\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 643.954\n            Avg Critic Loss: 1283.7688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 192,378 / 2,000,000 (9.6189%)\n            Episodes: 291\n            Currently: Rollout\n            Latest Reward: -440\n            Latest Avg Rewards: -308\n            Recent Change: 0.82\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 643.954\n            Avg Critic Loss: 1283.7688\n            =========================================\n        \n\n            =========================================\n            Timesteps: 192,378 / 2,000,000 (9.6189%)\n            Episodes: 291\n            Currently: Training cycle 1/5\n            Latest Reward: -440\n            Latest Avg Rewards: -308\n            Recent Change: 0.82\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0013\n            Latest Critic Loss: 643.954\n            Avg Critic Loss: 1283.7688\n            =========================================\n        \n\n            =========================================\n            Timesteps: 192,378 / 2,000,000 (9.6189%)\n            Episodes: 291\n            Currently: Training cycle 2/5\n            Latest Reward: -440\n            Latest Avg Rewards: -308\n            Recent Change: 0.82\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 327.8588\n            Avg Critic Loss: 1278.3375\n            =========================================\n        \n\n            =========================================\n            Timesteps: 192,378 / 2,000,000 (9.6189%)\n            Episodes: 291\n            Currently: Training cycle 3/5\n            Latest Reward: -440\n            Latest Avg Rewards: -308\n            Recent Change: 0.82\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 323.9582\n            Avg Critic Loss: 1272.9455\n            =========================================\n        \n\n            =========================================\n            Timesteps: 192,378 / 2,000,000 (9.6189%)\n            Episodes: 291\n            Currently: Training cycle 4/5\n            Latest Reward: -440\n            Latest Avg Rewards: -308\n            Recent Change: 0.82\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 320.3612\n            Avg Critic Loss: 1267.5939\n            =========================================\n        \n\n            =========================================\n            Timesteps: 192,378 / 2,000,000 (9.6189%)\n            Episodes: 291\n            Currently: Training cycle 5/5\n            Latest Reward: -440\n            Latest Avg Rewards: -308\n            Recent Change: 0.82\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 317.0837\n            Avg Critic Loss: 1262.2838\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 193,128 / 2,000,000 (9.6564%)\n            Episodes: 292\n            Currently: Rollout\n            Latest Reward: -360\n            Latest Avg Rewards: -308\n            Recent Change: 0.87\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 314.131\n            Avg Critic Loss: 1257.0163\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 193,878 / 2,000,000 (9.6939%)\n            Episodes: 293\n            Currently: Rollout\n            Latest Reward: -230\n            Latest Avg Rewards: -307\n            Recent Change: 0.86\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 314.131\n            Avg Critic Loss: 1257.0163\n            =========================================\n        \n\n            =========================================\n            Timesteps: 194,628 / 2,000,000 (9.7314%)\n            Episodes: 294\n            Currently: Rollout\n            Latest Reward: -267\n            Latest Avg Rewards: -306\n            Recent Change: 0.86\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 314.131\n            Avg Critic Loss: 1257.0163\n            =========================================\n        \n\n            =========================================\n            Timesteps: 195,378 / 2,000,000 (9.7689%)\n            Episodes: 295\n            Currently: Rollout\n            Latest Reward: -285\n            Latest Avg Rewards: -306\n            Recent Change: 0.84\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 314.131\n            Avg Critic Loss: 1257.0163\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 196,128 / 2,000,000 (9.8064%)\n            Episodes: 296\n            Currently: Rollout\n            Latest Reward: -337\n            Latest Avg Rewards: -308\n            Recent Change: 0.75\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 314.131\n            Avg Critic Loss: 1257.0163\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 196,878 / 2,000,000 (9.8439%)\n            Episodes: 297\n            Currently: Rollout\n            Latest Reward: -241\n            Latest Avg Rewards: -308\n            Recent Change: 0.69\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 314.131\n            Avg Critic Loss: 1257.0163\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 197,628 / 2,000,000 (9.8814%)\n            Episodes: 298\n            Currently: Rollout\n            Latest Reward: -471\n            Latest Avg Rewards: -310\n            Recent Change: 0.75\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 314.131\n            Avg Critic Loss: 1257.0163\n            =========================================\n        \n\n            =========================================\n            Timesteps: 197,628 / 2,000,000 (9.8814%)\n            Episodes: 298\n            Currently: Training cycle 1/5\n            Latest Reward: -471\n            Latest Avg Rewards: -310\n            Recent Change: 0.75\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 314.131\n            Avg Critic Loss: 1257.0163\n            =========================================\n        \n\n            =========================================\n            Timesteps: 197,628 / 2,000,000 (9.8814%)\n            Episodes: 298\n            Currently: Training cycle 2/5\n            Latest Reward: -471\n            Latest Avg Rewards: -310\n            Recent Change: 0.75\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 218.0959\n            Avg Critic Loss: 1251.2764\n            =========================================\n        \n\n            =========================================\n            Timesteps: 197,628 / 2,000,000 (9.8814%)\n            Episodes: 298\n            Currently: Training cycle 3/5\n            Latest Reward: -471\n            Latest Avg Rewards: -310\n            Recent Change: 0.75\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 221.5967\n            Avg Critic Loss: 1245.6188\n            =========================================\n        \n\n            =========================================\n            Timesteps: 197,628 / 2,000,000 (9.8814%)\n            Episodes: 298\n            Currently: Training cycle 4/5\n            Latest Reward: -471\n            Latest Avg Rewards: -310\n            Recent Change: 0.75\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 224.3042\n            Avg Critic Loss: 1240.0379\n            =========================================\n        \n\n            =========================================\n            Timesteps: 197,628 / 2,000,000 (9.8814%)\n            Episodes: 298\n            Currently: Training cycle 5/5\n            Latest Reward: -471\n            Latest Avg Rewards: -310\n            Recent Change: 0.75\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 226.1764\n            Avg Critic Loss: 1234.5277\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 198,378 / 2,000,000 (9.9189%)\n            Episodes: 299\n            Currently: Rollout\n            Latest Reward: -681\n            Latest Avg Rewards: -314\n            Recent Change: 0.95\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 227.2179\n            Avg Critic Loss: 1229.0828\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 199,128 / 2,000,000 (9.9564%)\n            Episodes: 300\n            Currently: Rollout\n            Latest Reward: -366\n            Latest Avg Rewards: -315\n            Recent Change: 0.93\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 227.2179\n            Avg Critic Loss: 1229.0828\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 199,612 / 2,000,000 (9.9806%)\n            Episodes: 301\n            Currently: Rollout\n            Latest Reward: -283\n            Latest Avg Rewards: -314\n            Recent Change: 0.95\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 227.2179\n            Avg Critic Loss: 1229.0828\n            =========================================\n        \n\n            =========================================\n            Timesteps: 200,362 / 2,000,000 (10.0181%)\n            Episodes: 302\n            Currently: Rollout\n            Latest Reward: -232\n            Latest Avg Rewards: -315\n            Recent Change: 0.83\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 227.2179\n            Avg Critic Loss: 1229.0828\n            =========================================\n        \n\n            =========================================\n            Timesteps: 201,112 / 2,000,000 (10.0556%)\n            Episodes: 303\n            Currently: Rollout\n            Latest Reward: -230\n            Latest Avg Rewards: -314\n            Recent Change: 0.74\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 227.2179\n            Avg Critic Loss: 1229.0828\n            =========================================\n        \n\n            =========================================\n            Timesteps: 201,862 / 2,000,000 (10.0931%)\n            Episodes: 304\n            Currently: Rollout\n            Latest Reward: -220\n            Latest Avg Rewards: -313\n            Recent Change: 0.69\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 227.2179\n            Avg Critic Loss: 1229.0828\n            =========================================\n        \n\n            =========================================\n            Timesteps: 202,612 / 2,000,000 (10.1306%)\n            Episodes: 305\n            Currently: Rollout\n            Latest Reward: -223\n            Latest Avg Rewards: -313\n            Recent Change: 0.59\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 227.2179\n            Avg Critic Loss: 1229.0828\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 203,362 / 2,000,000 (10.1681%)\n            Episodes: 306\n            Currently: Rollout\n            Latest Reward: -471\n            Latest Avg Rewards: -314\n            Recent Change: 0.72\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 227.2179\n            Avg Critic Loss: 1229.0828\n            =========================================\n        \n\n            =========================================\n            Timesteps: 203,362 / 2,000,000 (10.1681%)\n            Episodes: 306\n            Currently: Training cycle 1/5\n            Latest Reward: -471\n            Latest Avg Rewards: -314\n            Recent Change: 0.72\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 227.2179\n            Avg Critic Loss: 1229.0828\n            =========================================\n        \n\n            =========================================\n            Timesteps: 203,362 / 2,000,000 (10.1681%)\n            Episodes: 306\n            Currently: Training cycle 2/5\n            Latest Reward: -471\n            Latest Avg Rewards: -314\n            Recent Change: 0.72\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 454.9224\n            Avg Critic Loss: 1224.9207\n            =========================================\n        \n\n            =========================================\n            Timesteps: 203,362 / 2,000,000 (10.1681%)\n            Episodes: 306\n            Currently: Training cycle 3/5\n            Latest Reward: -471\n            Latest Avg Rewards: -314\n            Recent Change: 0.72\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 454.568\n            Avg Critic Loss: 1220.8011\n            =========================================\n        \n\n            =========================================\n            Timesteps: 203,362 / 2,000,000 (10.1681%)\n            Episodes: 306\n            Currently: Training cycle 4/5\n            Latest Reward: -471\n            Latest Avg Rewards: -314\n            Recent Change: 0.72\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 453.9449\n            Avg Critic Loss: 1216.7221\n            =========================================\n        \n\n            =========================================\n            Timesteps: 203,362 / 2,000,000 (10.1681%)\n            Episodes: 306\n            Currently: Training cycle 5/5\n            Latest Reward: -471\n            Latest Avg Rewards: -314\n            Recent Change: 0.72\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 453.0865\n            Avg Critic Loss: 1212.6817\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 204,112 / 2,000,000 (10.2056%)\n            Episodes: 307\n            Currently: Rollout\n            Latest Reward: -394\n            Latest Avg Rewards: -312\n            Recent Change: 0.95\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 452.0235\n            Avg Critic Loss: 1208.6782\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 204,862 / 2,000,000 (10.2431%)\n            Episodes: 308\n            Currently: Rollout\n            Latest Reward: -237\n            Latest Avg Rewards: -313\n            Recent Change: 0.78\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 452.0235\n            Avg Critic Loss: 1208.6782\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 205,612 / 2,000,000 (10.2806%)\n            Episodes: 309\n            Currently: Rollout\n            Latest Reward: -321\n            Latest Avg Rewards: -314\n            Recent Change: 0.74\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 452.0235\n            Avg Critic Loss: 1208.6782\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 206,362 / 2,000,000 (10.3181%)\n            Episodes: 310\n            Currently: Rollout\n            Latest Reward: -422\n            Latest Avg Rewards: -316\n            Recent Change: 0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 452.0235\n            Avg Critic Loss: 1208.6782\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 206,416 / 2,000,000 (10.3208%)\n            Episodes: 311\n            Currently: Rollout\n            Latest Reward: -121\n            Latest Avg Rewards: -314\n            Recent Change: 0.62\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 452.0235\n            Avg Critic Loss: 1208.6782\n            =========================================\n        \n\n            =========================================\n            Timesteps: 207,166 / 2,000,000 (10.3583%)\n            Episodes: 312\n            Currently: Rollout\n            Latest Reward: -412\n            Latest Avg Rewards: -317\n            Recent Change: 0.56\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 452.0235\n            Avg Critic Loss: 1208.6782\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 207,794 / 2,000,000 (10.3897%)\n            Episodes: 313\n            Currently: Rollout\n            Latest Reward: -523\n            Latest Avg Rewards: -321\n            Recent Change: 0.6\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 452.0235\n            Avg Critic Loss: 1208.6782\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 correctly sorted into sorting_one\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 208,544 / 2,000,000 (10.4272%)\n            Episodes: 314\n            Currently: Rollout\n            Latest Reward: -224\n            Latest Avg Rewards: -318\n            Recent Change: 0.64\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 452.0235\n            Avg Critic Loss: 1208.6782\n            =========================================\n        \n\n            =========================================\n            Timesteps: 208,544 / 2,000,000 (10.4272%)\n            Episodes: 314\n            Currently: Training cycle 1/5\n            Latest Reward: -224\n            Latest Avg Rewards: -318\n            Recent Change: 0.64\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0012\n            Latest Critic Loss: 452.0235\n            Avg Critic Loss: 1208.6782\n            =========================================\n        \n\n            =========================================\n            Timesteps: 208,544 / 2,000,000 (10.4272%)\n            Episodes: 314\n            Currently: Training cycle 2/5\n            Latest Reward: -224\n            Latest Avg Rewards: -318\n            Recent Change: 0.64\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 398.2341\n            Avg Critic Loss: 1204.4351\n            =========================================\n        \n\n            =========================================\n            Timesteps: 208,544 / 2,000,000 (10.4272%)\n            Episodes: 314\n            Currently: Training cycle 3/5\n            Latest Reward: -224\n            Latest Avg Rewards: -318\n            Recent Change: 0.64\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 397.8052\n            Avg Critic Loss: 1200.2339\n            =========================================\n        \n\n            =========================================\n            Timesteps: 208,544 / 2,000,000 (10.4272%)\n            Episodes: 314\n            Currently: Training cycle 4/5\n            Latest Reward: -224\n            Latest Avg Rewards: -318\n            Recent Change: 0.64\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 397.2364\n            Avg Critic Loss: 1196.0733\n            =========================================\n        \n\n            =========================================\n            Timesteps: 208,544 / 2,000,000 (10.4272%)\n            Episodes: 314\n            Currently: Training cycle 5/5\n            Latest Reward: -224\n            Latest Avg Rewards: -318\n            Recent Change: 0.64\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 396.542\n            Avg Critic Loss: 1191.952\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 209,294 / 2,000,000 (10.4647%)\n            Episodes: 315\n            Currently: Rollout\n            Latest Reward: -209\n            Latest Avg Rewards: -318\n            Recent Change: 0.49\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 395.7382\n            Avg Critic Loss: 1187.8688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 209,433 / 2,000,000 (10.4717%)\n            Episodes: 316\n            Currently: Rollout\n            Latest Reward: -147\n            Latest Avg Rewards: -318\n            Recent Change: 0.32\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 395.7382\n            Avg Critic Loss: 1187.8688\n            =========================================\n        \n\n            =========================================\n            Timesteps: 210,183 / 2,000,000 (10.5091%)\n            Episodes: 317\n            Currently: Rollout\n            Latest Reward: -267\n            Latest Avg Rewards: -318\n            Recent Change: 0.25\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 395.7382\n            Avg Critic Loss: 1187.8688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 210,933 / 2,000,000 (10.5466%)\n            Episodes: 318\n            Currently: Rollout\n            Latest Reward: -353\n            Latest Avg Rewards: -319\n            Recent Change: 0.25\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 395.7382\n            Avg Critic Loss: 1187.8688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 211,683 / 2,000,000 (10.5842%)\n            Episodes: 319\n            Currently: Rollout\n            Latest Reward: -252\n            Latest Avg Rewards: -318\n            Recent Change: 0.23\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 395.7382\n            Avg Critic Loss: 1187.8688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 212,433 / 2,000,000 (10.6217%)\n            Episodes: 320\n            Currently: Rollout\n            Latest Reward: -316\n            Latest Avg Rewards: -320\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 395.7382\n            Avg Critic Loss: 1187.8688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 213,183 / 2,000,000 (10.6592%)\n            Episodes: 321\n            Currently: Rollout\n            Latest Reward: -316\n            Latest Avg Rewards: -319\n            Recent Change: 0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 395.7382\n            Avg Critic Loss: 1187.8688\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 213,403 / 2,000,000 (10.6701%)\n            Episodes: 322\n            Currently: Rollout\n            Latest Reward: -235\n            Latest Avg Rewards: -320\n            Recent Change: 0.0\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 395.7382\n            Avg Critic Loss: 1187.8688\n            =========================================\n        \n\n            =========================================\n            Timesteps: 214,153 / 2,000,000 (10.7077%)\n            Episodes: 323\n            Currently: Rollout\n            Latest Reward: -358\n            Latest Avg Rewards: -320\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 395.7382\n            Avg Critic Loss: 1187.8688\n            =========================================\n        \n\n            =========================================\n            Timesteps: 214,153 / 2,000,000 (10.7077%)\n            Episodes: 323\n            Currently: Training cycle 1/5\n            Latest Reward: -358\n            Latest Avg Rewards: -320\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 395.7382\n            Avg Critic Loss: 1187.8688\n            =========================================\n        \n\n            =========================================\n            Timesteps: 214,153 / 2,000,000 (10.7077%)\n            Episodes: 323\n            Currently: Training cycle 2/5\n            Latest Reward: -358\n            Latest Avg Rewards: -320\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 302.9258\n            Avg Critic Loss: 1183.3538\n            =========================================\n        \n\n            =========================================\n            Timesteps: 214,153 / 2,000,000 (10.7077%)\n            Episodes: 323\n            Currently: Training cycle 3/5\n            Latest Reward: -358\n            Latest Avg Rewards: -320\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 302.8426\n            Avg Critic Loss: 1178.8842\n            =========================================\n        \n\n            =========================================\n            Timesteps: 214,153 / 2,000,000 (10.7077%)\n            Episodes: 323\n            Currently: Training cycle 4/5\n            Latest Reward: -358\n            Latest Avg Rewards: -320\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 302.1213\n            Avg Critic Loss: 1174.4561\n            =========================================\n        \n\n            =========================================\n            Timesteps: 214,153 / 2,000,000 (10.7077%)\n            Episodes: 323\n            Currently: Training cycle 5/5\n            Latest Reward: -358\n            Latest Avg Rewards: -320\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 300.8498\n            Avg Critic Loss: 1170.0661\n            =========================================\n        \n\n            =========================================\n            Timesteps: 214,153 / 2,000,000 (10.7077%)\n            Episodes: 323\n            Currently: Saving\n            Latest Reward: -358\n            Latest Avg Rewards: -320\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 299.1233\n            Avg Critic Loss: 1165.7114\n            =========================================\n        \n\n            =========================================\n            Timesteps: 214,903 / 2,000,000 (10.7452%)\n            Episodes: 324\n            Currently: Rollout\n            Latest Reward: -437\n            Latest Avg Rewards: -322\n            Recent Change: 0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 299.1233\n            Avg Critic Loss: 1165.7114\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 215,653 / 2,000,000 (10.7827%)\n            Episodes: 325\n            Currently: Rollout\n            Latest Reward: -401\n            Latest Avg Rewards: -323\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 299.1233\n            Avg Critic Loss: 1165.7114\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 216,403 / 2,000,000 (10.8201%)\n            Episodes: 326\n            Currently: Rollout\n            Latest Reward: -362\n            Latest Avg Rewards: -323\n            Recent Change: 0.12\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 299.1233\n            Avg Critic Loss: 1165.7114\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 217,153 / 2,000,000 (10.8577%)\n            Episodes: 327\n            Currently: Rollout\n            Latest Reward: -276\n            Latest Avg Rewards: -320\n            Recent Change: 0.24\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 299.1233\n            Avg Critic Loss: 1165.7114\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 217,903 / 2,000,000 (10.8952%)\n            Episodes: 328\n            Currently: Rollout\n            Latest Reward: -382\n            Latest Avg Rewards: -321\n            Recent Change: 0.28\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 299.1233\n            Avg Critic Loss: 1165.7114\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 218,653 / 2,000,000 (10.9326%)\n            Episodes: 329\n            Currently: Rollout\n            Latest Reward: -254\n            Latest Avg Rewards: -322\n            Recent Change: 0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 299.1233\n            Avg Critic Loss: 1165.7114\n            =========================================\n        \n\n            =========================================\n            Timesteps: 219,403 / 2,000,000 (10.9701%)\n            Episodes: 330\n            Currently: Rollout\n            Latest Reward: -305\n            Latest Avg Rewards: -322\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 299.1233\n            Avg Critic Loss: 1165.7114\n            =========================================\n        \n\n            =========================================\n            Timesteps: 219,403 / 2,000,000 (10.9701%)\n            Episodes: 330\n            Currently: Training cycle 1/5\n            Latest Reward: -305\n            Latest Avg Rewards: -322\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 299.1233\n            Avg Critic Loss: 1165.7114\n            =========================================\n        \n\n            =========================================\n            Timesteps: 219,403 / 2,000,000 (10.9701%)\n            Episodes: 330\n            Currently: Training cycle 2/5\n            Latest Reward: -305\n            Latest Avg Rewards: -322\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.5294\n            Avg Critic Loss: 1161.4568\n            =========================================\n        \n\n            =========================================\n            Timesteps: 219,403 / 2,000,000 (10.9701%)\n            Episodes: 330\n            Currently: Training cycle 3/5\n            Latest Reward: -305\n            Latest Avg Rewards: -322\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.6429\n            Avg Critic Loss: 1157.2448\n            =========================================\n        \n\n            =========================================\n            Timesteps: 219,403 / 2,000,000 (10.9701%)\n            Episodes: 330\n            Currently: Training cycle 4/5\n            Latest Reward: -305\n            Latest Avg Rewards: -322\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.7356\n            Avg Critic Loss: 1153.0748\n            =========================================\n        \n\n            =========================================\n            Timesteps: 219,403 / 2,000,000 (10.9701%)\n            Episodes: 330\n            Currently: Training cycle 5/5\n            Latest Reward: -305\n            Latest Avg Rewards: -322\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.7993\n            Avg Critic Loss: 1148.946\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 220,153 / 2,000,000 (11.0076%)\n            Episodes: 331\n            Currently: Rollout\n            Latest Reward: -350\n            Latest Avg Rewards: -323\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.8283\n            Avg Critic Loss: 1144.8577\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 220,903 / 2,000,000 (11.0451%)\n            Episodes: 332\n            Currently: Rollout\n            Latest Reward: -258\n            Latest Avg Rewards: -322\n            Recent Change: 0.05\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.8283\n            Avg Critic Loss: 1144.8577\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 221,653 / 2,000,000 (11.0826%)\n            Episodes: 333\n            Currently: Rollout\n            Latest Reward: -413\n            Latest Avg Rewards: -321\n            Recent Change: 0.22\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.8283\n            Avg Critic Loss: 1144.8577\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 222,403 / 2,000,000 (11.1201%)\n            Episodes: 334\n            Currently: Rollout\n            Latest Reward: -204\n            Latest Avg Rewards: -321\n            Recent Change: 0.12\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.8283\n            Avg Critic Loss: 1144.8577\n            =========================================\n        \n\n            =========================================\n            Timesteps: 223,153 / 2,000,000 (11.1577%)\n            Episodes: 335\n            Currently: Rollout\n            Latest Reward: -388\n            Latest Avg Rewards: -321\n            Recent Change: 0.17\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.8283\n            Avg Critic Loss: 1144.8577\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 223,587 / 2,000,000 (11.1794%)\n            Episodes: 336\n            Currently: Rollout\n            Latest Reward: -252\n            Latest Avg Rewards: -320\n            Recent Change: 0.17\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.8283\n            Avg Critic Loss: 1144.8577\n            =========================================\n        \n\n            =========================================\n            Timesteps: 224,337 / 2,000,000 (11.2169%)\n            Episodes: 337\n            Currently: Rollout\n            Latest Reward: -357\n            Latest Avg Rewards: -319\n            Recent Change: 0.23\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.8283\n            Avg Critic Loss: 1144.8577\n            =========================================\n        \n\n            =========================================\n            Timesteps: 225,087 / 2,000,000 (11.2544%)\n            Episodes: 338\n            Currently: Rollout\n            Latest Reward: -236\n            Latest Avg Rewards: -319\n            Recent Change: 0.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.8283\n            Avg Critic Loss: 1144.8577\n            =========================================\n        \n\n            =========================================\n            Timesteps: 225,087 / 2,000,000 (11.2544%)\n            Episodes: 338\n            Currently: Training cycle 1/5\n            Latest Reward: -236\n            Latest Avg Rewards: -319\n            Recent Change: 0.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 310.8283\n            Avg Critic Loss: 1144.8577\n            =========================================\n        \n\n            =========================================\n            Timesteps: 225,087 / 2,000,000 (11.2544%)\n            Episodes: 338\n            Currently: Training cycle 2/5\n            Latest Reward: -236\n            Latest Avg Rewards: -319\n            Recent Change: 0.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 220.4826\n            Avg Critic Loss: 1140.3704\n            =========================================\n        \n\n            =========================================\n            Timesteps: 225,087 / 2,000,000 (11.2544%)\n            Episodes: 338\n            Currently: Training cycle 3/5\n            Latest Reward: -236\n            Latest Avg Rewards: -319\n            Recent Change: 0.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 220.3501\n            Avg Critic Loss: 1135.9259\n            =========================================\n        \n\n            =========================================\n            Timesteps: 225,087 / 2,000,000 (11.2544%)\n            Episodes: 338\n            Currently: Training cycle 4/5\n            Latest Reward: -236\n            Latest Avg Rewards: -319\n            Recent Change: 0.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0011\n            Latest Critic Loss: 220.212\n            Avg Critic Loss: 1131.5234\n            =========================================\n        \n\n            =========================================\n            Timesteps: 225,087 / 2,000,000 (11.2544%)\n            Episodes: 338\n            Currently: Training cycle 5/5\n            Latest Reward: -236\n            Latest Avg Rewards: -319\n            Recent Change: 0.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0006\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 220.0708\n            Avg Critic Loss: 1127.1624\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 225,128 / 2,000,000 (11.2564%)\n            Episodes: 339\n            Currently: Rollout\n            Latest Reward: -112\n            Latest Avg Rewards: -318\n            Recent Change: -0.0\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 219.9282\n            Avg Critic Loss: 1122.8422\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 225,878 / 2,000,000 (11.2939%)\n            Episodes: 340\n            Currently: Rollout\n            Latest Reward: -430\n            Latest Avg Rewards: -319\n            Recent Change: 0.07\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 219.9282\n            Avg Critic Loss: 1122.8422\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 226,628 / 2,000,000 (11.3314%)\n            Episodes: 341\n            Currently: Rollout\n            Latest Reward: -524\n            Latest Avg Rewards: -322\n            Recent Change: 0.09\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 219.9282\n            Avg Critic Loss: 1122.8422\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 227,378 / 2,000,000 (11.3689%)\n            Episodes: 342\n            Currently: Rollout\n            Latest Reward: -494\n            Latest Avg Rewards: -325\n            Recent Change: 0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 219.9282\n            Avg Critic Loss: 1122.8422\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 228,128 / 2,000,000 (11.4064%)\n            Episodes: 343\n            Currently: Rollout\n            Latest Reward: -288\n            Latest Avg Rewards: -323\n            Recent Change: 0.24\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 219.9282\n            Avg Critic Loss: 1122.8422\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 228,878 / 2,000,000 (11.4439%)\n            Episodes: 344\n            Currently: Rollout\n            Latest Reward: -281\n            Latest Avg Rewards: -324\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 219.9282\n            Avg Critic Loss: 1122.8422\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 229,628 / 2,000,000 (11.4814%)\n            Episodes: 345\n            Currently: Rollout\n            Latest Reward: -316\n            Latest Avg Rewards: -325\n            Recent Change: 0.05\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 219.9282\n            Avg Critic Loss: 1122.8422\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 230,378 / 2,000,000 (11.5189%)\n            Episodes: 346\n            Currently: Rollout\n            Latest Reward: -220\n            Latest Avg Rewards: -323\n            Recent Change: 0.03\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 219.9282\n            Avg Critic Loss: 1122.8422\n            =========================================\n        \n\n            =========================================\n            Timesteps: 230,378 / 2,000,000 (11.5189%)\n            Episodes: 346\n            Currently: Training cycle 1/5\n            Latest Reward: -220\n            Latest Avg Rewards: -323\n            Recent Change: 0.03\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 219.9282\n            Avg Critic Loss: 1122.8422\n            =========================================\n        \n\n            =========================================\n            Timesteps: 230,378 / 2,000,000 (11.5189%)\n            Episodes: 346\n            Currently: Training cycle 2/5\n            Latest Reward: -220\n            Latest Avg Rewards: -323\n            Recent Change: 0.03\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 433.3885\n            Avg Critic Loss: 1119.5747\n            =========================================\n        \n\n            =========================================\n            Timesteps: 230,378 / 2,000,000 (11.5189%)\n            Episodes: 346\n            Currently: Training cycle 3/5\n            Latest Reward: -220\n            Latest Avg Rewards: -323\n            Recent Change: 0.03\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 433.488\n            Avg Critic Loss: 1116.3384\n            =========================================\n        \n\n            =========================================\n            Timesteps: 230,378 / 2,000,000 (11.5189%)\n            Episodes: 346\n            Currently: Training cycle 4/5\n            Latest Reward: -220\n            Latest Avg Rewards: -323\n            Recent Change: 0.03\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 433.4014\n            Avg Critic Loss: 1113.1321\n            =========================================\n        \n\n            =========================================\n            Timesteps: 230,378 / 2,000,000 (11.5189%)\n            Episodes: 346\n            Currently: Training cycle 5/5\n            Latest Reward: -220\n            Latest Avg Rewards: -323\n            Recent Change: 0.03\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 433.1459\n            Avg Critic Loss: 1109.9546\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 231,128 / 2,000,000 (11.5564%)\n            Episodes: 347\n            Currently: Rollout\n            Latest Reward: -319\n            Latest Avg Rewards: -324\n            Recent Change: -0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0014\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 432.7423\n            Avg Critic Loss: 1106.8048\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 231,878 / 2,000,000 (11.5939%)\n            Episodes: 348\n            Currently: Rollout\n            Latest Reward: -267\n            Latest Avg Rewards: -322\n            Recent Change: 0.0\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0014\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 432.7423\n            Avg Critic Loss: 1106.8048\n            =========================================\n        \n\n            =========================================\n            Timesteps: 232,628 / 2,000,000 (11.6314%)\n            Episodes: 349\n            Currently: Rollout\n            Latest Reward: -267\n            Latest Avg Rewards: -322\n            Recent Change: -0.05\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0014\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 432.7423\n            Avg Critic Loss: 1106.8048\n            =========================================\n        \n\n            =========================================\n            Timesteps: 233,378 / 2,000,000 (11.6689%)\n            Episodes: 350\n            Currently: Rollout\n            Latest Reward: -243\n            Latest Avg Rewards: -323\n            Recent Change: -0.22\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0014\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 432.7423\n            Avg Critic Loss: 1106.8048\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 234,128 / 2,000,000 (11.7064%)\n            Episodes: 351\n            Currently: Rollout\n            Latest Reward: -614\n            Latest Avg Rewards: -327\n            Recent Change: -0.09\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0014\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 432.7423\n            Avg Critic Loss: 1106.8048\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 234,878 / 2,000,000 (11.7439%)\n            Episodes: 352\n            Currently: Rollout\n            Latest Reward: -437\n            Latest Avg Rewards: -328\n            Recent Change: -0.0\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0014\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 432.7423\n            Avg Critic Loss: 1106.8048\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 235,628 / 2,000,000 (11.7814%)\n            Episodes: 353\n            Currently: Rollout\n            Latest Reward: -405\n            Latest Avg Rewards: -327\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0014\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 432.7423\n            Avg Critic Loss: 1106.8048\n            =========================================\n        \n\n            =========================================\n            Timesteps: 235,628 / 2,000,000 (11.7814%)\n            Episodes: 353\n            Currently: Training cycle 1/5\n            Latest Reward: -405\n            Latest Avg Rewards: -327\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0014\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 432.7423\n            Avg Critic Loss: 1106.8048\n            =========================================\n        \n\n            =========================================\n            Timesteps: 235,628 / 2,000,000 (11.7814%)\n            Episodes: 353\n            Currently: Training cycle 2/5\n            Latest Reward: -405\n            Latest Avg Rewards: -327\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 472.6099\n            Avg Critic Loss: 1103.8687\n            =========================================\n        \n\n            =========================================\n            Timesteps: 235,628 / 2,000,000 (11.7814%)\n            Episodes: 353\n            Currently: Training cycle 3/5\n            Latest Reward: -405\n            Latest Avg Rewards: -327\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 472.0304\n            Avg Critic Loss: 1100.957\n            =========================================\n        \n\n            =========================================\n            Timesteps: 235,628 / 2,000,000 (11.7814%)\n            Episodes: 353\n            Currently: Training cycle 4/5\n            Latest Reward: -405\n            Latest Avg Rewards: -327\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 471.3328\n            Avg Critic Loss: 1098.0688\n            =========================================\n        \n\n            =========================================\n            Timesteps: 235,628 / 2,000,000 (11.7814%)\n            Episodes: 353\n            Currently: Training cycle 5/5\n            Latest Reward: -405\n            Latest Avg Rewards: -327\n            Recent Change: 0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0014\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 470.5376\n            Avg Critic Loss: 1095.2034\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 235,817 / 2,000,000 (11.7909%)\n            Episodes: 354\n            Currently: Rollout\n            Latest Reward: -227\n            Latest Avg Rewards: -327\n            Recent Change: -0.0\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0019\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 469.6632\n            Avg Critic Loss: 1092.36\n            =========================================\n        \n\n            =========================================\n            Timesteps: 236,567 / 2,000,000 (11.8284%)\n            Episodes: 355\n            Currently: Rollout\n            Latest Reward: -219\n            Latest Avg Rewards: -326\n            Recent Change: -0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0019\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 469.6632\n            Avg Critic Loss: 1092.36\n            =========================================\n        \n\n            =========================================\n            Timesteps: 237,317 / 2,000,000 (11.8659%)\n            Episodes: 356\n            Currently: Rollout\n            Latest Reward: -234\n            Latest Avg Rewards: -326\n            Recent Change: -0.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0019\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 469.6632\n            Avg Critic Loss: 1092.36\n            =========================================\n        \n\n            =========================================\n            Timesteps: 238,067 / 2,000,000 (11.9033%)\n            Episodes: 357\n            Currently: Rollout\n            Latest Reward: -213\n            Latest Avg Rewards: -324\n            Recent Change: -0.22\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0019\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 469.6632\n            Avg Critic Loss: 1092.36\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 238,817 / 2,000,000 (11.9408%)\n            Episodes: 358\n            Currently: Rollout\n            Latest Reward: -293\n            Latest Avg Rewards: -324\n            Recent Change: -0.2\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0019\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 469.6632\n            Avg Critic Loss: 1092.36\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 238,883 / 2,000,000 (11.9442%)\n            Episodes: 359\n            Currently: Rollout\n            Latest Reward: -124\n            Latest Avg Rewards: -322\n            Recent Change: -0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0019\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 469.6632\n            Avg Critic Loss: 1092.36\n            =========================================\n        \n\n            =========================================\n            Timesteps: 239,633 / 2,000,000 (11.9817%)\n            Episodes: 360\n            Currently: Rollout\n            Latest Reward: -293\n            Latest Avg Rewards: -323\n            Recent Change: -0.42\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0019\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 469.6632\n            Avg Critic Loss: 1092.36\n            =========================================\n        \n\n            =========================================\n            Timesteps: 240,383 / 2,000,000 (12.0191%)\n            Episodes: 361\n            Currently: Rollout\n            Latest Reward: -288\n            Latest Avg Rewards: -323\n            Recent Change: -0.49\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0019\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 469.6632\n            Avg Critic Loss: 1092.36\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 241,133 / 2,000,000 (12.0566%)\n            Episodes: 362\n            Currently: Rollout\n            Latest Reward: -314\n            Latest Avg Rewards: -318\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0019\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 469.6632\n            Avg Critic Loss: 1092.36\n            =========================================\n        \n\n            =========================================\n            Timesteps: 241,133 / 2,000,000 (12.0566%)\n            Episodes: 362\n            Currently: Training cycle 1/5\n            Latest Reward: -314\n            Latest Avg Rewards: -318\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0019\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 469.6632\n            Avg Critic Loss: 1092.36\n            =========================================\n        \n\n            =========================================\n            Timesteps: 241,133 / 2,000,000 (12.0566%)\n            Episodes: 362\n            Currently: Training cycle 2/5\n            Latest Reward: -314\n            Latest Avg Rewards: -318\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 204.704\n            Avg Critic Loss: 1088.3435\n            =========================================\n        \n\n            =========================================\n            Timesteps: 241,133 / 2,000,000 (12.0566%)\n            Episodes: 362\n            Currently: Training cycle 3/5\n            Latest Reward: -314\n            Latest Avg Rewards: -318\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 204.9753\n            Avg Critic Loss: 1084.3643\n            =========================================\n        \n\n            =========================================\n            Timesteps: 241,133 / 2,000,000 (12.0566%)\n            Episodes: 362\n            Currently: Training cycle 4/5\n            Latest Reward: -314\n            Latest Avg Rewards: -318\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 204.2791\n            Avg Critic Loss: 1080.4178\n            =========================================\n        \n\n            =========================================\n            Timesteps: 241,133 / 2,000,000 (12.0566%)\n            Episodes: 362\n            Currently: Training cycle 5/5\n            Latest Reward: -314\n            Latest Avg Rewards: -318\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 202.7425\n            Avg Critic Loss: 1076.4996\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 241,883 / 2,000,000 (12.0941%)\n            Episodes: 363\n            Currently: Rollout\n            Latest Reward: -397\n            Latest Avg Rewards: -319\n            Recent Change: -0.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 200.5064\n            Avg Critic Loss: 1072.6063\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 242,633 / 2,000,000 (12.1316%)\n            Episodes: 364\n            Currently: Rollout\n            Latest Reward: -274\n            Latest Avg Rewards: -318\n            Recent Change: -0.17\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 200.5064\n            Avg Critic Loss: 1072.6063\n            =========================================\n        \n\n            =========================================\n            Timesteps: 243,383 / 2,000,000 (12.1692%)\n            Episodes: 365\n            Currently: Rollout\n            Latest Reward: -301\n            Latest Avg Rewards: -319\n            Recent Change: -0.21\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 200.5064\n            Avg Critic Loss: 1072.6063\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 243,594 / 2,000,000 (12.1797%)\n            Episodes: 366\n            Currently: Rollout\n            Latest Reward: -175\n            Latest Avg Rewards: -318\n            Recent Change: -0.32\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 200.5064\n            Avg Critic Loss: 1072.6063\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 244,344 / 2,000,000 (12.2172%)\n            Episodes: 367\n            Currently: Rollout\n            Latest Reward: -377\n            Latest Avg Rewards: -319\n            Recent Change: -0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 200.5064\n            Avg Critic Loss: 1072.6063\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 245,094 / 2,000,000 (12.2547%)\n            Episodes: 368\n            Currently: Rollout\n            Latest Reward: -420\n            Latest Avg Rewards: -321\n            Recent Change: -0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 200.5064\n            Avg Critic Loss: 1072.6063\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 245,844 / 2,000,000 (12.2922%)\n            Episodes: 369\n            Currently: Rollout\n            Latest Reward: -327\n            Latest Avg Rewards: -322\n            Recent Change: -0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 200.5064\n            Avg Critic Loss: 1072.6063\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 246,594 / 2,000,000 (12.3297%)\n            Episodes: 370\n            Currently: Rollout\n            Latest Reward: -221\n            Latest Avg Rewards: -321\n            Recent Change: -0.48\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 200.5064\n            Avg Critic Loss: 1072.6063\n            =========================================\n        \n\n            =========================================\n            Timesteps: 246,594 / 2,000,000 (12.3297%)\n            Episodes: 370\n            Currently: Training cycle 1/5\n            Latest Reward: -221\n            Latest Avg Rewards: -321\n            Recent Change: -0.48\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 200.5064\n            Avg Critic Loss: 1072.6063\n            =========================================\n        \n\n            =========================================\n            Timesteps: 246,594 / 2,000,000 (12.3297%)\n            Episodes: 370\n            Currently: Training cycle 2/5\n            Latest Reward: -221\n            Latest Avg Rewards: -321\n            Recent Change: -0.48\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 257.4317\n            Avg Critic Loss: 1068.9993\n            =========================================\n        \n\n            =========================================\n            Timesteps: 246,594 / 2,000,000 (12.3297%)\n            Episodes: 370\n            Currently: Training cycle 3/5\n            Latest Reward: -221\n            Latest Avg Rewards: -321\n            Recent Change: -0.48\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 258.2326\n            Avg Critic Loss: 1065.4277\n            =========================================\n        \n\n            =========================================\n            Timesteps: 246,594 / 2,000,000 (12.3297%)\n            Episodes: 370\n            Currently: Training cycle 4/5\n            Latest Reward: -221\n            Latest Avg Rewards: -321\n            Recent Change: -0.48\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 258.8571\n            Avg Critic Loss: 1061.8901\n            =========================================\n        \n\n            =========================================\n            Timesteps: 246,594 / 2,000,000 (12.3297%)\n            Episodes: 370\n            Currently: Training cycle 5/5\n            Latest Reward: -221\n            Latest Avg Rewards: -321\n            Recent Change: -0.48\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 259.3038\n            Avg Critic Loss: 1058.3853\n            =========================================\n        \n\n            =========================================\n            Timesteps: 247,344 / 2,000,000 (12.3672%)\n            Episodes: 371\n            Currently: Rollout\n            Latest Reward: -233\n            Latest Avg Rewards: -319\n            Recent Change: -0.41\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 259.5772\n            Avg Critic Loss: 1054.9122\n            =========================================\n        \n\n            =========================================\n            Timesteps: 248,094 / 2,000,000 (12.4047%)\n            Episodes: 372\n            Currently: Rollout\n            Latest Reward: -351\n            Latest Avg Rewards: -319\n            Recent Change: -0.4\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 259.5772\n            Avg Critic Loss: 1054.9122\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 248,627 / 2,000,000 (12.4314%)\n            Episodes: 373\n            Currently: Rollout\n            Latest Reward: -285\n            Latest Avg Rewards: -320\n            Recent Change: -0.5\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 259.5772\n            Avg Critic Loss: 1054.9122\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 249,182 / 2,000,000 (12.4591%)\n            Episodes: 374\n            Currently: Rollout\n            Latest Reward: -264\n            Latest Avg Rewards: -320\n            Recent Change: -0.54\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 259.5772\n            Avg Critic Loss: 1054.9122\n            =========================================\n        \n\n            =========================================\n            Timesteps: 249,932 / 2,000,000 (12.4966%)\n            Episodes: 375\n            Currently: Rollout\n            Latest Reward: -399\n            Latest Avg Rewards: -322\n            Recent Change: -0.59\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 259.5772\n            Avg Critic Loss: 1054.9122\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 250,682 / 2,000,000 (12.5341%)\n            Episodes: 376\n            Currently: Rollout\n            Latest Reward: -211\n            Latest Avg Rewards: -321\n            Recent Change: -0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 259.5772\n            Avg Critic Loss: 1054.9122\n            =========================================\n        \n\n            =========================================\n            Timesteps: 251,432 / 2,000,000 (12.5716%)\n            Episodes: 377\n            Currently: Rollout\n            Latest Reward: -244\n            Latest Avg Rewards: -320\n            Recent Change: -0.72\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 259.5772\n            Avg Critic Loss: 1054.9122\n            =========================================\n        \n\n            =========================================\n            Timesteps: 252,182 / 2,000,000 (12.6091%)\n            Episodes: 378\n            Currently: Rollout\n            Latest Reward: -258\n            Latest Avg Rewards: -320\n            Recent Change: -0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 259.5772\n            Avg Critic Loss: 1054.9122\n            =========================================\n        \n\n            =========================================\n            Timesteps: 252,182 / 2,000,000 (12.6091%)\n            Episodes: 378\n            Currently: Training cycle 1/5\n            Latest Reward: -258\n            Latest Avg Rewards: -320\n            Recent Change: -0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.001\n            Latest Critic Loss: 259.5772\n            Avg Critic Loss: 1054.9122\n            =========================================\n        \n\n            =========================================\n            Timesteps: 252,182 / 2,000,000 (12.6091%)\n            Episodes: 378\n            Currently: Training cycle 2/5\n            Latest Reward: -258\n            Latest Avg Rewards: -320\n            Recent Change: -0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 183.2642\n            Avg Critic Loss: 1051.1389\n            =========================================\n        \n\n            =========================================\n            Timesteps: 252,182 / 2,000,000 (12.6091%)\n            Episodes: 378\n            Currently: Training cycle 3/5\n            Latest Reward: -258\n            Latest Avg Rewards: -320\n            Recent Change: -0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 182.8054\n            Avg Critic Loss: 1047.3961\n            =========================================\n        \n\n            =========================================\n            Timesteps: 252,182 / 2,000,000 (12.6091%)\n            Episodes: 378\n            Currently: Training cycle 4/5\n            Latest Reward: -258\n            Latest Avg Rewards: -320\n            Recent Change: -0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0009\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 182.1663\n            Avg Critic Loss: 1043.6826\n            =========================================\n        \n\n            =========================================\n            Timesteps: 252,182 / 2,000,000 (12.6091%)\n            Episodes: 378\n            Currently: Training cycle 5/5\n            Latest Reward: -258\n            Latest Avg Rewards: -320\n            Recent Change: -0.76\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0014\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 181.3798\n            Avg Critic Loss: 1039.9976\n            =========================================\n        \n\n            =========================================\n            Timesteps: 252,932 / 2,000,000 (12.6466%)\n            Episodes: 379\n            Currently: Rollout\n            Latest Reward: -374\n            Latest Avg Rewards: -321\n            Recent Change: -0.78\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 180.4786\n            Avg Critic Loss: 1036.34\n            =========================================\n        \n\n            =========================================\n            Timesteps: 253,682 / 2,000,000 (12.6841%)\n            Episodes: 380\n            Currently: Rollout\n            Latest Reward: -265\n            Latest Avg Rewards: -318\n            Recent Change: -0.67\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 180.4786\n            Avg Critic Loss: 1036.34\n            =========================================\n        \n\n            =========================================\n            Timesteps: 254,432 / 2,000,000 (12.7216%)\n            Episodes: 381\n            Currently: Rollout\n            Latest Reward: -229\n            Latest Avg Rewards: -319\n            Recent Change: -0.8\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 180.4786\n            Avg Critic Loss: 1036.34\n            =========================================\n        \n\n            =========================================\n            Timesteps: 255,182 / 2,000,000 (12.7591%)\n            Episodes: 382\n            Currently: Rollout\n            Latest Reward: -256\n            Latest Avg Rewards: -315\n            Recent Change: -0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 180.4786\n            Avg Critic Loss: 1036.34\n            =========================================\n        \n\n            =========================================\n            Timesteps: 255,202 / 2,000,000 (12.7601%)\n            Episodes: 383\n            Currently: Rollout\n            Latest Reward: -109\n            Latest Avg Rewards: -313\n            Recent Change: -0.77\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 180.4786\n            Avg Critic Loss: 1036.34\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 255,952 / 2,000,000 (12.7976%)\n            Episodes: 384\n            Currently: Rollout\n            Latest Reward: -237\n            Latest Avg Rewards: -312\n            Recent Change: -0.83\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 180.4786\n            Avg Critic Loss: 1036.34\n            =========================================\n        \n\n            =========================================\n            Timesteps: 256,702 / 2,000,000 (12.8351%)\n            Episodes: 385\n            Currently: Rollout\n            Latest Reward: -547\n            Latest Avg Rewards: -313\n            Recent Change: -0.57\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 180.4786\n            Avg Critic Loss: 1036.34\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 257,171 / 2,000,000 (12.8585%)\n            Episodes: 386\n            Currently: Rollout\n            Latest Reward: -256\n            Latest Avg Rewards: -313\n            Recent Change: -0.66\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 180.4786\n            Avg Critic Loss: 1036.34\n            =========================================\n        \n\n            =========================================\n            Timesteps: 257,921 / 2,000,000 (12.8961%)\n            Episodes: 387\n            Currently: Rollout\n            Latest Reward: -439\n            Latest Avg Rewards: -314\n            Recent Change: -0.54\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 180.4786\n            Avg Critic Loss: 1036.34\n            =========================================\n        \n\n            =========================================\n            Timesteps: 257,921 / 2,000,000 (12.8961%)\n            Episodes: 387\n            Currently: Training cycle 1/5\n            Latest Reward: -439\n            Latest Avg Rewards: -314\n            Recent Change: -0.54\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 180.4786\n            Avg Critic Loss: 1036.34\n            =========================================\n        \n\n            =========================================\n            Timesteps: 257,921 / 2,000,000 (12.8961%)\n            Episodes: 387\n            Currently: Training cycle 2/5\n            Latest Reward: -439\n            Latest Avg Rewards: -314\n            Recent Change: -0.54\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 363.5678\n            Avg Critic Loss: 1033.4893\n            =========================================\n        \n\n            =========================================\n            Timesteps: 257,921 / 2,000,000 (12.8961%)\n            Episodes: 387\n            Currently: Training cycle 3/5\n            Latest Reward: -439\n            Latest Avg Rewards: -314\n            Recent Change: -0.54\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.015\n            Avg Critic Loss: 1030.6645\n            =========================================\n        \n\n            =========================================\n            Timesteps: 257,921 / 2,000,000 (12.8961%)\n            Episodes: 387\n            Currently: Training cycle 4/5\n            Latest Reward: -439\n            Latest Avg Rewards: -314\n            Recent Change: -0.54\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.2637\n            Avg Critic Loss: 1027.8645\n            =========================================\n        \n\n            =========================================\n            Timesteps: 257,921 / 2,000,000 (12.8961%)\n            Episodes: 387\n            Currently: Training cycle 5/5\n            Latest Reward: -439\n            Latest Avg Rewards: -314\n            Recent Change: -0.54\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.3251\n            Avg Critic Loss: 1025.0882\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 258,671 / 2,000,000 (12.9335%)\n            Episodes: 388\n            Currently: Rollout\n            Latest Reward: -234\n            Latest Avg Rewards: -312\n            Recent Change: -0.54\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.2123\n            Avg Critic Loss: 1022.3346\n            =========================================\n        \n\n            =========================================\n            Timesteps: 258,706 / 2,000,000 (12.9353%)\n            Episodes: 389\n            Currently: Rollout\n            Latest Reward: -115\n            Latest Avg Rewards: -308\n            Recent Change: -0.53\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.2123\n            Avg Critic Loss: 1022.3346\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 259,456 / 2,000,000 (12.9728%)\n            Episodes: 390\n            Currently: Rollout\n            Latest Reward: -193\n            Latest Avg Rewards: -307\n            Recent Change: -0.63\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.2123\n            Avg Critic Loss: 1022.3346\n            =========================================\n        \n\n            =========================================\n            Timesteps: 260,206 / 2,000,000 (13.0103%)\n            Episodes: 391\n            Currently: Rollout\n            Latest Reward: -308\n            Latest Avg Rewards: -306\n            Recent Change: -0.55\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.2123\n            Avg Critic Loss: 1022.3346\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 260,956 / 2,000,000 (13.0478%)\n            Episodes: 392\n            Currently: Rollout\n            Latest Reward: -397\n            Latest Avg Rewards: -306\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.2123\n            Avg Critic Loss: 1022.3346\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 261,706 / 2,000,000 (13.0853%)\n            Episodes: 393\n            Currently: Rollout\n            Latest Reward: -248\n            Latest Avg Rewards: -307\n            Recent Change: -0.54\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.2123\n            Avg Critic Loss: 1022.3346\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 262,456 / 2,000,000 (13.1228%)\n            Episodes: 394\n            Currently: Rollout\n            Latest Reward: -525\n            Latest Avg Rewards: -309\n            Recent Change: -0.44\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.2123\n            Avg Critic Loss: 1022.3346\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 263,206 / 2,000,000 (13.1603%)\n            Episodes: 395\n            Currently: Rollout\n            Latest Reward: -476\n            Latest Avg Rewards: -311\n            Recent Change: -0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.2123\n            Avg Critic Loss: 1022.3346\n            =========================================\n        \n\n            =========================================\n            Timesteps: 263,206 / 2,000,000 (13.1603%)\n            Episodes: 395\n            Currently: Training cycle 1/5\n            Latest Reward: -476\n            Latest Avg Rewards: -311\n            Recent Change: -0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 364.2123\n            Avg Critic Loss: 1022.3346\n            =========================================\n        \n\n            =========================================\n            Timesteps: 263,206 / 2,000,000 (13.1603%)\n            Episodes: 395\n            Currently: Training cycle 2/5\n            Latest Reward: -476\n            Latest Avg Rewards: -311\n            Recent Change: -0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 318.0482\n            Avg Critic Loss: 1019.4122\n            =========================================\n        \n\n            =========================================\n            Timesteps: 263,206 / 2,000,000 (13.1603%)\n            Episodes: 395\n            Currently: Training cycle 3/5\n            Latest Reward: -476\n            Latest Avg Rewards: -311\n            Recent Change: -0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 317.6692\n            Avg Critic Loss: 1016.5124\n            =========================================\n        \n\n            =========================================\n            Timesteps: 263,206 / 2,000,000 (13.1603%)\n            Episodes: 395\n            Currently: Training cycle 4/5\n            Latest Reward: -476\n            Latest Avg Rewards: -311\n            Recent Change: -0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 317.1459\n            Avg Critic Loss: 1013.6344\n            =========================================\n        \n\n            =========================================\n            Timesteps: 263,206 / 2,000,000 (13.1603%)\n            Episodes: 395\n            Currently: Training cycle 5/5\n            Latest Reward: -476\n            Latest Avg Rewards: -311\n            Recent Change: -0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 316.4987\n            Avg Critic Loss: 1010.7773\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 263,956 / 2,000,000 (13.1978%)\n            Episodes: 396\n            Currently: Rollout\n            Latest Reward: -293\n            Latest Avg Rewards: -311\n            Recent Change: -0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0011\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 315.7475\n            Avg Critic Loss: 1007.9404\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 264,706 / 2,000,000 (13.2353%)\n            Episodes: 397\n            Currently: Rollout\n            Latest Reward: -498\n            Latest Avg Rewards: -313\n            Recent Change: -0.28\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0011\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 315.7475\n            Avg Critic Loss: 1007.9404\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 265,456 / 2,000,000 (13.2728%)\n            Episodes: 398\n            Currently: Rollout\n            Latest Reward: -235\n            Latest Avg Rewards: -311\n            Recent Change: -0.23\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0011\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 315.7475\n            Avg Critic Loss: 1007.9404\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 266,206 / 2,000,000 (13.3103%)\n            Episodes: 399\n            Currently: Rollout\n            Latest Reward: -331\n            Latest Avg Rewards: -307\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0011\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 315.7475\n            Avg Critic Loss: 1007.9404\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 266,956 / 2,000,000 (13.3478%)\n            Episodes: 400\n            Currently: Rollout\n            Latest Reward: -543\n            Latest Avg Rewards: -309\n            Recent Change: 0.18\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0011\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 315.7475\n            Avg Critic Loss: 1007.9404\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 267,706 / 2,000,000 (13.3853%)\n            Episodes: 401\n            Currently: Rollout\n            Latest Reward: -346\n            Latest Avg Rewards: -310\n            Recent Change: 0.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0011\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 315.7475\n            Avg Critic Loss: 1007.9404\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 268,456 / 2,000,000 (13.4228%)\n            Episodes: 402\n            Currently: Rollout\n            Latest Reward: -318\n            Latest Avg Rewards: -311\n            Recent Change: 0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0011\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 315.7475\n            Avg Critic Loss: 1007.9404\n            =========================================\n        \n\n            =========================================\n            Timesteps: 268,456 / 2,000,000 (13.4228%)\n            Episodes: 402\n            Currently: Training cycle 1/5\n            Latest Reward: -318\n            Latest Avg Rewards: -311\n            Recent Change: 0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0011\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 315.7475\n            Avg Critic Loss: 1007.9404\n            =========================================\n        \n\n            =========================================\n            Timesteps: 268,456 / 2,000,000 (13.4228%)\n            Episodes: 402\n            Currently: Training cycle 2/5\n            Latest Reward: -318\n            Latest Avg Rewards: -311\n            Recent Change: 0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 537.9633\n            Avg Critic Loss: 1006.0299\n            =========================================\n        \n\n            =========================================\n            Timesteps: 268,456 / 2,000,000 (13.4228%)\n            Episodes: 402\n            Currently: Training cycle 3/5\n            Latest Reward: -318\n            Latest Avg Rewards: -311\n            Recent Change: 0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 536.4384\n            Avg Critic Loss: 1004.1288\n            =========================================\n        \n\n            =========================================\n            Timesteps: 268,456 / 2,000,000 (13.4228%)\n            Episodes: 402\n            Currently: Training cycle 4/5\n            Latest Reward: -318\n            Latest Avg Rewards: -311\n            Recent Change: 0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 534.3483\n            Avg Critic Loss: 1002.2345\n            =========================================\n        \n\n            =========================================\n            Timesteps: 268,456 / 2,000,000 (13.4228%)\n            Episodes: 402\n            Currently: Training cycle 5/5\n            Latest Reward: -318\n            Latest Avg Rewards: -311\n            Recent Change: 0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 531.7993\n            Avg Critic Loss: 1000.3452\n            =========================================\n        \n\n            =========================================\n            Timesteps: 268,456 / 2,000,000 (13.4228%)\n            Episodes: 402\n            Currently: Saving\n            Latest Reward: -318\n            Latest Avg Rewards: -311\n            Recent Change: 0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 528.8923\n            Avg Critic Loss: 998.4594\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 269,206 / 2,000,000 (13.4603%)\n            Episodes: 403\n            Currently: Rollout\n            Latest Reward: -330\n            Latest Avg Rewards: -312\n            Recent Change: 0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 528.8923\n            Avg Critic Loss: 998.4594\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 269,956 / 2,000,000 (13.4978%)\n            Episodes: 404\n            Currently: Rollout\n            Latest Reward: -232\n            Latest Avg Rewards: -312\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 528.8923\n            Avg Critic Loss: 998.4594\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 270,037 / 2,000,000 (13.5019%)\n            Episodes: 405\n            Currently: Rollout\n            Latest Reward: -136\n            Latest Avg Rewards: -311\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 528.8923\n            Avg Critic Loss: 998.4594\n            =========================================\n        \n\n            =========================================\n            Timesteps: 270,787 / 2,000,000 (13.5394%)\n            Episodes: 406\n            Currently: Rollout\n            Latest Reward: -248\n            Latest Avg Rewards: -309\n            Recent Change: -0.09\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 528.8923\n            Avg Critic Loss: 998.4594\n            =========================================\n        \n\n            =========================================\n            Timesteps: 270,817 / 2,000,000 (13.5408%)\n            Episodes: 407\n            Currently: Rollout\n            Latest Reward: -113\n            Latest Avg Rewards: -306\n            Recent Change: -0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 528.8923\n            Avg Critic Loss: 998.4594\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 271,567 / 2,000,000 (13.5784%)\n            Episodes: 408\n            Currently: Rollout\n            Latest Reward: -323\n            Latest Avg Rewards: -307\n            Recent Change: -0.19\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 528.8923\n            Avg Critic Loss: 998.4594\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 272,317 / 2,000,000 (13.6158%)\n            Episodes: 409\n            Currently: Rollout\n            Latest Reward: -235\n            Latest Avg Rewards: -306\n            Recent Change: -0.22\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 528.8923\n            Avg Critic Loss: 998.4594\n            =========================================\n        \n\n            =========================================\n            Timesteps: 273,067 / 2,000,000 (13.6533%)\n            Episodes: 410\n            Currently: Rollout\n            Latest Reward: -288\n            Latest Avg Rewards: -304\n            Recent Change: -0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 528.8923\n            Avg Critic Loss: 998.4594\n            =========================================\n        \n\n            =========================================\n            Timesteps: 273,817 / 2,000,000 (13.6908%)\n            Episodes: 411\n            Currently: Rollout\n            Latest Reward: -260\n            Latest Avg Rewards: -306\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 528.8923\n            Avg Critic Loss: 998.4594\n            =========================================\n        \n\n            =========================================\n            Timesteps: 273,817 / 2,000,000 (13.6908%)\n            Episodes: 411\n            Currently: Training cycle 1/5\n            Latest Reward: -260\n            Latest Avg Rewards: -306\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 528.8923\n            Avg Critic Loss: 998.4594\n            =========================================\n        \n\n            =========================================\n            Timesteps: 273,817 / 2,000,000 (13.6908%)\n            Episodes: 411\n            Currently: Training cycle 2/5\n            Latest Reward: -260\n            Latest Avg Rewards: -306\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 203.6167\n            Avg Critic Loss: 995.2927\n            =========================================\n        \n\n            =========================================\n            Timesteps: 273,817 / 2,000,000 (13.6908%)\n            Episodes: 411\n            Currently: Training cycle 3/5\n            Latest Reward: -260\n            Latest Avg Rewards: -306\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 205.564\n            Avg Critic Loss: 992.1588\n            =========================================\n        \n\n            =========================================\n            Timesteps: 273,817 / 2,000,000 (13.6908%)\n            Episodes: 411\n            Currently: Training cycle 4/5\n            Latest Reward: -260\n            Latest Avg Rewards: -306\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 206.7018\n            Avg Critic Loss: 989.0543\n            =========================================\n        \n\n            =========================================\n            Timesteps: 273,817 / 2,000,000 (13.6908%)\n            Episodes: 411\n            Currently: Training cycle 5/5\n            Latest Reward: -260\n            Latest Avg Rewards: -306\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 207.06\n            Avg Critic Loss: 985.9755\n            =========================================\n        \n\n            =========================================\n            Timesteps: 274,567 / 2,000,000 (13.7284%)\n            Episodes: 412\n            Currently: Rollout\n            Latest Reward: -199\n            Latest Avg Rewards: -304\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 206.6982\n            Avg Critic Loss: 982.9195\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 275,317 / 2,000,000 (13.7658%)\n            Episodes: 413\n            Currently: Rollout\n            Latest Reward: -472\n            Latest Avg Rewards: -303\n            Recent Change: -0.07\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 206.6982\n            Avg Critic Loss: 982.9195\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 276,067 / 2,000,000 (13.8034%)\n            Episodes: 414\n            Currently: Rollout\n            Latest Reward: -237\n            Latest Avg Rewards: -303\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 206.6982\n            Avg Critic Loss: 982.9195\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 276,259 / 2,000,000 (13.8129%)\n            Episodes: 415\n            Currently: Rollout\n            Latest Reward: -159\n            Latest Avg Rewards: -303\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 206.6982\n            Avg Critic Loss: 982.9195\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 277,009 / 2,000,000 (13.8505%)\n            Episodes: 416\n            Currently: Rollout\n            Latest Reward: -373\n            Latest Avg Rewards: -305\n            Recent Change: -0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 206.6982\n            Avg Critic Loss: 982.9195\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 277,759 / 2,000,000 (13.8879%)\n            Episodes: 417\n            Currently: Rollout\n            Latest Reward: -265\n            Latest Avg Rewards: -305\n            Recent Change: -0.39\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 206.6982\n            Avg Critic Loss: 982.9195\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 278,509 / 2,000,000 (13.9254%)\n            Episodes: 418\n            Currently: Rollout\n            Latest Reward: -193\n            Latest Avg Rewards: -303\n            Recent Change: -0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 206.6982\n            Avg Critic Loss: 982.9195\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 279,259 / 2,000,000 (13.9629%)\n            Episodes: 419\n            Currently: Rollout\n            Latest Reward: -357\n            Latest Avg Rewards: -305\n            Recent Change: -0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 206.6982\n            Avg Critic Loss: 982.9195\n            =========================================\n        \n\n            =========================================\n            Timesteps: 279,259 / 2,000,000 (13.9629%)\n            Episodes: 419\n            Currently: Training cycle 1/5\n            Latest Reward: -357\n            Latest Avg Rewards: -305\n            Recent Change: -0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 206.6982\n            Avg Critic Loss: 982.9195\n            =========================================\n        \n\n            =========================================\n            Timesteps: 279,259 / 2,000,000 (13.9629%)\n            Episodes: 419\n            Currently: Training cycle 2/5\n            Latest Reward: -357\n            Latest Avg Rewards: -305\n            Recent Change: -0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 340.5053\n            Avg Critic Loss: 980.4101\n            =========================================\n        \n\n            =========================================\n            Timesteps: 279,259 / 2,000,000 (13.9629%)\n            Episodes: 419\n            Currently: Training cycle 3/5\n            Latest Reward: -357\n            Latest Avg Rewards: -305\n            Recent Change: -0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 339.494\n            Avg Critic Loss: 977.9163\n            =========================================\n        \n\n            =========================================\n            Timesteps: 279,259 / 2,000,000 (13.9629%)\n            Episodes: 419\n            Currently: Training cycle 4/5\n            Latest Reward: -357\n            Latest Avg Rewards: -305\n            Recent Change: -0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0009\n            Latest Critic Loss: 338.2118\n            Avg Critic Loss: 975.4368\n            =========================================\n        \n\n            =========================================\n            Timesteps: 279,259 / 2,000,000 (13.9629%)\n            Episodes: 419\n            Currently: Training cycle 5/5\n            Latest Reward: -357\n            Latest Avg Rewards: -305\n            Recent Change: -0.43\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 336.7209\n            Avg Critic Loss: 972.9707\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 280,009 / 2,000,000 (14.0005%)\n            Episodes: 420\n            Currently: Rollout\n            Latest Reward: -370\n            Latest Avg Rewards: -305\n            Recent Change: -0.38\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 335.0808\n            Avg Critic Loss: 970.5173\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 280,759 / 2,000,000 (14.0379%)\n            Episodes: 421\n            Currently: Rollout\n            Latest Reward: -307\n            Latest Avg Rewards: -305\n            Recent Change: -0.38\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 335.0808\n            Avg Critic Loss: 970.5173\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 281,509 / 2,000,000 (14.0755%)\n            Episodes: 422\n            Currently: Rollout\n            Latest Reward: -308\n            Latest Avg Rewards: -306\n            Recent Change: -0.42\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 335.0808\n            Avg Critic Loss: 970.5173\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 282,259 / 2,000,000 (14.1129%)\n            Episodes: 423\n            Currently: Rollout\n            Latest Reward: -271\n            Latest Avg Rewards: -305\n            Recent Change: -0.41\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 335.0808\n            Avg Critic Loss: 970.5173\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 283,009 / 2,000,000 (14.1505%)\n            Episodes: 424\n            Currently: Rollout\n            Latest Reward: -552\n            Latest Avg Rewards: -306\n            Recent Change: -0.18\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 335.0808\n            Avg Critic Loss: 970.5173\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 283,759 / 2,000,000 (14.1879%)\n            Episodes: 425\n            Currently: Rollout\n            Latest Reward: -321\n            Latest Avg Rewards: -305\n            Recent Change: -0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 335.0808\n            Avg Critic Loss: 970.5173\n            =========================================\n        \n\n            =========================================\n            Timesteps: 284,509 / 2,000,000 (14.2255%)\n            Episodes: 426\n            Currently: Rollout\n            Latest Reward: -369\n            Latest Avg Rewards: -305\n            Recent Change: -0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 335.0808\n            Avg Critic Loss: 970.5173\n            =========================================\n        \n\n            =========================================\n            Timesteps: 284,509 / 2,000,000 (14.2255%)\n            Episodes: 426\n            Currently: Training cycle 1/5\n            Latest Reward: -369\n            Latest Avg Rewards: -305\n            Recent Change: -0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 335.0808\n            Avg Critic Loss: 970.5173\n            =========================================\n        \n\n            =========================================\n            Timesteps: 284,509 / 2,000,000 (14.2255%)\n            Episodes: 426\n            Currently: Training cycle 2/5\n            Latest Reward: -369\n            Latest Avg Rewards: -305\n            Recent Change: -0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 384.5122\n            Avg Critic Loss: 968.2721\n            =========================================\n        \n\n            =========================================\n            Timesteps: 284,509 / 2,000,000 (14.2255%)\n            Episodes: 426\n            Currently: Training cycle 3/5\n            Latest Reward: -369\n            Latest Avg Rewards: -305\n            Recent Change: -0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 385.8167\n            Avg Critic Loss: 966.049\n            =========================================\n        \n\n            =========================================\n            Timesteps: 284,509 / 2,000,000 (14.2255%)\n            Episodes: 426\n            Currently: Training cycle 4/5\n            Latest Reward: -369\n            Latest Avg Rewards: -305\n            Recent Change: -0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 386.6691\n            Avg Critic Loss: 963.846\n            =========================================\n        \n\n            =========================================\n            Timesteps: 284,509 / 2,000,000 (14.2255%)\n            Episodes: 426\n            Currently: Training cycle 5/5\n            Latest Reward: -369\n            Latest Avg Rewards: -305\n            Recent Change: -0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0005\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 387.0895\n            Avg Critic Loss: 961.6613\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 285,259 / 2,000,000 (14.263%)\n            Episodes: 427\n            Currently: Rollout\n            Latest Reward: -308\n            Latest Avg Rewards: -306\n            Recent Change: -0.06\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 387.1099\n            Avg Critic Loss: 959.4932\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 286,009 / 2,000,000 (14.3005%)\n            Episodes: 428\n            Currently: Rollout\n            Latest Reward: -269\n            Latest Avg Rewards: -304\n            Recent Change: -0.03\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 387.1099\n            Avg Critic Loss: 959.4932\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 286,759 / 2,000,000 (14.3379%)\n            Episodes: 429\n            Currently: Rollout\n            Latest Reward: -417\n            Latest Avg Rewards: -306\n            Recent Change: 0.0\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 387.1099\n            Avg Critic Loss: 959.4932\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 286,832 / 2,000,000 (14.3416%)\n            Episodes: 430\n            Currently: Rollout\n            Latest Reward: -138\n            Latest Avg Rewards: -304\n            Recent Change: -0.1\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 387.1099\n            Avg Critic Loss: 959.4932\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 286,954 / 2,000,000 (14.3477%)\n            Episodes: 431\n            Currently: Rollout\n            Latest Reward: -144\n            Latest Avg Rewards: -302\n            Recent Change: -0.17\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 387.1099\n            Avg Critic Loss: 959.4932\n            =========================================\n        \n\n            =========================================\n            Timesteps: 287,704 / 2,000,000 (14.3852%)\n            Episodes: 432\n            Currently: Rollout\n            Latest Reward: -192\n            Latest Avg Rewards: -302\n            Recent Change: -0.26\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 387.1099\n            Avg Critic Loss: 959.4932\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 288,454 / 2,000,000 (14.4227%)\n            Episodes: 433\n            Currently: Rollout\n            Latest Reward: -430\n            Latest Avg Rewards: -302\n            Recent Change: -0.11\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 387.1099\n            Avg Critic Loss: 959.4932\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 289,204 / 2,000,000 (14.4602%)\n            Episodes: 434\n            Currently: Rollout\n            Latest Reward: -264\n            Latest Avg Rewards: -302\n            Recent Change: -0.2\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 387.1099\n            Avg Critic Loss: 959.4932\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 289,954 / 2,000,000 (14.4977%)\n            Episodes: 435\n            Currently: Rollout\n            Latest Reward: -269\n            Latest Avg Rewards: -301\n            Recent Change: -0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 387.1099\n            Avg Critic Loss: 959.4932\n            =========================================\n        \n\n            =========================================\n            Timesteps: 289,954 / 2,000,000 (14.4977%)\n            Episodes: 435\n            Currently: Training cycle 1/5\n            Latest Reward: -269\n            Latest Avg Rewards: -301\n            Recent Change: -0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 387.1099\n            Avg Critic Loss: 959.4932\n            =========================================\n        \n\n            =========================================\n            Timesteps: 289,954 / 2,000,000 (14.4977%)\n            Episodes: 435\n            Currently: Training cycle 2/5\n            Latest Reward: -269\n            Latest Avg Rewards: -301\n            Recent Change: -0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.9295\n            Avg Critic Loss: 956.8332\n            =========================================\n        \n\n            =========================================\n            Timesteps: 289,954 / 2,000,000 (14.4977%)\n            Episodes: 435\n            Currently: Training cycle 3/5\n            Latest Reward: -269\n            Latest Avg Rewards: -301\n            Recent Change: -0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.9792\n            Avg Critic Loss: 954.1933\n            =========================================\n        \n\n            =========================================\n            Timesteps: 289,954 / 2,000,000 (14.4977%)\n            Episodes: 435\n            Currently: Training cycle 4/5\n            Latest Reward: -269\n            Latest Avg Rewards: -301\n            Recent Change: -0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.856\n            Avg Critic Loss: 951.5726\n            =========================================\n        \n\n            =========================================\n            Timesteps: 289,954 / 2,000,000 (14.4977%)\n            Episodes: 435\n            Currently: Training cycle 5/5\n            Latest Reward: -269\n            Latest Avg Rewards: -301\n            Recent Change: -0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.5805\n            Avg Critic Loss: 948.9704\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 incorrectly sorted into sorting_two\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 290,704 / 2,000,000 (14.5352%)\n            Episodes: 436\n            Currently: Rollout\n            Latest Reward: -397\n            Latest Avg Rewards: -303\n            Recent Change: -0.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.1757\n            Avg Critic Loss: 946.386\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 291,454 / 2,000,000 (14.5727%)\n            Episodes: 437\n            Currently: Rollout\n            Latest Reward: -266\n            Latest Avg Rewards: -302\n            Recent Change: -0.13\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.1757\n            Avg Critic Loss: 946.386\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 292,204 / 2,000,000 (14.6102%)\n            Episodes: 438\n            Currently: Rollout\n            Latest Reward: -385\n            Latest Avg Rewards: -303\n            Recent Change: -0.12\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.1757\n            Avg Critic Loss: 946.386\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 292,274 / 2,000,000 (14.6137%)\n            Episodes: 439\n            Currently: Rollout\n            Latest Reward: -127\n            Latest Avg Rewards: -303\n            Recent Change: -0.34\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.1757\n            Avg Critic Loss: 946.386\n            =========================================\n        \n\n            =========================================\n            Timesteps: 293,024 / 2,000,000 (14.6512%)\n            Episodes: 440\n            Currently: Rollout\n            Latest Reward: -244\n            Latest Avg Rewards: -302\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.1757\n            Avg Critic Loss: 946.386\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 293,774 / 2,000,000 (14.6887%)\n            Episodes: 441\n            Currently: Rollout\n            Latest Reward: -445\n            Latest Avg Rewards: -301\n            Recent Change: -0.08\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.1757\n            Avg Critic Loss: 946.386\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 294,524 / 2,000,000 (14.7262%)\n            Episodes: 442\n            Currently: Rollout\n            Latest Reward: -270\n            Latest Avg Rewards: -299\n            Recent Change: 0.02\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.1757\n            Avg Critic Loss: 946.386\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 295,274 / 2,000,000 (14.7637%)\n            Episodes: 443\n            Currently: Rollout\n            Latest Reward: -186\n            Latest Avg Rewards: -298\n            Recent Change: -0.05\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.1757\n            Avg Critic Loss: 946.386\n            =========================================\n        \n\n            =========================================\n            Timesteps: 295,274 / 2,000,000 (14.7637%)\n            Episodes: 443\n            Currently: Training cycle 1/5\n            Latest Reward: -186\n            Latest Avg Rewards: -298\n            Recent Change: -0.05\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 251.1757\n            Avg Critic Loss: 946.386\n            =========================================\n        \n\n            =========================================\n            Timesteps: 295,274 / 2,000,000 (14.7637%)\n            Episodes: 443\n            Currently: Training cycle 2/5\n            Latest Reward: -186\n            Latest Avg Rewards: -298\n            Recent Change: -0.05\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 282.8337\n            Avg Critic Loss: 943.9375\n            =========================================\n        \n\n            =========================================\n            Timesteps: 295,274 / 2,000,000 (14.7637%)\n            Episodes: 443\n            Currently: Training cycle 3/5\n            Latest Reward: -186\n            Latest Avg Rewards: -298\n            Recent Change: -0.05\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 282.473\n            Avg Critic Loss: 941.5056\n            =========================================\n        \n\n            =========================================\n            Timesteps: 295,274 / 2,000,000 (14.7637%)\n            Episodes: 443\n            Currently: Training cycle 4/5\n            Latest Reward: -186\n            Latest Avg Rewards: -298\n            Recent Change: -0.05\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 282.0738\n            Avg Critic Loss: 939.0901\n            =========================================\n        \n\n            =========================================\n            Timesteps: 295,274 / 2,000,000 (14.7637%)\n            Episodes: 443\n            Currently: Training cycle 5/5\n            Latest Reward: -186\n            Latest Avg Rewards: -298\n            Recent Change: -0.05\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0008\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.6498\n            Avg Critic Loss: 936.6907\n            =========================================\n        \n\n            =========================================\n            Timesteps: 296,024 / 2,000,000 (14.8012%)\n            Episodes: 444\n            Currently: Rollout\n            Latest Reward: -327\n            Latest Avg Rewards: -298\n            Recent Change: -0.04\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.2134\n            Avg Critic Loss: 934.3071\n            =========================================\n        \n\n            =========================================\n            Timesteps: 296,053 / 2,000,000 (14.8026%)\n            Episodes: 445\n            Currently: Rollout\n            Latest Reward: -112\n            Latest Avg Rewards: -296\n            Recent Change: -0.14\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.2134\n            Avg Critic Loss: 934.3071\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 296,095 / 2,000,000 (14.8048%)\n            Episodes: 446\n            Currently: Rollout\n            Latest Reward: -118\n            Latest Avg Rewards: -295\n            Recent Change: -0.29\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.2134\n            Avg Critic Loss: 934.3071\n            =========================================\n        \n\n            =========================================\n            Timesteps: 296,845 / 2,000,000 (14.8423%)\n            Episodes: 447\n            Currently: Rollout\n            Latest Reward: -288\n            Latest Avg Rewards: -295\n            Recent Change: -0.28\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.2134\n            Avg Critic Loss: 934.3071\n            =========================================\n        \n\n            =========================================\n            Timesteps: 297,595 / 2,000,000 (14.8797%)\n            Episodes: 448\n            Currently: Rollout\n            Latest Reward: -351\n            Latest Avg Rewards: -295\n            Recent Change: -0.27\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.2134\n            Avg Critic Loss: 934.3071\n            =========================================\n        \n\n            =========================================\n            Timesteps: 298,345 / 2,000,000 (14.9173%)\n            Episodes: 449\n            Currently: Rollout\n            Latest Reward: -222\n            Latest Avg Rewards: -295\n            Recent Change: -0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.2134\n            Avg Critic Loss: 934.3071\n            =========================================\n        \n\n            =========================================\n            Timesteps: 299,095 / 2,000,000 (14.9548%)\n            Episodes: 450\n            Currently: Rollout\n            Latest Reward: -342\n            Latest Avg Rewards: -296\n            Recent Change: -0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.2134\n            Avg Critic Loss: 934.3071\n            =========================================\n        \n\n            =========================================\n            Timesteps: 299,845 / 2,000,000 (14.9922%)\n            Episodes: 451\n            Currently: Rollout\n            Latest Reward: -487\n            Latest Avg Rewards: -295\n            Recent Change: -0.02\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.2134\n            Avg Critic Loss: 934.3071\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 300,128 / 2,000,000 (15.0064%)\n            Episodes: 452\n            Currently: Rollout\n            Latest Reward: -202\n            Latest Avg Rewards: -292\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.2134\n            Avg Critic Loss: 934.3071\n            =========================================\n        \n\n            =========================================\n            Timesteps: 300,878 / 2,000,000 (15.0439%)\n            Episodes: 453\n            Currently: Rollout\n            Latest Reward: -194\n            Latest Avg Rewards: -290\n            Recent Change: 0.02\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.2134\n            Avg Critic Loss: 934.3071\n            =========================================\n        \n\n            =========================================\n            Timesteps: 300,878 / 2,000,000 (15.0439%)\n            Episodes: 453\n            Currently: Training cycle 1/5\n            Latest Reward: -194\n            Latest Avg Rewards: -290\n            Recent Change: 0.02\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0013\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 281.2134\n            Avg Critic Loss: 934.3071\n            =========================================\n        \n\n            =========================================\n            Timesteps: 300,878 / 2,000,000 (15.0439%)\n            Episodes: 453\n            Currently: Training cycle 2/5\n            Latest Reward: -194\n            Latest Avg Rewards: -290\n            Recent Change: 0.02\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 241.4415\n            Avg Critic Loss: 931.7967\n            =========================================\n        \n\n            =========================================\n            Timesteps: 300,878 / 2,000,000 (15.0439%)\n            Episodes: 453\n            Currently: Training cycle 3/5\n            Latest Reward: -194\n            Latest Avg Rewards: -290\n            Recent Change: 0.02\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 241.9165\n            Avg Critic Loss: 929.3062\n            =========================================\n        \n\n            =========================================\n            Timesteps: 300,878 / 2,000,000 (15.0439%)\n            Episodes: 453\n            Currently: Training cycle 4/5\n            Latest Reward: -194\n            Latest Avg Rewards: -290\n            Recent Change: 0.02\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 242.1715\n            Avg Critic Loss: 926.8345\n            =========================================\n        \n\n            =========================================\n            Timesteps: 300,878 / 2,000,000 (15.0439%)\n            Episodes: 453\n            Currently: Training cycle 5/5\n            Latest Reward: -194\n            Latest Avg Rewards: -290\n            Recent Change: 0.02\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 242.2192\n            Avg Critic Loss: 924.3807\n            =========================================\n        \n\n            =========================================\n            Timesteps: 301,628 / 2,000,000 (15.0814%)\n            Episodes: 454\n            Currently: Rollout\n            Latest Reward: -348\n            Latest Avg Rewards: -291\n            Recent Change: 0.01\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 242.0775\n            Avg Critic Loss: 921.9439\n            =========================================\n        \n\n            =========================================\n            Timesteps: 302,378 / 2,000,000 (15.1189%)\n            Episodes: 455\n            Currently: Rollout\n            Latest Reward: -222\n            Latest Avg Rewards: -291\n            Recent Change: -0.07\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 242.0775\n            Avg Critic Loss: 921.9439\n            =========================================\n        \n\n            =========================================\n            Timesteps: 303,128 / 2,000,000 (15.1564%)\n            Episodes: 456\n            Currently: Rollout\n            Latest Reward: -195\n            Latest Avg Rewards: -291\n            Recent Change: -0.16\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 242.0775\n            Avg Critic Loss: 921.9439\n            =========================================\n        \n\n            =========================================\n            Timesteps: 303,878 / 2,000,000 (15.1939%)\n            Episodes: 457\n            Currently: Rollout\n            Latest Reward: -235\n            Latest Avg Rewards: -291\n            Recent Change: -0.25\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 242.0775\n            Avg Critic Loss: 921.9439\n            =========================================\n        \n\n            =========================================\n            Timesteps: 304,628 / 2,000,000 (15.2314%)\n            Episodes: 458\n            Currently: Rollout\n            Latest Reward: -340\n            Latest Avg Rewards: -292\n            Recent Change: -0.22\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 242.0775\n            Avg Critic Loss: 921.9439\n            =========================================\n        \n\n            =========================================\n            Timesteps: 305,378 / 2,000,000 (15.2689%)\n            Episodes: 459\n            Currently: Rollout\n            Latest Reward: -320\n            Latest Avg Rewards: -294\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 242.0775\n            Avg Critic Loss: 921.9439\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 305,737 / 2,000,000 (15.2868%)\n            Episodes: 460\n            Currently: Rollout\n            Latest Reward: -223\n            Latest Avg Rewards: -293\n            Recent Change: -0.34\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 242.0775\n            Avg Critic Loss: 921.9439\n            =========================================\n        \n\n            =========================================\n            Timesteps: 306,487 / 2,000,000 (15.3244%)\n            Episodes: 461\n            Currently: Rollout\n            Latest Reward: -318\n            Latest Avg Rewards: -293\n            Recent Change: -0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 242.0775\n            Avg Critic Loss: 921.9439\n            =========================================\n        \n\n            =========================================\n            Timesteps: 306,487 / 2,000,000 (15.3244%)\n            Episodes: 461\n            Currently: Training cycle 1/5\n            Latest Reward: -318\n            Latest Avg Rewards: -293\n            Recent Change: -0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 242.0775\n            Avg Critic Loss: 921.9439\n            =========================================\n        \n\n            =========================================\n            Timesteps: 306,487 / 2,000,000 (15.3244%)\n            Episodes: 461\n            Currently: Training cycle 2/5\n            Latest Reward: -318\n            Latest Avg Rewards: -293\n            Recent Change: -0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.9486\n            Avg Critic Loss: 919.3425\n            =========================================\n        \n\n            =========================================\n            Timesteps: 306,487 / 2,000,000 (15.3244%)\n            Episodes: 461\n            Currently: Training cycle 3/5\n            Latest Reward: -318\n            Latest Avg Rewards: -293\n            Recent Change: -0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.962\n            Avg Critic Loss: 916.7596\n            =========================================\n        \n\n            =========================================\n            Timesteps: 306,487 / 2,000,000 (15.3244%)\n            Episodes: 461\n            Currently: Training cycle 4/5\n            Latest Reward: -318\n            Latest Avg Rewards: -293\n            Recent Change: -0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0001\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.8263\n            Avg Critic Loss: 914.1944\n            =========================================\n        \n\n            =========================================\n            Timesteps: 306,487 / 2,000,000 (15.3244%)\n            Episodes: 461\n            Currently: Training cycle 5/5\n            Latest Reward: -318\n            Latest Avg Rewards: -293\n            Recent Change: -0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0002\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.5591\n            Avg Critic Loss: 911.6464\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 307,237 / 2,000,000 (15.3618%)\n            Episodes: 462\n            Currently: Rollout\n            Latest Reward: -292\n            Latest Avg Rewards: -293\n            Recent Change: -0.32\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.1801\n            Avg Critic Loss: 909.115\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 307,987 / 2,000,000 (15.3994%)\n            Episodes: 463\n            Currently: Rollout\n            Latest Reward: -215\n            Latest Avg Rewards: -291\n            Recent Change: -0.3\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.1801\n            Avg Critic Loss: 909.115\n            =========================================\n        \n\n            =========================================\n            Timesteps: 308,737 / 2,000,000 (15.4368%)\n            Episodes: 464\n            Currently: Rollout\n            Latest Reward: -227\n            Latest Avg Rewards: -291\n            Recent Change: -0.35\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.1801\n            Avg Critic Loss: 909.115\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 309,487 / 2,000,000 (15.4744%)\n            Episodes: 465\n            Currently: Rollout\n            Latest Reward: -428\n            Latest Avg Rewards: -292\n            Recent Change: -0.26\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.1801\n            Avg Critic Loss: 909.115\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\nObject 0 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 309,650 / 2,000,000 (15.4825%)\n            Episodes: 466\n            Currently: Rollout\n            Latest Reward: -170\n            Latest Avg Rewards: -292\n            Recent Change: -0.41\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.1801\n            Avg Critic Loss: 909.115\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 310,400 / 2,000,000 (15.52%)\n            Episodes: 467\n            Currently: Rollout\n            Latest Reward: -395\n            Latest Avg Rewards: -292\n            Recent Change: -0.29\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.1801\n            Avg Critic Loss: 909.115\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 311,150 / 2,000,000 (15.5575%)\n            Episodes: 468\n            Currently: Rollout\n            Latest Reward: -275\n            Latest Avg Rewards: -291\n            Recent Change: -0.23\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.1801\n            Avg Critic Loss: 909.115\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 311,900 / 2,000,000 (15.595%)\n            Episodes: 469\n            Currently: Rollout\n            Latest Reward: -378\n            Latest Avg Rewards: -291\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.1801\n            Avg Critic Loss: 909.115\n            =========================================\n        \n\n            =========================================\n            Timesteps: 311,900 / 2,000,000 (15.595%)\n            Episodes: 469\n            Currently: Training cycle 1/5\n            Latest Reward: -378\n            Latest Avg Rewards: -291\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 190.1801\n            Avg Critic Loss: 909.115\n            =========================================\n        \n\n            =========================================\n            Timesteps: 311,900 / 2,000,000 (15.595%)\n            Episodes: 469\n            Currently: Training cycle 2/5\n            Latest Reward: -378\n            Latest Avg Rewards: -291\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 271.4015\n            Avg Critic Loss: 906.8852\n            =========================================\n        \n\n            =========================================\n            Timesteps: 311,900 / 2,000,000 (15.595%)\n            Episodes: 469\n            Currently: Training cycle 3/5\n            Latest Reward: -378\n            Latest Avg Rewards: -291\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0003\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 271.1969\n            Avg Critic Loss: 904.6702\n            =========================================\n        \n\n            =========================================\n            Timesteps: 311,900 / 2,000,000 (15.595%)\n            Episodes: 469\n            Currently: Training cycle 4/5\n            Latest Reward: -378\n            Latest Avg Rewards: -291\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0007\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.9752\n            Avg Critic Loss: 902.4699\n            =========================================\n        \n\n            =========================================\n            Timesteps: 311,900 / 2,000,000 (15.595%)\n            Episodes: 469\n            Currently: Training cycle 5/5\n            Latest Reward: -378\n            Latest Avg Rewards: -291\n            Recent Change: -0.15\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0011\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.7401\n            Avg Critic Loss: 900.284\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 312,650 / 2,000,000 (15.6325%)\n            Episodes: 470\n            Currently: Rollout\n            Latest Reward: -219\n            Latest Avg Rewards: -291\n            Recent Change: -0.24\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0016\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.4944\n            Avg Critic Loss: 898.1123\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\nObject 1 incorrectly sorted into sorting_one\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 312,907 / 2,000,000 (15.6453%)\n            Episodes: 471\n            Currently: Rollout\n            Latest Reward: -153\n            Latest Avg Rewards: -290\n            Recent Change: -0.36\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0016\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.4944\n            Avg Critic Loss: 898.1123\n            =========================================\n        \n\n            =========================================\n            Timesteps: 313,657 / 2,000,000 (15.6829%)\n            Episodes: 472\n            Currently: Rollout\n            Latest Reward: -270\n            Latest Avg Rewards: -290\n            Recent Change: -0.33\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0016\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.4944\n            Avg Critic Loss: 898.1123\n            =========================================\n        \n\n            =========================================\n            Timesteps: 314,407 / 2,000,000 (15.7203%)\n            Episodes: 473\n            Currently: Rollout\n            Latest Reward: -238\n            Latest Avg Rewards: -289\n            Recent Change: -0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0016\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.4944\n            Avg Critic Loss: 898.1123\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 315,157 / 2,000,000 (15.7579%)\n            Episodes: 474\n            Currently: Rollout\n            Latest Reward: -270\n            Latest Avg Rewards: -289\n            Recent Change: -0.39\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0016\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.4944\n            Avg Critic Loss: 898.1123\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 315,907 / 2,000,000 (15.7953%)\n            Episodes: 475\n            Currently: Rollout\n            Latest Reward: -215\n            Latest Avg Rewards: -287\n            Recent Change: -0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0016\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.4944\n            Avg Critic Loss: 898.1123\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 1 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 316,657 / 2,000,000 (15.8329%)\n            Episodes: 476\n            Currently: Rollout\n            Latest Reward: -236\n            Latest Avg Rewards: -288\n            Recent Change: -0.45\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0016\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.4944\n            Avg Critic Loss: 898.1123\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 316,804 / 2,000,000 (15.8402%)\n            Episodes: 477\n            Currently: Rollout\n            Latest Reward: -175\n            Latest Avg Rewards: -287\n            Recent Change: -0.54\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0016\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.4944\n            Avg Critic Loss: 898.1123\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 317,554 / 2,000,000 (15.8777%)\n            Episodes: 478\n            Currently: Rollout\n            Latest Reward: -357\n            Latest Avg Rewards: -288\n            Recent Change: -0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0016\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.4944\n            Avg Critic Loss: 898.1123\n            =========================================\n        \n\n            =========================================\n            Timesteps: 317,554 / 2,000,000 (15.8777%)\n            Episodes: 478\n            Currently: Training cycle 1/5\n            Latest Reward: -357\n            Latest Avg Rewards: -288\n            Recent Change: -0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0016\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 270.4944\n            Avg Critic Loss: 898.1123\n            =========================================\n        \n\n            =========================================\n            Timesteps: 317,554 / 2,000,000 (15.8777%)\n            Episodes: 478\n            Currently: Training cycle 2/5\n            Latest Reward: -357\n            Latest Avg Rewards: -288\n            Recent Change: -0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 232.5957\n            Avg Critic Loss: 895.8253\n            =========================================\n        \n\n            =========================================\n            Timesteps: 317,554 / 2,000,000 (15.8777%)\n            Episodes: 478\n            Currently: Training cycle 3/5\n            Latest Reward: -357\n            Latest Avg Rewards: -288\n            Recent Change: -0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0004\n            Latest Continuous Actor Loss: 0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0008\n            Latest Critic Loss: 230.5746\n            Avg Critic Loss: 893.5471\n            =========================================\n        \n\n            =========================================\n            Timesteps: 317,554 / 2,000,000 (15.8777%)\n            Episodes: 478\n            Currently: Training cycle 4/5\n            Latest Reward: -357\n            Latest Avg Rewards: -288\n            Recent Change: -0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0006\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 227.8561\n            Avg Critic Loss: 891.2751\n            =========================================\n        \n\n            =========================================\n            Timesteps: 317,554 / 2,000,000 (15.8777%)\n            Episodes: 478\n            Currently: Training cycle 5/5\n            Latest Reward: -357\n            Latest Avg Rewards: -288\n            Recent Change: -0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0006\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 224.5995\n            Avg Critic Loss: 889.0075\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 318,304 / 2,000,000 (15.9152%)\n            Episodes: 479\n            Currently: Rollout\n            Latest Reward: -366\n            Latest Avg Rewards: -288\n            Recent Change: -0.42\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 220.9577\n            Avg Critic Loss: 886.7429\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 319,054 / 2,000,000 (15.9527%)\n            Episodes: 480\n            Currently: Rollout\n            Latest Reward: -282\n            Latest Avg Rewards: -288\n            Recent Change: -0.44\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 220.9577\n            Avg Critic Loss: 886.7429\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"b3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nObject 0 dropped to the floor\nObject 1 dropped to the floor\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\nb3Warning[examples/SharedMemory/PhysicsDirect.cpp,866]:\nRemove body failed\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 319,179 / 2,000,000 (15.9589%)\n            Episodes: 481\n            Currently: Rollout\n            Latest Reward: -139\n            Latest Avg Rewards: -287\n            Recent Change: -0.56\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 220.9577\n            Avg Critic Loss: 886.7429\n            =========================================\n        \n\n            =========================================\n            Timesteps: 319,929 / 2,000,000 (15.9965%)\n            Episodes: 482\n            Currently: Rollout\n            Latest Reward: -473\n            Latest Avg Rewards: -289\n            Recent Change: -0.47\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 220.9577\n            Avg Critic Loss: 886.7429\n            =========================================\n        \n\n            =========================================\n            Timesteps: 320,679 / 2,000,000 (16.034%)\n            Episodes: 483\n            Currently: Rollout\n            Latest Reward: -485\n            Latest Avg Rewards: -293\n            Recent Change: -0.46\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 220.9577\n            Avg Critic Loss: 886.7429\n            =========================================\n        \n\n            =========================================\n            Timesteps: 321,429 / 2,000,000 (16.0715%)\n            Episodes: 484\n            Currently: Rollout\n            Latest Reward: -257\n            Latest Avg Rewards: -293\n            Recent Change: -0.52\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 220.9577\n            Avg Critic Loss: 886.7429\n            =========================================\n        \n\n            =========================================\n            Timesteps: 322,179 / 2,000,000 (16.109%)\n            Episodes: 485\n            Currently: Rollout\n            Latest Reward: -270\n            Latest Avg Rewards: -291\n            Recent Change: -0.38\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 220.9577\n            Avg Critic Loss: 886.7429\n            =========================================\n        \n","output_type":"stream"},{"name":"stdout","text":"Object 0 dropped to the floor\n","output_type":"stream"},{"name":"stderr","text":"\n            =========================================\n            Timesteps: 322,929 / 2,000,000 (16.1465%)\n            Episodes: 486\n            Currently: Rollout\n            Latest Reward: -334\n            Latest Avg Rewards: -291\n            Recent Change: -0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 220.9577\n            Avg Critic Loss: 886.7429\n            =========================================\n        \n\n            =========================================\n            Timesteps: 322,929 / 2,000,000 (16.1465%)\n            Episodes: 486\n            Currently: Training cycle 1/5\n            Latest Reward: -334\n            Latest Avg Rewards: -291\n            Recent Change: -0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0005\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 220.9577\n            Avg Critic Loss: 886.7429\n            =========================================\n        \n\n            =========================================\n            Timesteps: 322,929 / 2,000,000 (16.1465%)\n            Episodes: 486\n            Currently: Training cycle 2/5\n            Latest Reward: -334\n            Latest Avg Rewards: -291\n            Recent Change: -0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: -0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 436.93\n            Avg Critic Loss: 885.2233\n            =========================================\n        \n\n            =========================================\n            Timesteps: 322,929 / 2,000,000 (16.1465%)\n            Episodes: 486\n            Currently: Training cycle 3/5\n            Latest Reward: -334\n            Latest Avg Rewards: -291\n            Recent Change: -0.37\n            Best Reward: -108.08\n            Latest Discrete Actor Loss: 0.0\n            Latest Continuous Actor Loss: -0.0\n            Avg Discrete Actor Loss: -0.0001\n            Avg Continuous Actor Loss: 0.0007\n            Latest Critic Loss: 439.5203\n            Avg Critic Loss: 883.7226\n            =========================================\n        \n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}